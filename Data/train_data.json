[{"context": "The dialogue above is from ELIZA, an early natural language processing system ELIZA that could carry on a limited conversation with a user by imitating the responses of a Rogerian psychotherapist (Weizenbaum, 1966). ELIZA is a surprisingly simple program that uses pattern matching to recognize phrases like \\\"I need X\\\" and translate them into suitable outputs like \\\"What would it mean to you if you got X?\\\". This simple technique succeeds in this domain because ELIZA doesn't actually need to know anything to mimic a Rogerian psychotherapist. As Weizenbaum notes, this is one of the few dialogue genres where listeners can act as if they know nothing of the world. Eliza's mimicry of human conversation was remarkably successful: many people who interacted with ELIZA came to believe that it really understood them and their problems, many continued to believe in ELIZA's abilities even after the program's operation was explained to them (Weizenbaum, 1976), and even today such chatbots are a fun diversion.", "questions_and_answers": [{"answer_start": 171, "answer": "Rogerian psychotherapist", "question": "ELIZA could carry on a limited conversation with a user by imitating the responses of what?"}, {"answer_start": 27, "answer": "ELIZA", "question": "What is a surprisingly simple program that uses pattern matching to recognize phrases like \"I need X\" and translate them into suitable outputs"}, {"answer_start": 466, "answer": "ELIZA doesn't actually need to know anything", "question": "Why is ELIZA able to mimic a Rogerian psychotherapist?"}, {"answer_start": 197, "answer": "Weizenbaum", "question": "Who noted that ELIZA is one of the few dialogue genres where listeners can act as if they know nothing of the world?"}, {"answer_start": 957, "answer": "1976", "question": "When did Weizenbaum write about ELIZA?"}]}, {"context": "Of course modern conversational agents are much more than a diversion; they can answer questions, book flights, or find restaurants, functions for which they rely on a much more sophisticated understanding of the user's intent, as we will see in Chapter 24. Nonetheless, the simple pattern-based methods that powered ELIZA and other chatbots play a crucial role in natural language processing.", "questions_and_answers": [{"answer_start": 17, "answer": "conversational agents", "question": "What modern chatbots are more than a diversion?"}, {"answer_start": 365, "answer": "natural language processing", "question": "What do the simple pattern-based methods that powered ELIZA and other chatbots play a crucial role in?"}]}, {"context": "We'll begin with the most important tool for describing text patterns: the regular expression. Regular expressions can be used to specify strings we might want to extract from a document, from transforming \\\"I need X\\\" in Eliza above, to defining strings like $199 or $24.99 for extracting tables of prices from a document.", "questions_and_answers": [{"answer_start": 71, "answer": "the regular expression", "question": "What is the most important tool for describing text patterns?"}, {"answer_start": 260, "answer": "$199 or $24.99", "question": "Regular expressions can be used to specify strings like what?"}, {"answer_start": 222, "answer": "Eliza", "question": "What is the name of the regular expression that can be used to specify strings we want to extract from a document?"}]}, {"context": "We'll then turn to a set of tasks collectively called text normalization, in which regular expressions play an important part. Normalizing text means converting it to a more convenient, standard form. For example, most of what we are going to do with language relies on first separating out or tokenizing words from running text, the task of tokenization. English words are often separated from each other by whitespace, but whitespace is not always sufficient. New York and rock 'n' roll are sometimes treated as large words despite the fact that they contain spaces, while sometimes we'll need to separate I'm into the two words I and am. For processing tweets or texts we'll need to tokenize emoticons like :) or hashtags like #nlproc. [ 2.1 ] \\u2022 REGULAR EXPRESSIONS 3 Some languages, like Japanese, don't have spaces between words, so word tokenization becomes more difficult.", "questions_and_answers": [{"answer_start": 54, "answer": "text normalization", "question": "What is a set of tasks collectively called?"}, {"answer_start": 150, "answer": "converting it to a more convenient, standard form", "question": "What does normalizing text mean?"}, {"answer_start": 342, "answer": "tokenization", "question": "What is the task of separating words from running text?"}, {"answer_start": 409, "answer": "whitespace", "question": "English words are often separated from each other by what?"}, {"answer_start": 462, "answer": "New York and rock 'n' roll", "question": "What are sometimes treated as large words despite the fact that they contain spaces?"}, {"answer_start": 730, "answer": "#nlproc", "question": "What is an example of a hashtag that we'll need to tokenize?"}, {"answer_start": 797, "answer": "Japanese", "question": "What language doesn't have spaces between words?"}]}, {"context": "Another part of text normalization is lemmatization, the task of determining that two words have the same root, despite their surface differences. For example, the words sang, sung, and sings are forms of the verb sing. The word sing is the common lemma of these words, and a lemmatizer maps from all of these to sing. Lemmatization is essential for processing morphologically complex languages like Arabic. Stemming refers to a simpler version of lemmatization in which we mainly just strip suffixes from the end of the word. Text normalization also includes sentence segmentation: breaking up a text into individual sentences, using cues like periods or exclamation points.", "questions_and_answers": [{"answer_start": 38, "answer": "lemmatization", "question": "What is the task of determining that two words have the same root?"}, {"answer_start": 186, "answer": "sing", "question": "What is a form of the verb sing?"}, {"answer_start": 186, "answer": "sing", "question": "What is the common lemma of the words sang, sung, and sings?"}, {"answer_start": 319, "answer": "Lemmatization", "question": "What is essential for processing morphologically complex languages like Arabic?"}, {"answer_start": 408, "answer": "Stemming", "question": "What refers to a simpler version of lemmatization in which we mainly strip suffixes from the end of the word?"}, {"answer_start": 618, "answer": "sentences", "question": "Text normalization breaks up a text into individual what?"}]}, {"context": "Finally, we'll need to compare words and other strings. We'll introduce a metric called edit distance that measures how similar two strings are based on the number of edits (insertions, deletions, substitutions) it takes to change one string into the other. Edit distance is an algorithm with applications throughout language processing, from spelling correction to speech recognition to coreference resolution.", "questions_and_answers": [{"answer_start": 23, "answer": "compare", "question": "What will we need to do with words and other strings?"}, {"answer_start": 88, "answer": "edit distance", "question": "What metric measures how similar two strings are based on the number of edits?"}, {"answer_start": 258, "answer": "Edit distance", "question": "What is an algorithm with applications throughout language processing?"}]}, {"context": "One of the unsung successes in standardization in computer science has been the regular expression (RE), a language for specifying text search strings. This prac-regular expression tical language is used in every computer language, word processor, and text processing tools like the Unix tools grep or Emacs. Formally, a regular expression is an algebraic notation for characterizing a set of strings. They are particularly useful for searching in texts, when we have a pattern to search for and a corpus of texts to search through. A regular expression search function will search through the corpus, returning all texts that match the pattern. The corpus can be a single document or a collection. For example, the Unix command-line tool grep takes a regular expression and returns every line of the input document that matches the expression.", "questions_and_answers": [{"answer_start": 80, "answer": "regular expression", "question": "What language is used for specifying text search strings?"}, {"answer_start": 157, "answer": "prac-regular expression tical", "question": "What language is used in every computer language, word processor, and text processing tools like the Unix tools grep or Emacs?"}, {"answer_start": 346, "answer": "algebraic notation", "question": "What is a regular expression?"}, {"answer_start": 498, "answer": "corpus", "question": "Regular expressions are particularly useful when we have a pattern to search for and what type of texts to search through?"}, {"answer_start": 533, "answer": "A regular expression search function", "question": "What will search through the corpus, returning all texts that match the pattern?"}, {"answer_start": 664, "answer": "a single document or a collection", "question": "What types of corpus can a regular expression search function search through?"}, {"answer_start": 783, "answer": "every line of the input document", "question": "What does grep return that matches a regular expression?"}]}, {"context": "A search can be designed to return every match on a line, if there are more than one, or just the first match. In the following examples we generally underline the exact part of the pattern that matches the regular expression and show only the first match. We'll show regular expressions delimited by slashes but note that slashes are not part of the regular expressions.", "questions_and_answers": [{"answer_start": 35, "answer": "every match on a line", "question": "A search can be designed to return what if there are more than one, or just the first match?"}, {"answer_start": 160, "answer": "the exact part of the pattern", "question": "In the following examples, what is underlined that matches the regular expression?"}, {"answer_start": 301, "answer": "slashes", "question": "What are regular expressions delimited by?"}]}, {"context": "Regular expressions come in many variants. We'll be describing extended regular expressions; different regular expression parsers may only recognize subsets of these, or treat some expressions slightly differently. Using an online regular expression tester is a handy way to test out your expressions and explore these variations.", "questions_and_answers": [{"answer_start": 0, "answer": "Regular expressions", "question": "What come in many variants?"}, {"answer_start": 93, "answer": "different regular expression parsers may only recognize subsets of these, or treat some expressions slightly differently", "question": "What is the difference between regular expression parsers and regular expression parsers?"}, {"answer_start": 63, "answer": "extended regular expressions", "question": "What will we be describing?"}, {"answer_start": 224, "answer": "online regular expression tester", "question": "What is a handy way to test out your expressions?"}]}, {"context": "The simplest kind of regular expression is a sequence of simple characters. To search for woodchuck, we type [ /woodchuck/ ]. The expression [ /Buttercup/ ] matches any string containing the substring Buttercup; grep with that expression would return the line I'm called little Buttercup. The search string can consist of a single character (like [ /!/ ]) or a sequence of characters (like [ /urgl/ ]).", "questions_and_answers": [{"answer_start": 43, "answer": "a sequence of simple characters", "question": "What is the simplest kind of regular expression?"}, {"answer_start": 90, "answer": "woodchuck", "question": "To search for what, we type [ /woodchuck/ ]."}, {"answer_start": 157, "answer": "matches any string containing the substring Buttercup", "question": "What does the expression \"Buttercup\" match?"}, {"answer_start": 322, "answer": "a single character", "question": "What can a search string consist of?"}]}, {"context": "Regular expressions are case sensitive; lower case [ /[ s/ ] is distinct from upper case [ /S/ ] ] ([ /s/ ] matches a lower case s but not an upper case S). This means that the pattern [ /woodchucks/ ] will not match the string Woodchucks. We can solve this problem with the use of the square braces [ and ] . The string of characters inside the braces specifies a disjunction of characters to match. For example, Figure [ 2.2 ] shows that the pattern [ /[wW]/ ] matches patterns containing either w or W.", "questions_and_answers": [{"answer_start": 24, "answer": "case sensitive", "question": "Regular expressions are what?"}, {"answer_start": 217, "answer": "the string Woodchucks", "question": "The pattern [ /woodchucks/ ] will not match what?"}, {"answer_start": 286, "answer": "square braces", "question": "What can be used to solve the problem of woodchucks not matching the string Woodchucks?"}, {"answer_start": 365, "answer": "disjunction", "question": "The string of characters inside the braces specifies what?"}, {"answer_start": 498, "answer": "w or W", "question": "What characters does the pattern match?"}]}, {"context": "How can we talk about optional elements, like an optional s in woodchuck and woodchucks? We can\u2019t use the square brackets, because while they allow us to say \u201cs or S\u201d, they don\u2019t allow us to say \u201cs or nothing\u201d. For this we use the question mark [ /?/ ], which means \u201cthe preceding character or nothing\u201d, as shown in Figure [ 2.5 ].", "questions_and_answers": [{"answer_start": 22, "answer": "optional elements", "question": "What is an optional s in woodchuck and woodchucks?"}, {"answer_start": 106, "answer": "square brackets", "question": "What can't be used because they don't allow us to say \"s or S\"?"}, {"answer_start": 267, "answer": "the preceding character or nothing", "question": "What does the question mark mean?"}]}, {"context": "This language consists of strings with a b, followed by at least two a's, followed by an exclamation point. The set of operators that allows us to say things like \"some number of as\" are based on the asterisk or *, commonly called the Kleene * (gen-Kleene * erally pronounced \"cleany star\"). The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\". So [ /a*/ ] means \"any string of zero or more as\". This will match a or aaaaaa, but it will also match Off Minor since the string Off Minor has zero a's. So the regular expression for matching one or more a is [ /aa*/ ], meaning one a followed by zero or more as. More complex patterns can also be repeated. So [ /[ab]*/ ] means \"zero or more a's or b's\" (not \"zero or more right square braces\"). This will match strings like aaaa or ababab or bbbb.", "questions_and_answers": [{"answer_start": 41, "answer": "b", "question": "What is the name of the string that consists of strings with a?"}, {"answer_start": 200, "answer": "asterisk or *", "question": "The set of operators that allows us to say things like \"some number of as\" are based on what?"}, {"answer_start": 315, "answer": "zero or more occurrences of the immediately previous character or regular expression", "question": "What does the Kleene star mean?"}, {"answer_start": 421, "answer": "any string of zero or more as", "question": "What does the Kleene star mean?"}, {"answer_start": 469, "answer": "a or aaaaa", "question": "What strings will this match?"}, {"answer_start": 631, "answer": "one a followed by zero or more as", "question": "What does the regular expression for matching one or more a mean?"}, {"answer_start": 666, "answer": "More complex patterns", "question": "What can also be repeated?"}, {"answer_start": 763, "answer": "zero or more right square braces", "question": "What is not a \"zero or more a's or b's\"?"}, {"answer_start": 846, "answer": "bbbb", "question": "What is a string that will match aaaa or ababab?"}]}, {"context": "For specifying multiple digits (useful for finding prices) we can extend [ /[0-9]/ ], the regular expression for a single digit. An integer (a string of digits) is thus [ /[0-9][0-9]*/ ]. (Why isn't it just [ /[0-9]*/ ]?) Sometimes it's annoying to have to write the regular expression for digits twice, so there is a shorter way to specify \"at least one\" of some character. This is the Kleene +, which means \"one or more occurrences of the immediately preceding Kleene + character or regular expression\". Thus, the expression [ /[0-9]+/ ] is the normal way to specify \"a sequence of digits\". There are thus two ways to specify the sheep language: [ /baaa*!/ ] or [ /baa+!/ ].", "questions_and_answers": [{"answer_start": 43, "answer": "finding prices", "question": "What is the use of multiple digits?"}, {"answer_start": 141, "answer": "a string of digits", "question": "What is an integer?"}, {"answer_start": 207, "answer": "[ /[0-9]*/", "question": "What is the regular expression for a string of digits?"}, {"answer_start": 297, "answer": "twice", "question": "Sometimes it's annoying to have to write the regular expression for digits how many times?"}, {"answer_start": 387, "answer": "Kleene +", "question": "What is a shorter way to specify \"at least one\" of some character?"}, {"answer_start": 527, "answer": "[ /[0-9]+/ ]", "question": "What is the normal way to specify a sequence of digits?"}, {"answer_start": 632, "answer": "sheep language", "question": "What is there two ways to specify?"}]}, {"context": "One very important special character is the period ([ /./ ]), a wildcard expression that matches any single character (except a carriage return), as shown in Figure 2 .6.", "questions_and_answers": [{"answer_start": 40, "answer": "the period", "question": "What is a wildcard expression that matches any single character except a carriage return?"}, {"answer_start": 128, "answer": "carriage return", "question": "What is the only wildcard expression that matches any single character?"}]}, {"context": "The wildcard is often used together with the Kleene star to mean \"any string of characters\". For example, suppose we want to find any line in which a particular word, for example, aardvark, appears twice. We can specify this with the regular expression /aardvark. *aardvark/.", "questions_and_answers": [{"answer_start": 66, "answer": "any string of characters", "question": "The wildcard is often used together with the Kleene star to mean what?"}, {"answer_start": 180, "answer": "aardvark", "question": "What is an example of a word that appears twice in a line?"}, {"answer_start": 253, "answer": "/aardvark", "question": "What is the regular expression used to specify a line in which a word, for example, aardvark, appears twice?"}, {"answer_start": 264, "answer": "*aardvark", "question": "What is the regular expression for aardvark?"}]}, {"context": "Suppose we need to search for texts about pets; perhaps we are particularly interested in cats and dogs. In such a case, we might want to search for either the string cat or the string dog. Since we can't use the square brackets to search for \"cat or dog\" (why can't we say [ /[catdog]/ ]? ), we need a new operator, the disjunction operator, also disjunction called the pipe symbol |. The pattern [ /cat|dog/ ] matches either the string cat or the string dog.", "questions_and_answers": [{"answer_start": 90, "answer": "cats and dogs", "question": "What are we particularly interested in when searching for texts about pets?"}, {"answer_start": 160, "answer": "string cat or the string dog", "question": "What would we want to search for in a text about pets?"}, {"answer_start": 213, "answer": "square brackets", "question": "What can't we use to search for \"cat or dog\"?"}, {"answer_start": 321, "answer": "disjunction operator", "question": "What is the new operator that we need?"}, {"answer_start": 386, "answer": "The pattern", "question": "What matches either the string cat or the string dog?"}]}, {"context": "Sometimes we need to use this disjunction operator in the midst of a larger sequence. For example, suppose I want to search for information about pet fish for my cousin David. How can I specify both guppy and guppies? We cannot simply say [ /guppy|ies/ ], because that would match only the strings guppy and ies. This is because sequences like guppy take precedence over the disjunction operator |.", "questions_and_answers": [{"answer_start": 30, "answer": "disjunction operator", "question": "What operator do we sometimes need to use in the midst of a larger sequence?"}, {"answer_start": 146, "answer": "pet fish", "question": "What do I want to search for for my cousin David?"}, {"answer_start": 199, "answer": "guppy and guppies", "question": "What can I specify when searching for information about pet fish for my cousin David?"}, {"answer_start": 241, "answer": "/guppy|ies/", "question": "What can't be used to specify both guppy and guppies?"}, {"answer_start": 329, "answer": "sequences like guppy take precedence over the disjunction operator", "question": "Why can't we simply say [ /guppy|ies/ ], because that would match only the strings guppy and ies?"}]}, {"context": "precedence To make the disjunction operator apply only to a specific pattern, we need to use the parenthesis operators ( and ). Enclosing a pattern in parentheses makes it act like a single character for the purposes of neighboring operators like the pipe | and the Kleene*. So the pattern [ /gupp(y|ies)/ ] would specify that we meant the disjunction only to apply to the suffixes y and ies.", "questions_and_answers": [{"answer_start": 97, "answer": "parenthesis operators", "question": "What do we need to use to make the disjunction operator apply only to a specific pattern?"}, {"answer_start": 151, "answer": "parentheses", "question": "Enclosing a pattern in what makes it act like a single character for the purposes of neighboring operators?"}, {"answer_start": 382, "answer": "y and ies", "question": "What suffixes would the pattern specify that we meant the disjunction only to apply to?"}]}, {"context": "The parenthesis operator ( is also useful when we are using counters like the Kleene*. Unlike the | operator, the Kleene* operator applies by default only to a single character, not to a whole sequence. Suppose we want to match repeated instances of a string. Perhaps we have a line that has column labels of the form Column 1 Column 2 Column 3. The expression [ /Column [0-9]+ */ ] will not match any number of columns; instead, it will match a single column followed by any number of spaces! The star here applies only to the space that precedes it, not to the whole sequence. With the parentheses, we could write the expression [ /(Column [0-9]+ *)*/ ] to match the word Column, followed by a number and optional spaces, the whole pattern repeated zero or more times.", "questions_and_answers": [{"answer_start": 0, "answer": "The parenthesis operator", "question": "What is useful when we are using counters like the Kleene*?"}, {"answer_start": 78, "answer": "Kleene*", "question": "What operator applies by default only to a single character?"}, {"answer_start": 228, "answer": "repeated instances of a string", "question": "What do we want to match with the Kleene* operator?"}, {"answer_start": 318, "answer": "Column 1 Column 2 Column 3", "question": "What is the name of the column labels on a line that we want to match repeated instances of a string?"}, {"answer_start": 444, "answer": "a single column followed by any number of spaces", "question": "The expression [ /Column [0-9]+ */ ] will match what?"}, {"answer_start": 524, "answer": "the space that precedes it", "question": "The star here applies only to what?"}, {"answer_start": 724, "answer": "the whole pattern", "question": "What is repeated zero or more times with the Kleene* operator?"}]}, {"context": "This idea that one operator may take precedence over another, requiring us to sometimes use parentheses to specify what we mean, is formalized by the operator precedence hierarchy for regular expressions. The following table gives the order of RE operator precedence, from highest precedence to lowest precedence.", "questions_and_answers": [{"answer_start": 92, "answer": "parentheses", "question": "What do we sometimes use to specify what we mean?"}, {"answer_start": 273, "answer": "highest precedence to lowest precedence", "question": "What is the order of RE operator precedence?"}]}, {"context": "Suppose we wanted to write a RE to find cases of the English article the. A simple (but incorrect) pattern might be: [ /the/ ]", "questions_and_answers": [{"answer_start": 32, "answer": "to find cases of the English article the", "question": "What is the purpose of writing a RE?"}, {"answer_start": 76, "answer": "simple", "question": "What kind of pattern might we write to find cases of the English article the?"}]}, {"context": "One problem is that this pattern will miss the word when it begins a sentence and hence is capitalized (i.e., The). This might lead us to the following pattern: [ /[tT]he/ ]", "questions_and_answers": [{"answer_start": 38, "answer": "miss the word", "question": "What happens when a sentence begins and is capitalized?"}, {"answer_start": 91, "answer": "capitalized", "question": "What is a pattern that misses the word when it begins a sentence?"}, {"answer_start": 161, "answer": "[ /[tT]he/", "question": "What might lead us to the following pattern?"}]}, {"context": "But we will still incorrectly return texts with the embedded in other words (e.g., other or theology). So we need to specify that we want instances with a word boundary on both sides: [ /\\b[tT]he\\b/ ]", "questions_and_answers": [{"answer_start": 52, "answer": "embedded in other words", "question": "We will still return texts with what?"}, {"answer_start": 155, "answer": "word boundary", "question": "What do we want instances with on both sides?"}]}, {"context": "But there is still one more problem with this pattern: it won\u2019t find the word the when it begins a line. This is because the regular expression [\u02c6a-zA-Z], which we used to avoid embedded instances of the, implies that there must be some single (although non-alphabetic) character before the the. We can avoid this by specifying that before the the we require either the beginning-of-line or a non-alphabetic character, and the same at the end of the line: [ /(\u02c6|[\u02c6a-zA-Z])[tT]he([\u02c6a-zA-Z]|$)/ ]", "questions_and_answers": [{"answer_start": 55, "answer": "it won\u2019t find the word the when it begins a line", "question": "What is the problem with the pattern?"}, {"answer_start": 205, "answer": "implies that there must be some single (although non-alphabetic) character before the the", "question": "What does the regular expression [a-zA-Z] mean?"}, {"answer_start": 366, "answer": "the beginning-of-line or a non-alphabetic character", "question": "What do we specify before the the?"}]}, {"context": "The process we just went through was based on fixing two kinds of errors: false positives, strings that we incorrectly matched like other or there, and false negafalse positives tives, strings that we incorrectly missed, like The. Addressing these two kinds of false negatives errors comes up again and again in implementing speech and language processing systems. Reducing the overall error rate for an application thus involves two antagonistic efforts:", "questions_and_answers": [{"answer_start": 74, "answer": "false positives", "question": "What are strings that we incorrectly matched like other or there?"}, {"answer_start": 152, "answer": "false negafalse positives tives", "question": "What are strings that we incorrectly missed like The?"}, {"answer_start": 152, "answer": "false negafalse positives", "question": "What are tives?"}, {"answer_start": 325, "answer": "speech and language processing systems", "question": "In what systems do false negatives come up again and again?"}, {"answer_start": 434, "answer": "antagonistic efforts", "question": "Reducing the overall error rate for an application involves two what?"}]}, {"context": "We'll come back to precision and recall with more precise definitions in Chapter 4.", "questions_and_answers": [{"answer_start": 73, "answer": "Chapter 4", "question": "In what chapter will we get more precise definitions?"}]}, {"context": "Let\u2019s try out a more significant example of the power of REs. Suppose we want to build an application to help a user buy a computer on the Web. The user might want \u201cany machine with at least 6 GHz and 500 GB of disk space for less than $1000\u201d. To do this kind of retrieval, we first need to be able to look for expressions like 6GHz or 500 GB or Mac or $999.99. In the rest of this section we\u2019ll work out some simple regular expressions for this task.", "questions_and_answers": [{"answer_start": 57, "answer": "REs", "question": "What is a more significant example of the power of?"}, {"answer_start": 81, "answer": "build an application", "question": "What do we want to do to help a user buy a computer on the Web?"}, {"answer_start": 236, "answer": "$1000", "question": "What would a user want to buy a computer for?"}, {"answer_start": 353, "answer": "$999.99", "question": "What is the price range for a Mac?"}, {"answer_start": 410, "answer": "simple regular expressions", "question": "What will we work out in the rest of this section?"}]}, {"context": "First, let\u2019s complete our regular expression for prices. Here\u2019s a regular expression for a dollar sign followed by a string of digits:", "questions_and_answers": [{"answer_start": 49, "answer": "prices", "question": "What does the regular expression for a dollar sign follow by a string of digits?"}, {"answer_start": 115, "answer": "a string of digits", "question": "What is the regular expression for a dollar sign followed by?"}]}, {"context": "Note that the $ character has a different function here than the end-of-line function we discussed earlier. Most regular expression parsers are smart enough to realize that $ here doesn\u2019t mean end-of-line. (As a thought experiment, think about how regex parsers might figure out the function of $ from the context.)", "questions_and_answers": [{"answer_start": 14, "answer": "$", "question": "What character has a different function here than the end-of-line function?"}, {"answer_start": 65, "answer": "end-of-line", "question": "Most regular expression parsers are smart enough to realize that $ here doesn't mean what?"}, {"answer_start": 248, "answer": "regex parsers", "question": "Who might figure out the function of $ from the context?"}]}, {"context": "Modifying this regular expression so that it only matches more than 500 GB is left as an exercise for the reader.", "questions_and_answers": [{"answer_start": 68, "answer": "500 GB", "question": "How many GB does the regular expression match?"}]}, {"context": "An important use of regular expressions is in substitutions. For example, the substitution operator [ s[ /regexp1/ ]pattern[ / ] used in Python and in Unix commands like vim or sed allows a string characterized by a regular expression to be replaced by another string: [ s/ ]colour[ /color/ ] ]", "questions_and_answers": [{"answer_start": 46, "answer": "substitutions", "question": "What is an important use of regular expressions?"}, {"answer_start": 78, "answer": "substitution operator", "question": "What operator allows a string characterized by a regular expression to be replaced by another string?"}]}, {"context": "Here the \\1 will be replaced by whatever string matched the first item in parentheses. So this will match the bigger they were, the bigger they will be but not the bigger they were, the faster they will be.", "questions_and_answers": [{"answer_start": 74, "answer": "parentheses", "question": "Where will the 1 be replaced by whatever string matched the first item in?"}, {"answer_start": 182, "answer": "the faster they will be", "question": "What happens when the 1 is replaced by whatever string matched the first item in parentheses?"}]}, {"context": "Since multiple substitutions can apply to a given input, substitutions are assigned a rank and applied in order. Creating patterns is the topic of Exercise [ 2.3 ], and we return to the details of the ELIZA architecture in Chapter 24.", "questions_and_answers": [{"answer_start": 86, "answer": "rank", "question": "What are substitutions assigned?"}, {"answer_start": 113, "answer": "Creating patterns", "question": "What is the topic of Exercise 2.3?"}]}, {"context": "Finally, there will be times when we need to predict the future: look ahead in the text to see if some pattern matches, but not advance the match cursor, so that we can then deal with the pattern if it occurs.", "questions_and_answers": [{"answer_start": 128, "answer": "advance the match cursor", "question": "What do we not do when we need to look ahead in text to see if a pattern matches?"}]}, {"context": "Before we talk about processing words, we need to decide what counts as a word. Let\u2019s start by looking at one particular corpus (plural corpora), a computer-readable collection of text or speech. For example the Brown corpus is a million-word collection of samples from 500 written English texts from different genres (newspaper, fiction, non-fiction, academic, etc. ), assembled at Brown University in 1963-64 (Ku\u010dera and Francis, 1967) . How many words are in the following Brown sentence?", "questions_and_answers": [{"answer_start": 57, "answer": "what counts as a word", "question": "What do we need to decide before we talk about processing words?"}, {"answer_start": 129, "answer": "plural corpora", "question": "What is another name for corpus?"}, {"answer_start": 228, "answer": "a million-word collection of samples from 500 written English texts", "question": "What is the Brown corpus?"}, {"answer_start": 403, "answer": "1963-64", "question": "When was the Brown corpus assembled?"}, {"answer_start": 440, "answer": "How many words are in the following Brown sentence?", "question": "How many words are in the following Brown sentence?"}]}, {"context": "This sentence has 13 words if we don't count punctuation marks as words, 15 if we count punctuation. Whether we treat period (\". \"), comma (\",\"), and so on as words depends on the task. Punctuation is critical for finding boundaries of things (commas, periods, colons) and for identifying some aspects of meaning (question marks, exclamation marks, quotation marks). For some tasks, like part-of-speech tagging or parsing or speech synthesis, we sometimes treat punctuation marks as if they were separate words.", "questions_and_answers": [{"answer_start": 18, "answer": "13", "question": "How many words does this sentence have if we don't count punctuation marks as words?"}, {"answer_start": 73, "answer": "15", "question": "How many words does this sentence have if we count punctuation?"}, {"answer_start": 118, "answer": "period", "question": "What is a comma or comma in a sentence?"}, {"answer_start": 133, "answer": "comma", "question": "What word does a sentence have that isn't punctuation marks?"}, {"answer_start": 186, "answer": "Punctuation", "question": "What is critical for finding boundaries of things?"}, {"answer_start": 388, "answer": "part-of-speech tagging or parsing or speech synthesis", "question": "For what tasks do we sometimes treat punctuation marks as if they were separate words?"}]}, {"context": "The Switchboard corpus of American English telephone conversations between strangers was collected in the early 1990s; it contains 2430 conversations averaging 6 minutes each, totaling 240 hours of speech and about 3 million words (Godfrey et al., 1992) . Such corpora of spoken language don't have punctuation but do intro-duce other complications with regard to defining words. Let's look at one utterance from Switchboard; an utterance is the spoken correlate of a sentence: I do uh main-mainly business data processing This utterance has two kinds of disfluencies. The broken-off word main-is disfluency called a fragment. Words like uh and um are called fillers or filled pauses. Should we consider these to be words? Again, it depends on the application. If we are building a speech transcription system, we might want to eventually strip out the disfluencies.", "questions_and_answers": [{"answer_start": 215, "answer": "3 million", "question": "How many words are in the Switchboard corpus?"}, {"answer_start": 299, "answer": "punctuation", "question": "What does the Switchboard corpus of spoken language not have?"}, {"answer_start": 542, "answer": "two", "question": "How many kinds of disfluencies does an utterance have?"}, {"answer_start": 597, "answer": "disfluency", "question": "The broken-off word main-is what called a fragment?"}, {"answer_start": 670, "answer": "filled pauses", "question": "Fillers or what are words like uh and um called?"}, {"answer_start": 225, "answer": "words", "question": "fillers or filled pauses"}, {"answer_start": 744, "answer": "the application", "question": "uh and um are filled pauses. Should we consider them to be words?"}, {"answer_start": 839, "answer": "strip out the disfluencies", "question": "If we are building a speech transcription system, we might want to eventually what?"}]}, {"context": "Are capitalized tokens like They and uncapitalized tokens like they the same word? These are lumped together in some tasks (speech recognition), while for partof-speech or named-entity tagging, capitalization is a useful feature and is retained.", "questions_and_answers": [{"answer_start": 4, "answer": "capitalized tokens", "question": "What is similar to They and uncapitalized tokens?"}, {"answer_start": 124, "answer": "speech recognition", "question": "What is an example of a task where capitalized and uncapitalized tokens are lumped together?"}]}, {"context": "How about inflected forms like cats versus cat? These two words have the same lemma cat but are different wordforms. A lemma is a set of lexical forms having lemma the same stem, the same major part-of-speech, and the same word sense. The wordform is the full inflected or derived form of the word. For morphologically complex wordform languages like Arabic, we often need to deal with lemmatization. For many tasks in English, however, wordforms are sufficient.", "questions_and_answers": [{"answer_start": 31, "answer": "cats", "question": "What word has the same lemma cat but are different wordforms?"}, {"answer_start": 78, "answer": "lemma cat", "question": "What do cats and cats have the same?"}, {"answer_start": 117, "answer": "A lemma", "question": "What is a set of lexical forms having lemma the same stem, the same major part-of-speech, and the"}, {"answer_start": 255, "answer": "full inflected or derived form", "question": "What is the wordform of a lemma?"}, {"answer_start": 386, "answer": "lemmatization", "question": "For morphologically complex wordform languages like Arabic, we often need to deal with what?"}, {"answer_start": 419, "answer": "English", "question": "For many tasks in what language are wordforms sufficient?"}]}, {"context": "How many words are there in English? To answer this question we need to distinguish two ways of talking about words. Types are the number of distinct words word type in a corpus; if the set of words in the vocabulary is V , the number of types is the vocabulary size |V |. Tokens are the total number N of running words. If we ignore word token punctuation, the following Brown sentence has 16 tokens and 14 types:", "questions_and_answers": [{"answer_start": 0, "answer": "How many words", "question": "How many words are there in English?"}, {"answer_start": 84, "answer": "two", "question": "How many ways of talking about words are there in English?"}, {"answer_start": 117, "answer": "Types", "question": "What are the number of distinct words word type in a corpus?"}, {"answer_start": 288, "answer": "total number N of running words", "question": "What are tokens?"}, {"answer_start": 391, "answer": "16", "question": "How many tokens does the following Brown sentence have?"}]}, {"context": "They picnicked by the pool, then lay back on the grass and looked at the stars.", "questions_and_answers": [{"answer_start": 15, "answer": "by the pool", "question": "Where did they picnic?"}, {"answer_start": 69, "answer": "the stars", "question": "What did the picnickers look at?"}]}, {"context": "When we speak about the number of words in the language, we are generally referring to word types.", "questions_and_answers": [{"answer_start": 87, "answer": "word types", "question": "When we talk about the number of words in a language, we are generally referring to what?"}]}, {"context": "Tokens = N Types = |V | Shakespeare 884 thousand 31 thousand Brown corpus 1 million 38 thousand Switchboard telephone conversations [ 2.4 ] million 20 thousand COCA 440 million 2 million Google n-grams 1 trillion 13 million Figure 2 .11 Rough numbers of types and tokens for some English language corpora. The largest, the Google n-grams corpus, contains 13 million types, but this count only includes types appearing 40 or more times, so the true number would be much larger.", "questions_and_answers": [{"answer_start": 74, "answer": "1 million 38 thousand", "question": "How many Brown corpus are there?"}, {"answer_start": 319, "answer": "the Google n-grams corpus", "question": "What is the largest English language corpora?"}]}, {"context": "Another measure of the number of words in the language is the number of lemmas instead of wordform types. Dictionaries can help in giving lemma counts; dictionary entries or boldface forms are a very rough upper bound on the number of lemmas (since some lemmas have multiple boldface forms). The 1989 edition of the Oxford English Dictionary had 615,000 entries.", "questions_and_answers": [{"answer_start": 58, "answer": "the number of lemmas", "question": "What is another measure of the number of words in a language?"}, {"answer_start": 152, "answer": "dictionary entries or boldface forms", "question": "What are a very rough upper bound on the number of lemmas?"}, {"answer_start": 346, "answer": "615,000", "question": "How many entries did the 1989 edition of the Oxford English Dictionary have?"}]}, {"context": "Words don't appear out of nowhere. Any particular piece of text that we study is produced by one or more specific speakers or writers, in a specific dialect of a specific language, at a specific time, in a specific place, for a specific function.", "questions_and_answers": [{"answer_start": 0, "answer": "Words", "question": "What doesn't appear out of nowhere?"}, {"answer_start": 93, "answer": "one or more specific speakers or writers", "question": "Who produces a particular piece of text that we study?"}]}, {"context": "Perhaps the most important dimension of variation is the language. NLP algorithms are most useful when they apply across many languages. The world has 7097 languages at the time of this writing, according to the online Ethnologue catalog (Simons and Fennig, 2018) . It is important to test algorithms on more than one language, and particularly on languages with different properties; by contrast there is an unfortunate current tendency for NLP algorithms to be developed or tested just on English (Bender, 2019) . Even when algorithms are developed beyond English, they tend to be developed for the official languages of large industrialized nations (Chinese, Spanish, Japanese, German etc. ), but we don't want to limit tools to just these few languages. Furthermore, most languages also have multiple varieties, often spoken in different regions or by different social groups. Thus, for example, if we're processing text that uses features of African American English (AAE) or AAE African American Vernacular English (AAVE) -the variations of English used by millions of people in African American communities (King 2020) -we must use NLP tools that function with features of those varieties. Twitter posts might use features often used by speakers of African American English, such as constructions like iont (I don't in Mainstream American English (MAE)), or talmbout corresponding MAE to MAE talking about, both examples that influence word segmentation (Blodgett et al. 2016 , Jones 2015 .", "questions_and_answers": [{"answer_start": 57, "answer": "language", "question": "What is the most important dimension of variation?"}, {"answer_start": 98, "answer": "when they apply across many languages", "question": "When are NLP algorithms most useful?"}, {"answer_start": 151, "answer": "7097", "question": "How many languages does the world have at the time of this writing?"}, {"answer_start": 491, "answer": "English", "question": "What language do NLP algorithms tend to be tested on?"}, {"answer_start": 653, "answer": "Chinese, Spanish, Japanese, German", "question": "What are some examples of countries where NLP algorithms are developed?"}, {"answer_start": 717, "answer": "limit tools to just these few languages", "question": "What do we not want to do when NLP algorithms are developed for the official languages of large industrialized nations?"}, {"answer_start": 796, "answer": "multiple varieties", "question": "What do most languages have?"}, {"answer_start": 947, "answer": "African American English", "question": "What does AAE stand for?"}, {"answer_start": 1197, "answer": "Twitter", "question": "What social network might use features often used by speakers of African American English?"}, {"answer_start": 1485, "answer": "Jones", "question": "Who published a study on NLP algorithms in 2015?"}]}, {"context": "It's also quite common for speakers or writers to use multiple languages in a single communicative act, a phenomenon called code switching. Code switching ([ 2.2 ]) Por primera vez veo a @username actually being hateful! it was beautiful:)", "questions_and_answers": [{"answer_start": 124, "answer": "code switching", "question": "What is the phenomenon that occurs when speakers or writers use multiple languages in a single communicative act?"}, {"answer_start": 187, "answer": "@username", "question": "What is actually being hateful?"}, {"answer_start": 228, "answer": "beautiful", "question": "What was the effect of code switching?"}]}, {"context": "[For the first time I get to see @username actually being hateful! it was beautiful:) ] ([ 2.3 ]) dost tha or ra-hega ... dont wory ... but dherya rakhe [\"he was and will remain a friend ... don't worry ...", "questions_and_answers": [{"answer_start": 58, "answer": "hateful", "question": "What was @username?"}, {"answer_start": 140, "answer": "dherya rakhe", "question": "What is the name of the friend that @username was and will remain a friend?"}]}, {"context": "Another dimension of variation is the genre. The text that our algorithms must process might come from newswire, fiction or non-fiction books, scientific articles, Wikipedia, or religious texts. It might come from spoken genres like telephone conversations, business meetings, police body-worn cameras, medical interviews, or transcripts of television shows or movies. It might come from work situations like doctors' notes, legal text, or parliamentary or congressional proceedings.", "questions_and_answers": [{"answer_start": 38, "answer": "genre", "question": "What is another dimension of variation?"}, {"answer_start": 103, "answer": "newswire", "question": "What type of text might our algorithms process?"}, {"answer_start": 233, "answer": "telephone conversations", "question": "What is an example of a spoken genre?"}, {"answer_start": 388, "answer": "work situations", "question": "What might the text that our algorithms process come from?"}]}, {"context": "Text also reflects the demographic characteristics of the writer (or speaker): their age, gender, race, socioeconomic class can all influence the linguistic properties of the text we are processing.", "questions_and_answers": [{"answer_start": 79, "answer": "their age, gender, race, socioeconomic class", "question": "What can all influence the linguistic properties of text?"}]}, {"context": "And finally, time matters too. Language changes over time, and for some languages we have good corpora of texts from different historical periods.", "questions_and_answers": [{"answer_start": 13, "answer": "time", "question": "What does language change over time?"}, {"answer_start": 31, "answer": "Language", "question": "What does change over time?"}]}, {"context": "Was the data collected with consent? How was the data pre-processed, and what metadata is available? Annotation process: What are the annotations, what are the demographics of the annotators, how were they trained, how was the data annotated? Distribution: Are there copyright or other intellectual property restrictions?", "questions_and_answers": [{"answer_start": 28, "answer": "consent", "question": "What was the data collected with?"}, {"answer_start": 73, "answer": "what metadata", "question": "What is available?"}, {"answer_start": 160, "answer": "demographics", "question": "What are the annotators?"}, {"answer_start": 286, "answer": "intellectual property", "question": "What type of restrictions are there in relation to distribution of data?"}]}, {"context": "Let's begin with an easy, if somewhat naive version of word tokenization and normalization (and frequency computation) that can be accomplished for English solely in a single UNIX command-line, inspired by Church (1994) . We'll make use of some Unix commands: tr, used to systematically change particular characters in the input; sort, which sorts input lines in alphabetical order; and uniq, which collapses and counts adjacent identical lines.", "questions_and_answers": [{"answer_start": 206, "answer": "Church", "question": "What was the name of the UNIX command-line that inspired the word tokenization and normalization?"}, {"answer_start": 260, "answer": "tr", "question": "What Unix command is used to change particular characters in the input?"}, {"answer_start": 387, "answer": "uniq", "question": "What collapses and counts adjacent identical lines?"}]}, {"context": "For example let's begin with the 'complete words' of Shakespeare in one file, sh.txt. We can use tr to tokenize the words by changing every sequence of nonalphabetic characters to a newline ('A-Za-z' means alphabetic, the -c option complements to non-alphabet, and the -s option squeezes all sequences into a single character): tr -sc 'A-Za-z' '\\n' < sh.txt", "questions_and_answers": [{"answer_start": 34, "answer": "complete words", "question": "What does Shakespeare's sh.txt begin with?"}, {"answer_start": 78, "answer": "sh.txt", "question": "What file contains the complete words of Shakespeare?"}, {"answer_start": 155, "answer": "alphabetic", "question": "What type of characters can be changed to a newline in sh.txt?"}, {"answer_start": 97, "answer": "tr", "question": "What can we use to tokenize the words by changing every sequence of nonalphabetic characters to a newline?"}]}, {"context": "Now that there is one word per line, we can sort the lines, and pass them to uniq -c which will collapse and count them: tr -sc 'A-Za-z' '\\n' < sh.txt | sort | uniq -c with the following output:", "questions_and_answers": [{"answer_start": 77, "answer": "uniq -c", "question": "What program will collapse and count the lines?"}, {"answer_start": 18, "answer": "one", "question": "How many words per line?"}]}, {"context": "tr -sc 'A-Za-z' '\\n' < sh.txt | tr A-Z a-z | sort | uniq -c whose output is 14725 a 97 aaron 1 abaissiez 10 abandon 2 abandoned 2 abase 1 abash 14 abate 3 abated 3 abatement ... Now we can sort again to find the frequent words. The -n option to sort means to sort numerically rather than alphabetically, and the -r option means to sort in reverse order (highest-to-lowest):", "questions_and_answers": [{"answer_start": 76, "answer": "14725", "question": "What is the output of uniq -c?"}, {"answer_start": 264, "answer": "numerically", "question": "The -n option to sort means to sort what rather than alphabetically?"}]}, {"context": "The results show that the most frequent words in Shakespeare, as in any other corpus, are the short function words like articles, pronouns, prepositions:", "questions_and_answers": [{"answer_start": 120, "answer": "articles, pronouns, prepositions", "question": "What are the most frequent short function words in Shakespeare?"}]}, {"context": "Unix tools of this sort can be very handy in building quick word count statistics for any corpus.", "questions_and_answers": [{"answer_start": 54, "answer": "quick word count statistics", "question": "Unix tools can be useful in building what for any corpus?"}]}, {"context": "The simple UNIX tools above were fine for getting rough word statistics but more sophisticated algorithms are generally necessary for tokenization, the task of segmenting running text into words.", "questions_and_answers": [{"answer_start": 134, "answer": "tokenization", "question": "What is the task of segmenting running text into words called?"}]}, {"context": "While the Unix command sequence just removed all the numbers and punctuation, for most NLP applications we\u2019ll need to keep these in our tokenization. We often want to break off punctuation as a separate token; commas are a useful piece of information for parsers, periods help indicate sentence boundaries. But we\u2019ll often want to keep the punctuation that occurs word internally, in examples like m.p.h., Ph.D., AT&T, and cap\u2019n. Special characters and numbers will need to be kept in prices ($45.55) and dates (01[ /02/ ]06); we don\u2019t want to segment that price into separate tokens of \u201c45\u201d and \u201c55\u201d. And there are URLs (http://www.stanford.edu), Twitter hashtags (#nlproc), or email addresses (someone@cs.colorado.edu).", "questions_and_answers": [{"answer_start": 45, "answer": "all the numbers and punctuation", "question": "What did the Unix command sequence remove?"}, {"answer_start": 210, "answer": "commas", "question": "What is a useful piece of information for parsers?"}, {"answer_start": 398, "answer": "m.p.h., Ph.D., AT&T, and cap\u2019n", "question": "What are examples of NLP applications where we want to keep the punctuation that occurs word internally?"}, {"answer_start": 494, "answer": "45.55", "question": "What is the price of AT&T?"}, {"answer_start": 696, "answer": "someone@cs.colorado.edu", "question": "What is an example of an email address?"}]}, {"context": "Number expressions introduce other complications as well; while commas normally appear at word boundaries, commas are used inside numbers in English, every three digits: 555,[ 500.50 ]. Languages, and hence tokenization requirements, differ on this; many continental European languages like Spanish, French, and German, by contrast, use a comma to mark the decimal point, and spaces (or sometimes periods) where English puts commas, for example, 555 500,50.", "questions_and_answers": [{"answer_start": 150, "answer": "every three digits", "question": "How often are commas used inside numbers in English?"}, {"answer_start": 170, "answer": "555,[ 500.50 ].", "question": "What is an example of a comma every three digits in English?"}, {"answer_start": 64, "answer": "comma", "question": "What do many continental European languages use to mark the decimal point?"}]}, {"context": "A tokenizer can also be used to expand clitic contractions that are marked by apostrophes, for example, converting what\u2019re to the two tokens what are, and we\u2019re to we are. A clitic is a part of a word that can\u2019t stand on its own, and can only occur when it is attached to another word. Some such contractions occur in other alphabetic languages, including articles and pronouns in French (j\u2019ai, l\u2019homme).", "questions_and_answers": [{"answer_start": 78, "answer": "apostrophes", "question": "What mark can be used to expand clitic contractions?"}, {"answer_start": 249, "answer": "when it is attached to another word", "question": "When can a clitic occur?"}, {"answer_start": 356, "answer": "articles and pronouns", "question": "What are examples of clitic contractions in French?"}]}, {"context": "Depending on the application, tokenization algorithms may also tokenize multiword expressions like New York or rock \u2019n\u2019 roll as a single token, which requires a multiword expression dictionary of some sort. Tokenization is thus intimately tied up with named entity recognition, the task of detecting names, dates, and organizations (Chapter 8).", "questions_and_answers": [{"answer_start": 161, "answer": "multiword expression dictionary", "question": "What type of dictionary is required to tokenize multiword expressions?"}, {"answer_start": 252, "answer": "named entity recognition", "question": "Tokenization is intimately tied to what?"}]}, {"context": "One commonly used tokenization standard is known as the Penn Treebank tokenization standard, used for the parsed corpora (treebanks) released by the Linguistic Data Consortium (LDC), the source of many useful datasets. This standard separates out clitics (doesn\u2019t becomes does plus n\u2019t), keeps hyphenated words together, and separates out all punctuation (to save space we\u2019re showing visible spaces \u2018 \u2019 between tokens, although newlines is a more common output):", "questions_and_answers": [{"answer_start": 145, "answer": "the Linguistic Data Consortium", "question": "What is the LDC?"}, {"answer_start": 56, "answer": "Penn Treebank tokenization standard", "question": "What is the common tokenization standard known as?"}, {"answer_start": 247, "answer": "clitics", "question": "What does the Penn Treebank tokenization standard separate out?"}]}, {"context": "Input: \"The San Francisco-based restaurant,\" they said, \"doesn't charge $10\". Output: \" The San Francisco-based restaurant , \" they said , \" does n't charge $ 10 \" .", "questions_and_answers": [{"answer_start": 72, "answer": "$10", "question": "What does the San Francisco-based restaurant not charge?"}, {"answer_start": 157, "answer": "$ 10", "question": "What does the San Francisco-based restaurant not charge?"}]}, {"context": "In practice, since tokenization needs to be run before any other language processing, it needs to be very fast. The standard method for tokenization is therefore to use deterministic algorithms based on regular expressions compiled into very efficient finite state automata. For example, Figure 2 .12 shows an example of a basic regular expression that can be used to tokenize with the nltk.regexp tokenize function of the Python-based Natural Language Toolkit (NLTK) (Bird et al. 2009;  http://www.nltk.org).", "questions_and_answers": [{"answer_start": 19, "answer": "tokenization", "question": "What needs to be run before any other language processing?"}, {"answer_start": 252, "answer": "finite state automata", "question": "What are deterministic algorithms compiled into?"}, {"answer_start": 423, "answer": "Python", "question": "What language is the NLTK based on?"}, {"answer_start": 481, "answer": "2009", "question": "When was the Python-based Natural Language Toolkit released?"}]}, {"context": ">>> text = 'That U.S.A. poster-print costs $12.40...' >>> pattern = r''' (?x) # set flag to allow verbose regexps . ['That', 'U.S.A. ', 'costs', '$12.40', '...'] Figure 2 .12 A Python trace of regular expression tokenization in the NLTK Python-based natural language processing toolkit (Bird et al., 2009) , commented for readability; the (?x) verbose flag tells Python to strip comments and whitespace.", "questions_and_answers": [{"answer_start": 43, "answer": "$12.40", "question": "How much does a poster-print cost in the U.S.?"}, {"answer_start": 117, "answer": "'That'", "question": "What is the verbose flag to allow verbose regexps?"}, {"answer_start": 232, "answer": "NLTK Python-based natural language processing toolkit", "question": "What is the name of the toolkit that allows regular expression tokenization?"}]}, {"context": "Carefully designed deterministic algorithms can deal with the ambiguities that arise, such as the fact that the apostrophe needs to be tokenized differently when used as a genitive marker (as in the book's cover), a quotative as in 'The other class', she said, or in clitics like they're.", "questions_and_answers": [{"answer_start": 214, "answer": "a quotative", "question": "What does the apostrophe need to be tokenized differently when used as a genitive marker?"}, {"answer_start": 170, "answer": "a genitive marker", "question": "The apostrophe needs to be tokenized differently when used as what?"}, {"answer_start": 214, "answer": "a quotative", "question": "What does the apostrophe need to be tokenized differently when used as a genitive marker?"}, {"answer_start": 214, "answer": "a quotative", "question": "What does the apostrophe need to be tokenized differently when used as a genitive marker?"}]}, {"context": "Word tokenization is more complex in languages like written Chinese, Japanese, and Thai, which do not use spaces to mark potential word-boundaries. In Chinese, for example, words are composed of characters (called hanzi in Chinese). Each hanzi character generally represents a single unit of meaning (called a morpheme) and is pronounceable as a single syllable. Words are about [ 2.4 ] characters long on average. But deciding what counts as a word in Chinese is complex. For example, consider the following sentence:", "questions_and_answers": [{"answer_start": 0, "answer": "Word tokenization", "question": "What is more complex in languages like written Chinese, Japanese, and Thai?"}, {"answer_start": 195, "answer": "characters", "question": "hanzi is composed of what?"}, {"answer_start": 308, "answer": "a morpheme", "question": "hanzi character generally represents a single unit of meaning called what?"}, {"answer_start": 373, "answer": "about [ 2.4 ] characters", "question": "How long are words on average?"}, {"answer_start": 26, "answer": "complex", "question": "What does deciding what counts as a word in Chinese mean?"}, {"answer_start": 509, "answer": "sentence", "question": "What is an example of a complex word in Chinese?"}]}, {"context": "As Chen et al. (2017b) point out, this could be treated as 3 words ('Chinese Treebank' segmentation):", "questions_and_answers": [{"answer_start": 3, "answer": "Chen et al.", "question": "Who pointed out that this could be treated as 3 words ('Chinese Treebank' segmentation)?"}, {"answer_start": 3, "answer": "Chen et al.", "question": "Who pointed out that this could be treated as 3 words ('Chinese Treebank' segmentation)?"}, {"answer_start": 3, "answer": "Chen et al.", "question": "Who pointed out that this could be treated as 3 words ('Chinese Treebank' segmentation)?"}, {"answer_start": 3, "answer": "Chen et al.", "question": "Who pointed out that this could be treated as 3 words ('Chinese Treebank' segmentation)?"}, {"answer_start": 69, "answer": "Chinese Treebank", "question": "What is another term for segmentation?"}, {"answer_start": 59, "answer": "3", "question": "How many words could be treated as Chinese Treebank segmentation?"}]}, {"context": "([ 2.6 ]) \u59da Yao \u660e Ming \u8fdb\u5165 reaches \u603b overall \u51b3\u8d5b finals Finally, it is possible in Chinese simply to ignore words altogether and use characters as the basic elements, treating the sentence as a series of 7 characters:", "questions_and_answers": [{"answer_start": 202, "answer": "7", "question": "How many characters are in a sentence?"}]}, {"context": "In fact, for most Chinese NLP tasks it turns out to work better to take characters rather than words as input, since characters are at a reasonable semantic level for most applications, and since most word standards, by contrast, result in a huge vocabulary with large numbers of very rare words (Li et al., 2019b) .", "questions_and_answers": [{"answer_start": 72, "answer": "characters", "question": "For most Chinese NLP tasks it turns out to work better to take what as input?"}]}, {"context": "However, for Japanese and Thai the character is too small a unit, and so algorithms for word segmentation are required. These can also be useful for Chinese word segmentation in the rare situations where word rather than character boundaries are required. The standard segmentation algorithms for these languages use neural sequence models trained via supervised machine learning on hand-segmented training sets; we'll introduce sequence models in Chapter 8 and Chapter 9.", "questions_and_answers": [{"answer_start": 13, "answer": "Japanese and Thai", "question": "For what languages is the character too small a unit?"}, {"answer_start": 149, "answer": "Chinese", "question": "In what language can algorithms for word segmentation be useful?"}, {"answer_start": 383, "answer": "hand-segmented training sets", "question": "What are the neural sequence models trained on?"}]}, {"context": "There is a third option to tokenizing text. Instead of defining tokens as words (whether delimited by spaces or more complex algorithms), or as characters (as in Chinese), we can use our data to automatically tell us what the tokens should be. This is especially useful in dealing with unknown words, an important problem in language processing. As we will see in the next chapter, NLP algorithms often learn some facts about language from one corpus (a training corpus) and then use these facts to make decisions about a separate test corpus and its language. Thus if our training corpus contains, say the words low, new, newer, but not lower, then if the word lower appears in our test corpus, our system will not know what to do with it.", "questions_and_answers": [{"answer_start": 11, "answer": "third", "question": "What is the third option to tokenizing text?"}, {"answer_start": 144, "answer": "characters", "question": "What are tokens defined as in Chinese?"}, {"answer_start": 286, "answer": "unknown words", "question": "What is an important problem in language processing?"}, {"answer_start": 454, "answer": "training corpus", "question": "What is another name for a corpus?"}, {"answer_start": 613, "answer": "low, new, newer, but not lower", "question": "What words do NLP algorithms learn from a training corpus?"}]}, {"context": "To deal with this unknown word problem, modern tokenizers often automatically induce sets of tokens that include tokens smaller than words, called subwords. subwords Subwords can be arbitrary substrings, or they can be meaning-bearing units like the morphemes -est or -er. (A morpheme is the smallest meaning-bearing unit of a language; for example the word unlikeliest has the morphemes un-, likely, and -est.) In modern tokenization schemes, most tokens are words, but some tokens are frequently occurring morphemes or other subwords like -er. Every unseen word like lower can thus be represented by some sequence of known subword units, such as low and er, or even as a sequence of individual letters if necessary.", "questions_and_answers": [{"answer_start": 147, "answer": "subwords", "question": "Modern tokenizers often induce sets of tokens that include tokens smaller than words called what?"}, {"answer_start": 260, "answer": "-est or -er", "question": "Subwords can be meaning-bearing units like what?"}, {"answer_start": 250, "answer": "morpheme", "question": "What is the smallest meaning-bearing unit of a language?"}, {"answer_start": 268, "answer": "-er", "question": "What is an example of a frequently occurring morpheme?"}, {"answer_start": 43, "answer": "er", "question": "What is an unseen word like lower that can be represented by a sequence of known subword units?"}]}, {"context": "Most tokenization schemes have two parts: a token learner, and a token segmenter. The token learner takes a raw training corpus (sometimes roughly preseparated into words, for example by whitespace) and induces a vocabulary, a set of tokens. The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary. Three algorithms are widely used: byte-pair encoding (Sennrich et al., 2016) , unigram language modeling (Kudo, 2018) , and WordPiece (Schuster and Nakajima, 2012) ; there is also a SentencePiece library that includes implementations of the first two of the three (Kudo and Richardson, 2018) .", "questions_and_answers": [{"answer_start": 44, "answer": "token learner, and a token segmenter", "question": "What are the two parts of most tokenization schemes?"}, {"answer_start": 211, "answer": "a vocabulary", "question": "What does the token learner induce?"}, {"answer_start": 65, "answer": "token segmenter", "question": "What takes a raw test sentence and segments it into the tokens in the vocabulary?"}, {"answer_start": 463, "answer": "WordPiece", "question": "What is the name of the tokenization scheme used by Schuster and Nakajima in 2012?"}]}, {"context": "In this section we introduce the simplest of the three, the byte-pair encoding or BPE algorithm (Sennrich et al., 2016) ; see Figure 2 .13. The BPE token learner begins BPE with a vocabulary that is just the set of all individual characters. It then examines the training corpus, chooses the two symbols that are most frequently adjacent (say 'A', 'B'), adds a new merged symbol 'AB' to the vocabulary, and replaces every adjacent 'A' 'B' in the corpus with the new 'AB'. It continues to count and merge, creating new longer and longer character strings, until k merges have been done creating k novel tokens; k is thus a parameter of the algorithm. The resulting vocabulary consists of the original set of characters plus k new symbols.", "questions_and_answers": [{"answer_start": 60, "answer": "byte-pair encoding", "question": "What is the simplest of the three BPE algorithms?"}, {"answer_start": 178, "answer": "a vocabulary", "question": "What does the BPE token learner begin BPE with?"}, {"answer_start": 380, "answer": "AB", "question": "What is the new merged symbol added to the vocabulary?"}, {"answer_start": 150, "answer": "k", "question": "How many merges have been done creating k novel tokens?"}, {"answer_start": 723, "answer": "k new symbols", "question": "The resulting vocabulary consists of the original set of characters plus what?"}]}, {"context": "The algorithm is usually run inside words (not merging across word boundaries), so the input corpus is first white-space-separated to give a set of strings, each corresponding to the characters of a word, plus a special end-of-word symbol , and its counts. Let's see its operation on the following tiny input corpus of 18 word tokens with counts for each word (the word low appears 5 times, the word newer 6 times, and so on), which would have a starting vocabulary of 11 letters", "questions_and_answers": [{"answer_start": 29, "answer": "inside words", "question": "Where is the algorithm run?"}, {"answer_start": 469, "answer": "11", "question": "How many letters would a starting vocabulary have?"}]}, {"context": "The BPE algorithm first counts all pairs of adjacent symbols: the most frequent is the pair e r because it occurs in newer (frequency of 6) and wider (frequency of 3) for a total of 9 occurrences 1 . We then merge these symbols, treating er as one symbol, and count again:", "questions_and_answers": [{"answer_start": 92, "answer": "e r", "question": "What is the most frequent pair of adjacent symbols?"}, {"answer_start": 208, "answer": "merge these symbols", "question": "How does the BPE algorithm treat er as one symbol?"}]}, {"context": "Now the most frequent pair is er , which we merge; our system has learned that there should be a token for word-final er, represented as er :", "questions_and_answers": [{"answer_start": 30, "answer": "er", "question": "What is the most frequent pair?"}, {"answer_start": 30, "answer": "er", "question": "What is the most frequent pair?"}, {"answer_start": 30, "answer": "er", "question": "What is the most frequent pair?"}, {"answer_start": 30, "answer": "er", "question": "What is the most frequent pair?"}]}, {"context": "Once we've learned our vocabulary, the token parser is used to tokenize a test sentence. The token parser just runs on the test data the merges we have learned from the training data, greedily, in the order we learned them. (Thus the frequencies in the test data don't play a role, just the frequencies in the training data). So first we segment each test sentence word into characters. Then we apply the first rule: replace every instance of e r in the test corpus with er, and then the second rule: replace every instance of er in the test corpus with er , and so on. By the end, if the test corpus contained the word n e w e r , it would be tokenized as a full word. But a new (unknown) word like l o w e r would be merged into the two tokens low er .", "questions_and_answers": [{"answer_start": 63, "answer": "tokenize a test sentence", "question": "What is the token parser used to do?"}, {"answer_start": 133, "answer": "the merges", "question": "What does the token parser run on?"}, {"answer_start": 230, "answer": "the frequencies in the test data", "question": "What doesn't play a role in the token parser?"}, {"answer_start": 375, "answer": "characters", "question": "What does the token parser segment each test sentence word into?"}, {"answer_start": 417, "answer": "replace every instance of e r in the test corpus with er", "question": "What is the first rule of the token parser?"}, {"answer_start": 620, "answer": "n e w e r", "question": "What would be tokenized as a full word if the test corpus contained the word?"}, {"answer_start": 700, "answer": "l o w e r", "question": "What new word would be merged into the two tokens low er?"}]}, {"context": "The token learner part of the BPE algorithm for taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.", "questions_and_answers": [{"answer_start": 4, "answer": "token learner", "question": "What part of the BPE algorithm is used for taking a corpus broken up into individual characters or bytes?"}]}, {"context": "Of course in real algorithms BPE is run with many thousands of merges on a very large input corpus. The result is that most words will be represented as full symbols, and only the very rare words (and unknown words) will have to be represented by their parts.", "questions_and_answers": [{"answer_start": 63, "answer": "merges", "question": "BPE is run with thousands of what on a large input corpus?"}, {"answer_start": 119, "answer": "most words will be represented as full symbols", "question": "What happens when BPE is run with thousands of merges on a large input corpus?"}]}, {"context": "Word normalization is the task of putting words/tokens in a standard format, choosing a single normal form for words with multiple forms like USA and US or uh-huh and uhhuh. This standardization may be valuable, despite the spelling information that is lost in the normalization process. For information retrieval or information extraction about the US, we might want to see information from documents whether they mention the US or the USA.", "questions_and_answers": [{"answer_start": 0, "answer": "Word normalization", "question": "What is the task of putting words/tokens in a standard format?"}, {"answer_start": 224, "answer": "spelling information", "question": "What is lost in the normalization process?"}, {"answer_start": 292, "answer": "information retrieval or information extraction", "question": "What are two things that we might want to see information from documents about the US?"}]}, {"context": "Case folding is another kind of normalization. Mapping everything to lowercase means that Woodchuck and woodchuck are represented identically, which is very helpful for generalization in many tasks, such as information retrieval or speech recognition. For sentiment analysis and other text classification tasks, information extraction, and machine translation, by contrast, case can be quite helpful and case folding is generally not done. This is because maintaining the difference between, for example, US the country and us the pronoun can outweigh the advantage in generalization that case folding would have provided for other words. For many natural language processing situations we also want two morphologically different forms of a word to behave similarly. For example in web search, someone may type the string woodchucks but a useful system might want to also return pages that mention woodchuck with no s. This is especially common in morphologically complex languages like Russian, where for example the word Moscow has different endings in the phrases Moscow, of Moscow, to Moscow, and so on.", "questions_and_answers": [{"answer_start": 0, "answer": "Case folding", "question": "What is another kind of normalization?"}, {"answer_start": 207, "answer": "information retrieval or speech recognition", "question": "What are two examples of tasks that use case folding?"}, {"answer_start": 256, "answer": "sentiment analysis and other text classification tasks, information extraction, and machine translation", "question": "For what tasks is case folding generally not done?"}, {"answer_start": 505, "answer": "US the country and us the pronoun", "question": "What can outweigh the advantage in generalization that case folding would have provided for other words?"}, {"answer_start": 700, "answer": "two morphologically different forms", "question": "For many natural language processing situations, we also want what of a word to behave similarly?"}, {"answer_start": 987, "answer": "Russian", "question": "What language has different endings in the phrases Moscow, of Moscow, to Moscow, and so on?"}]}, {"context": "Lemmatization is the task of determining that two words have the same root, despite their surface differences. The words am, are, and is have the shared lemma be; the words dinner and dinners both have the lemma dinner. Lemmatizing each of these forms to the same lemma will let us find all mentions of words in Russian like Moscow. The lemmatized form of a sentence like He is reading detective stories would thus be He be read detective story.", "questions_and_answers": [{"answer_start": 0, "answer": "Lemmatization", "question": "What is the task of determining that two words have the same root?"}, {"answer_start": 121, "answer": "am, are, and is", "question": "What words have the shared lemma be?"}, {"answer_start": 173, "answer": "dinner and dinners", "question": "What words have the lemma dinner?"}, {"answer_start": 325, "answer": "Moscow", "question": "What is the name of a Russian city that is lemmatized to the same lemma?"}, {"answer_start": 429, "answer": "detective story", "question": "What is the lemmatized form of a sentence like He is reading detective stories?"}]}, {"context": "How is lemmatization done? The most sophisticated methods for lemmatization involve complete morphological parsing of the word. Morphology is the study of the way words are built up from smaller meaning-bearing units called morphemes. Two broad classes of morphemes can be distinguished: stems-the central morpheme of the word, supplying the main meaning-and affixes-adding \"additional\" meanings of various kinds. So, for example, the word fox consists of one morpheme (the morpheme fox) and the word cats consists of two: the morpheme cat and the morpheme -s. A morphological parser takes a word like cats and parses it into the two morphemes cat and s, or parses a Spanish word like amaren ('if in the future they would love') into the morpheme amar 'to love', and the morphological features 3PL and future subjunctive.", "questions_and_answers": [{"answer_start": 7, "answer": "lemmatization", "question": "What is done when a word is morphologically parsed?"}, {"answer_start": 84, "answer": "complete morphological parsing", "question": "What is the most sophisticated method for lemmatization?"}, {"answer_start": 128, "answer": "Morphology", "question": "What is the study of the way words are built up from smaller meaning-bearing units called morphemes?"}, {"answer_start": 288, "answer": "stems", "question": "What is the central morpheme of a word?"}, {"answer_start": 440, "answer": "fox", "question": "What word consists of one morpheme?"}]}, {"context": "Lemmatization algorithms can be complex. For this reason we sometimes make use of a simpler but cruder method, which mainly consists of chopping off word-final affixes. This naive version of morphological analysis is called stemming. One of stemming the most widely used stemming algorithms is the Porter (1980) . The Porter stemmer stemmer applied to the following paragraph:", "questions_and_answers": [{"answer_start": 0, "answer": "Lemmatization algorithms", "question": "What can be complex?"}, {"answer_start": 136, "answer": "chopping off word-final affixes", "question": "Lemmatization algorithms mainly consist of what?"}, {"answer_start": 224, "answer": "stemming", "question": "What is the naive version of morphological analysis called?"}, {"answer_start": 294, "answer": "the Porter", "question": "What is the most widely used stemming algorithm?"}, {"answer_start": 314, "answer": "The Porter stemmer stemmer", "question": "What is applied to the following paragraph?"}]}, {"context": "This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things-names and heights and soundings-with the single exception of the red crosses and the written notes.", "questions_and_answers": [{"answer_start": 58, "answer": "an accurate copy", "question": "What was the map we found in Billy Bones's chest?"}]}, {"context": "Thi wa not the map we found in Billi Bone s chest but an accur copi complet in all thing name and height and sound with the singl except of the red cross and the written note", "questions_and_answers": [{"answer_start": 140, "answer": "the red cross", "question": "What is the only thing missing from the map in Billi Bone s chest?"}, {"answer_start": 54, "answer": "an accur copi complet", "question": "What did we find in Billi Bone s chest?"}]}, {"context": "Detailed rule lists for the Porter stemmer, as well as code (in Java, Python, etc.) can be found on Martin Porter's homepage; see also the original paper (Porter, 1980) . Simple stemmers can be useful in cases where we need to collapse across different variants of the same lemma. Nonetheless, they do tend to commit errors of both over-and under-generalizing, as shown in the table below (Krovetz, 1993", "questions_and_answers": [{"answer_start": 64, "answer": "Java, Python, etc.", "question": "In what languages can code be found on Martin Porter's homepage?"}, {"answer_start": 100, "answer": "Martin Porter's homepage", "question": "Where can detailed rule lists for the Porter stemmer, as well as code (in Java, Python, etc.) be found?"}, {"answer_start": 171, "answer": "Simple stemmers", "question": "What can be useful in cases where we need to collapse across different variants of the same lemma?"}, {"answer_start": 332, "answer": "over-and under-generalizing", "question": "What errors do simple stemmers commit?"}]}, {"context": "Sentence segmentation is another important step in text processing. The most useful cues for segmenting a text into sentences are punctuation, like periods, question marks, and exclamation points. Question marks and exclamation points are relatively unambiguous markers of sentence boundaries. Periods, on the other hand, are more ambiguous. The period character \".\" is ambiguous between a sentence boundary marker and a marker of abbreviations like Mr. or Inc. The previous sentence that you just read showed an even more complex case of this ambiguity, in which the final period of Inc. marked both an abbreviation and the sentence boundary marker. For this reason, sentence tokenization and word tokenization may be addressed jointly.", "questions_and_answers": [{"answer_start": 0, "answer": "Sentence segmentation", "question": "What is another important step in text processing?"}, {"answer_start": 130, "answer": "punctuation", "question": "What is one of the most useful cues for segmenting a text into sentences?"}, {"answer_start": 197, "answer": "Question marks and exclamation points", "question": "What are relatively unambiguous markers of sentence boundaries?"}, {"answer_start": 294, "answer": "Periods", "question": "What is more ambiguous than question marks and exclamation points?"}, {"answer_start": 346, "answer": "period character", "question": "What character is ambiguous between a sentence boundary marker and a marker of abbreviations like Mr. or Inc?"}, {"answer_start": 450, "answer": "Mr. or Inc", "question": "What are two abbreviations that are ambiguous between a sentence boundary marker and a marker of abbreviations?"}, {"answer_start": 564, "answer": "the final period of Inc.", "question": "What marked both an abbreviation and the sentence boundary marker?"}, {"answer_start": 677, "answer": "tokenization", "question": "What may be addressed jointly?"}]}, {"context": "In general, sentence tokenization methods work by first deciding (based on rules or machine learning) whether a period is part of the word or is a sentence-boundary marker. An abbreviation dictionary can help determine whether the period is part of a commonly used abbreviation; the dictionaries can be hand-built or machinelearned (Kiss and Strunk, 2006) , as can the final sentence splitter. In the Stanford CoreNLP toolkit (Manning et al., 2014) , for example sentence splitting is rule-based, a deterministic consequence of tokenization; a sentence ends when a sentence-ending punctuation (., !, or ?) is not already grouped with other characters into a token (such as for an abbreviation or number), optionally followed by additional final quotes or brackets.", "questions_and_answers": [{"answer_start": 110, "answer": "a period", "question": "What is part of a word or a sentence-boundary marker?"}, {"answer_start": 350, "answer": "2006", "question": "In what year did Smith and Strunk publish dictionaries that can be machinelearned or hand-built?"}, {"answer_start": 401, "answer": "Stanford CoreNLP toolkit", "question": "In what toolkit is sentence splitting rule-based?"}, {"answer_start": 705, "answer": "optionally followed by additional final quotes or brackets", "question": "What happens when a sentence-ending punctuation is not already grouped with other characters into a token?"}]}, {"context": "Much of natural language processing is concerned with measuring how similar two strings are. For example in spelling correction, the user typed some erroneous string\u2014let\u2019s say graffe\u2013and we want to know what the user meant. The user probably intended a word that is similar to graffe. Among candidate similar words, the word giraffe, which differs by only one letter from graffe, seems intuitively to be more similar than, say grail or graf, which differ in more letters. Another example comes from coreference, the task of deciding whether two strings such as the following refer to the same entity:", "questions_and_answers": [{"answer_start": 54, "answer": "measuring how similar two strings are", "question": "What is much of natural language processing concerned with?"}, {"answer_start": 176, "answer": "graffe", "question": "What is an example of an erroneous string in spelling correction?"}, {"answer_start": 176, "answer": "graffe", "question": "What is a similar word to a graffe?"}, {"answer_start": 325, "answer": "giraffe", "question": "What word differs by only one letter from graffe?"}, {"answer_start": 499, "answer": "coreference", "question": "What is the task of deciding whether two strings refer to the same entity?"}]}, {"context": "Again, the fact that these two strings are very similar (differing by only one word) seems like useful evidence for deciding that they might be coreferent. Edit distance gives us a way to quantify both of these intuitions about string similarity. More formally, the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.", "questions_and_answers": [{"answer_start": 75, "answer": "one", "question": "How many words do the two strings differ by?"}, {"answer_start": 156, "answer": "Edit distance", "question": "What gives us a way to quantify both of these intuitions about string similarity?"}, {"answer_start": 326, "answer": "minimum number of editing operations", "question": "What is the minimum edit distance between two strings?"}]}, {"context": "We can also assign a particular cost or weight to each of these operations. The Levenshtein distance between two sequences is the simplest weighting factor in which each of the three operations has a cost of 1 (Levenshtein, 1966)-we assume that the substitution of a letter for itself, for example, t for t, has zero cost. The Levenshtein distance between intention and execution is 5. Levenshtein also proposed an alternative version of his metric in which each insertion or deletion has a cost of 1 and substitutions are not allowed. (This is equivalent to allowing substitution, but giving each substitution a cost of 2 since any substitution can be represented by one insertion and one deletion). Using this version, the Levenshtein distance between intention and execution is 8.", "questions_and_answers": [{"answer_start": 19, "answer": "a particular cost or weight", "question": "What can we assign to each of these operations?"}, {"answer_start": 80, "answer": "Levenshtein", "question": "What is the simplest weighting factor in which each of the three operations has a cost of 1?"}, {"answer_start": 383, "answer": "5.", "question": "What is the Levenshtein distance between intention and execution?"}, {"answer_start": 505, "answer": "substitutions are not allowed", "question": "What did Levenshtein propose in his version of the Levenshtein distance between intention and execution?"}, {"answer_start": 559, "answer": "allowing substitution", "question": "What is the Levenshtein distance between intention and execution equivalent to?"}, {"answer_start": 781, "answer": "8.", "question": "What is the Levenshtein distance between intention and execution?"}]}, {"context": "How do we find the minimum edit distance? We can think of this as a search task, in which we are searching for the shortest path-a sequence of edits-from one string to another.", "questions_and_answers": [{"answer_start": 19, "answer": "minimum edit distance", "question": "How do we find the minimum edit distance?"}, {"answer_start": 66, "answer": "a search task", "question": "How do we find the minimum edit distance?"}, {"answer_start": 129, "answer": "a sequence of edits", "question": "What is the shortest path from one string to another?"}]}, {"context": "The space of all possible edits is enormous, so we can't search naively. However, lots of distinct edit paths will end up in the same state (string), so rather than recomputing all those paths, we could just remember the shortest path to a state each time we saw it. We can do this by using dynamic programming. Dynamic programming dynamic programming is the name for a class of algorithms, first introduced by Bellman (1957) , that apply a table-driven method to solve problems by combining solutions to sub-problems. Some of the most commonly used algorithms in natural language processing make use of dynamic programming, such as the Viterbi algorithm (Chapter 8) and the CKY algorithm for parsing (Chapter 13) .", "questions_and_answers": [{"answer_start": 35, "answer": "enormous", "question": "The space of all possible edits is what?"}, {"answer_start": 125, "answer": "the same state", "question": "Lots of distinct edit paths will end up in what?"}, {"answer_start": 291, "answer": "dynamic programming", "question": "What is the name for a class of algorithms that apply a table-driven method to solve problems by combining solutions to sub-problems?"}, {"answer_start": 411, "answer": "Bellman", "question": "Who first introduced dynamic programming?"}, {"answer_start": 420, "answer": "1957", "question": "When was dynamic programming first introduced?"}, {"answer_start": 675, "answer": "CKY", "question": "What is the name of the algorithm used for parsing?"}]}, {"context": "The intuition of a dynamic programming problem is that a large problem can be solved by properly combining the solutions to various sub-problems. Consider the shortest path of transformed words that represents the minimum edit distance between the strings intention and execution shown in Figure [ 2.16 ] .", "questions_and_answers": [{"answer_start": 85, "answer": "by properly combining the solutions to various sub-problems", "question": "How can a large problem be solved?"}, {"answer_start": 155, "answer": "the shortest path", "question": "What represents the minimum edit distance between strings intention and execution?"}]}, {"context": "The minimum edit distance algorithm algorithm was named by Wagner and Fischer (1974) but independently discovered by many people (see the Historical Notes section of Chapter 8).", "questions_and_answers": [{"answer_start": 59, "answer": "Wagner and Fischer", "question": "Who named the minimum edit distance algorithm?"}, {"answer_start": 79, "answer": "1974", "question": "When was the minimum edit distance algorithm named?"}]}, {"context": "Let's first define the minimum edit distance between two strings. Given two strings, the source string X of length n, and target string Y of length m, we'll define D [i, j] as the edit distance between X[1..i] and Y [1.. j], i.e., the first i characters of X and the first j characters of Y . The edit distance between X and Y is thus D [n, m] .", "questions_and_answers": [{"answer_start": 23, "answer": "minimum edit distance", "question": "What is the minimum edit distance between two strings?"}, {"answer_start": 164, "answer": "D [i, j]", "question": "What is the edit distance between X[1..i] and Y[1..j]?"}, {"answer_start": 335, "answer": "D [n, m]", "question": "What is the edit distance between X and Y?"}]}, {"context": "We'll use dynamic programming to compute D[n, m] bottom up, combining solutions to subproblems. In the base case, with a source substring of length i but an empty target string, going from i characters to 0 requires i deletes. With a target substring of length j but an empty source going from 0 characters to j characters requires j inserts. Having computed D[i, j] for small i, j we then compute larger D[i, j] based on previously computed smaller values. The value of D[i, j] is computed by taking the minimum of the three possible paths through the matrix which arrive there:", "questions_and_answers": [{"answer_start": 10, "answer": "dynamic programming", "question": "What will we use to compute D[n, m] bottom up?"}, {"answer_start": 216, "answer": "i deletes", "question": "What does going from i characters to 0 require?"}, {"answer_start": 332, "answer": "j inserts", "question": "What does a target substring of length j require when going from 0 characters to j characters?"}, {"answer_start": 422, "answer": "previously computed smaller values", "question": "What do we compute larger D[i, j] based on?"}, {"answer_start": 491, "answer": "by taking the minimum of the three possible paths", "question": "How is the value of D[i, j] computed?"}]}, {"context": "If we assume the version of Levenshtein distance in which the insertions and deletions each have a cost of 1 (ins-cost([ \u2022 ]) = del-cost([ \u2022 ]) = 1), and substitutions have a cost of 2 (except substitution of identical letters have zero cost), the computation for D [i, j] becomes:", "questions_and_answers": [{"answer_start": 154, "answer": "substitutions", "question": "What has a cost of 2?"}, {"answer_start": 107, "answer": "1", "question": "What is the cost of insertions and deletions in a Levenshtein distance?"}]}, {"context": "Knowing the minimum edit distance is useful for algorithms like finding potential spelling error corrections. But the edit distance algorithm is important in another way; with a small change, it can also provide the minimum cost alignment between two strings. Aligning two strings is useful throughout speech and language processing. In speech recognition, minimum edit distance alignment is used to compute the word error rate (Chapter 26). Alignment plays a role in machine translation, in which sentences in a parallel corpus (a corpus with a text in two languages) need to be matched to each other.", "questions_and_answers": [{"answer_start": 82, "answer": "spelling error corrections", "question": "What is the minimum edit distance useful for?"}, {"answer_start": 212, "answer": "the minimum cost alignment between two strings", "question": "What can the edit distance algorithm provide with a small change?"}, {"answer_start": 260, "answer": "Aligning two strings", "question": "What is useful throughout speech and language processing?"}, {"answer_start": 397, "answer": "to compute the word error rate", "question": "What is the use of minimum edit distance alignment in speech recognition?"}, {"answer_start": 468, "answer": "machine translation", "question": "Alignment plays a role in what?"}]}, {"context": "The minimum edit distance algorithm, an example of the class of dynamic programming algorithms. The various costs can either be fixed (e.g., \u2200x, ins-cost(x) = 1) or can be specific to the letter (to model the fact that some letters are more likely to be inserted than others). We assume that there is no cost for substituting a letter for itself (i.e., sub-cost(x, x) = 0).", "questions_and_answers": [{"answer_start": 4, "answer": "minimum edit distance algorithm", "question": "What is an example of the class of dynamic programming algorithms?"}, {"answer_start": 128, "answer": "fixed", "question": "What can the costs of the minimum edit distance algorithm be?"}, {"answer_start": 353, "answer": "sub-cost(x, x) = 0", "question": "What is the assumption that there is no cost for substituting a letter for itself?"}]}, {"context": "Figure [ 2.18 ] Computation of minimum edit distance between intention and execution with the algorithm of Figure 2 .17, using Levenshtein distance with cost of 1 for insertions or deletions, 2 for substitutions.", "questions_and_answers": [{"answer_start": 127, "answer": "Levenshtein", "question": "What distance is used to calculate the minimum edit distance between intention and execution?"}]}, {"context": "Figure 2 .19 When entering a value in each cell, we mark which of the three neighboring cells we came from with up to three arrows. After the table is full we compute an alignment (minimum edit path) by using a backtrace, starting at the 8 in the lower-right corner and following the arrows back. The sequence of bold cells represents one possible minimum cost alignment between the two strings. Diagram design after Gusfield (1997).", "questions_and_answers": [{"answer_start": 70, "answer": "three", "question": "How many neighboring cells are there in Figure 2.19?"}, {"answer_start": 200, "answer": "by using a backtrace", "question": "How do we compute an alignment after the table is full?"}, {"answer_start": 335, "answer": "one possible minimum cost alignment between the two strings", "question": "What does the sequence of bold cells represent?"}, {"answer_start": 427, "answer": "1997", "question": "When was Gusfield born?"}]}, {"context": "This chapter introduced a fundamental tool in language processing, the regular expression, and showed how to perform basic text normalization tasks including word segmentation and normalization, sentence segmentation, and stemming. We also introduced the important minimum edit distance algorithm for comparing strings. Here's a summary of the main points we covered about these ideas:", "questions_and_answers": [{"answer_start": 71, "answer": "regular expression", "question": "What is a fundamental tool in language processing?"}, {"answer_start": 222, "answer": "stemming", "question": "What is a basic text normalization task?"}, {"answer_start": 265, "answer": "minimum edit distance algorithm", "question": "What algorithm was introduced for comparing strings?"}, {"answer_start": 329, "answer": "summary", "question": "What is a summary of the main points we covered in this chapter?"}]}, {"context": "[ \u2022 ] Word tokenization and normalization are generally done by cascades of simple regular expression substitutions or finite automata.", "questions_and_answers": [{"answer_start": 6, "answer": "Word tokenization and normalization", "question": "What are generally done by cascades of simple regular expression substitutions or finite automata?"}, {"answer_start": 119, "answer": "finite automata", "question": "Word tokenization and normalization are generally done by cascades of simple regular expression substitutions or what?"}]}, {"context": "[ \u2022 ] The Porter algorithm is a simple and efficient way to do stemming, stripping off affixes. It does not have high accuracy but may be useful for some tasks.", "questions_and_answers": [{"answer_start": 6, "answer": "The Porter algorithm", "question": "What is a simple and efficient way to do stemming?"}, {"answer_start": 113, "answer": "high accuracy", "question": "The Porter algorithm does not have what?"}]}, {"context": "[ \u2022 ] The minimum edit distance between two strings is the minimum number of operations it takes to edit one into the other. Minimum edit distance can be computed by dynamic programming, which also results in an alignment of the two strings.", "questions_and_answers": [{"answer_start": 59, "answer": "minimum number of operations", "question": "What is the minimum edit distance between two strings?"}, {"answer_start": 166, "answer": "dynamic programming", "question": "How can the minimum edit distance between two strings be computed?"}]}, {"context": "Kleene 1951; 1956 first defined regular expressions and the finite automaton, based on the McCulloch-Pitts neuron. Ken Thompson was one of the first to build regular expressions compilers into editors for text searching (Thompson, 1968) . His editor ed included a command \"g[ /regular expression/ ]p\", or Global Regular Expression Print, which later became the Unix grep utility. Text normalization algorithms have been applied since the beginning of the field. One of the earliest widely used stemmers was Lovins (1968) . Stemming was also applied early to the digital humanities, by Packard (1973) , who built an affix-stripping morphological parser for Ancient Greek. Currently a wide variety of code for tokenization and normalization is available, such as the Stanford Tokenizer (http:/[ /nlp.stanford.edu/ ]software[ /tokenizer.shtml) or specialized tokenizers for Twitter (O'Connor et al., 2010) , or for sentiment (http: / ][ /sentiment.christopherpotts.net/ ]tokenizing.html). See Palmer (2012) for a survey of text preprocessing. NLTK is an essential tool that offers both useful Python libraries (http://www.nltk.org) and textbook descriptions (Bird et al., 2009 ) of many algorithms including text normalization and corpus interfaces.", "questions_and_answers": [{"answer_start": 13, "answer": "1956", "question": "When did Kleene define regular expressions and the finite automaton?"}, {"answer_start": 115, "answer": "Ken Thompson", "question": "Who was one of the first to build regular expressions compilers into editors for text searching?"}, {"answer_start": 305, "answer": "Global Regular Expression Print", "question": "What is g[ /regular expression/ ]p?"}, {"answer_start": 380, "answer": "Text normalization algorithms", "question": "What has been applied since the beginning of the field?"}, {"answer_start": 231, "answer": "1968", "question": "When was Lovins first widely used stemmers?"}, {"answer_start": 585, "answer": "Packard", "question": "Who built an affix-stripping morphological parser for Ancient Greek?"}, {"answer_start": 765, "answer": "Stanford Tokenizer", "question": "What is the name of the code available for tokenization and normalization?"}, {"answer_start": 990, "answer": "Palmer", "question": "Who published a survey of text preprocessing?"}, {"answer_start": 1090, "answer": "Python libraries", "question": "What does NLTK offer?"}]}, {"context": "For more on Herdan's law and Heaps' Law, see Herdan (1960 , p. 28), Heaps (1978 , Egghe (2007) and Baayen (2001) ; Yasseri et al. (2012) discuss the relationship with other measures of linguistic complexity. For more on edit distance, see the excellent Gusfield (1997) . Our example measuring the edit distance from 'intention' to 'execution' was adapted from Kruskal (1983) . There are various publicly available packages to compute edit distance, including Unix diff and the NIST sclite program (NIST, 2005) .", "questions_and_answers": [{"answer_start": 12, "answer": "Herdan's law and Heaps' Law", "question": "What are two examples of the relationship between edit distance and linguistic complexity?"}, {"answer_start": 185, "answer": "linguistic complexity", "question": "Yasseri et al. (2012) discuss the relationship with other measures of what?"}, {"answer_start": 253, "answer": "Gusfield", "question": "What is the name of the author of 1997's work on edit distance?"}, {"answer_start": 369, "answer": "1983", "question": "When was Kruskal written?"}, {"answer_start": 459, "answer": "Unix diff and the NIST sclite program", "question": "What are two examples of publicly available packages to compute edit distance?"}]}, {"context": "In his autobiography Bellman (1984) explains how he originally came up with the term dynamic programming:", "questions_and_answers": [{"answer_start": 30, "answer": "1984", "question": "When was Bellman's autobiography published?"}]}, {"context": "\"...The 1950s were not good years for mathematical research. [the] Secretary of Defense ...had a pathological fear and hatred of the word, research... I decided therefore to use the word, \"programming\". I wanted to get across the idea that this was dynamic, this was multistage... I thought, let's ... take a word that has an absolutely precise meaning, namely dynamic... it's impossible to use the word, dynamic, in a pejorative sense. Try thinking of some combination that will possibly give it a pejorative meaning. It's impossible. Thus, I thought dynamic programming was a good name. It was something not even a Congressman could object to.\"", "questions_and_answers": [{"answer_start": 8, "answer": "1950s", "question": "When were not good years for mathematical research?"}, {"answer_start": 51, "answer": "research", "question": "What word did the Secretary of Defense have a pathological fear and hatred of?"}, {"answer_start": 189, "answer": "programming", "question": "What word did the Secretary of Defense decide to use?"}, {"answer_start": 267, "answer": "multistage", "question": "What did the Secretary of Defense want to get across by using the word \"programming\"?"}, {"answer_start": 249, "answer": "dynamic", "question": "What is the word that has an absolutely precise meaning?"}, {"answer_start": 419, "answer": "pejorative", "question": "What kind of meaning is it impossible to give the word dynamic?"}, {"answer_start": 377, "answer": "impossible", "question": "I thought dynamic programming was something not even a Congressman could object to?"}, {"answer_start": 552, "answer": "dynamic programming", "question": "What did I think was a good name?"}, {"answer_start": 617, "answer": "Congressman", "question": "Who could object to dynamic programming?"}]}, {"context": "\"You are uniformly charming!\" cried he, with a smile of associating and now and then I bowed and they perceived a chaise and four to wish for. Random sentence generated from a Jane Austen trigram model", "questions_and_answers": [{"answer_start": 9, "answer": "uniformly charming", "question": "What was Jane Austen's character?"}, {"answer_start": 125, "answer": "four", "question": "How many chaises did they wish for?"}, {"answer_start": 176, "answer": "Jane Austen", "question": "Random sentence generated from what trigram model?"}]}, {"context": "Predicting is difficult-especially about the future, as the old quip goes. But how about predicting something that seems much easier, like the next few words someone is going to say? What word, for example, is likely to follow", "questions_and_answers": [{"answer_start": 0, "answer": "Predicting", "question": "What is difficult, especially about the future?"}, {"answer_start": 139, "answer": "the next few words", "question": "What is an example of a word that is easy to predict?"}, {"answer_start": 152, "answer": "word", "question": "What is likely to follow a person's next words?"}]}, {"context": "Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the. In the following sections we will formalize this intuition by introducing models that assign a probability to each possible next word. The same models will also serve to assign a probability to an entire sentence. Such a model, for example, could predict that the following sequence has a much higher probability of appearing in a text:", "questions_and_answers": [{"answer_start": 99, "answer": "refrigerator", "question": "What is the most likely word to be in, or possibly over, but probably not?"}, {"answer_start": 194, "answer": "models", "question": "What will formalize this intuition by introducing?"}, {"answer_start": 317, "answer": "entire sentence", "question": "The same models will also serve to assign a probability to what?"}, {"answer_start": 414, "answer": "higher", "question": "What is the probability of appearing in a text predicted by a model?"}]}, {"context": "Why would you want to predict upcoming words, or assign probabilities to sentences? Probabilities are essential in any task in which we have to identify words in noisy, ambiguous input, like speech recognition. For a speech recognizer to realize that you said I will be back soonish and not I will be bassoon dish, it helps to know that back soonish is a much more probable sequence than bassoon dish. For writing tools like spelling correction or grammatical error correction, we need to find and correct errors in writing like Their are two midterms, in which There was mistyped as Their, or Everything has improve, in which improve should have been improved. The phrase There are will be much more probable than Their are, and has improved than has improve, allowing us to help users by detecting and correcting these errors.", "questions_and_answers": [{"answer_start": 49, "answer": "assign probabilities", "question": "Why would you want to predict upcoming words?"}, {"answer_start": 84, "answer": "Probabilities", "question": "What are essential in any task in which we have to identify words in noisy, ambiguous input?"}, {"answer_start": 270, "answer": "back soonish", "question": "What is a much more probable sequence than bassoon dish?"}, {"answer_start": 529, "answer": "Their are two midterms", "question": "What is an example of an error in writing that needs to be corrected?"}, {"answer_start": 673, "answer": "There are", "question": "What phrase will be more probable than Their are?"}]}, {"context": "Assigning probabilities to sequences of words is also essential in machine translation. Suppose we are translating a Chinese source sentence:", "questions_and_answers": [{"answer_start": 67, "answer": "machine translation", "question": "Assigning probabilities to sequences of words is essential in what?"}, {"answer_start": 117, "answer": "Chinese", "question": "Suppose we are translating a source sentence in what language?"}]}, {"context": "As part of the process we might have built the following set of potential rough English translations:", "questions_and_answers": [{"answer_start": 74, "answer": "rough English translations", "question": "What might have been built as part of the process?"}]}, {"context": "A probabilistic model of word sequences could suggest that briefed reporters on is a more probable English phrase than briefed to reporters (which has an awkward to after briefed) or introduced reporters to (which uses a verb that is less fluent English in this context), allowing us to correctly select the boldfaced sentence above.", "questions_and_answers": [{"answer_start": 308, "answer": "boldfaced", "question": "What type of sentence above could be correctly selected?"}]}, {"context": "Probabilities are also important for augmentative and alternative communication systems (Trnka et al. 2007 , Kane et al. 2017 . People often use such AAC devices if they are physically unable to speak or sign but can instead use eye gaze or other specific movements to select words from a menu to be spoken by the system. Word prediction can be used to suggest likely words for the menu.", "questions_and_answers": [{"answer_start": 0, "answer": "Probabilities", "question": "What is important for augmentative and alternative communication systems?"}, {"answer_start": 109, "answer": "Kane", "question": "Who et al. 2017 cited the importance of probabilities in augmentative and alternative communication systems?"}, {"answer_start": 121, "answer": "2017", "question": "What year did Kane and Trnka publish their work on AAC devices?"}, {"answer_start": 229, "answer": "eye gaze", "question": "What can people use to select words from a menu to be spoken by the system?"}, {"answer_start": 322, "answer": "Word prediction", "question": "What can be used to suggest likely words for the menu?"}]}, {"context": "Models that assign probabilities to sequences of words are called language models or LMs. In this chapter we introduce the simplest model that assigns probabilities to sentences and sequences of words, the n-gram. An n-gram is a sequence of n words: a 2-gram (which we'll call bigram) is a two-word sequence of words like \"please turn\", \"turn your\", or \"your homework\", and a 3-gram (a trigram) is a three-word sequence of words like \"please turn your\", or \"turn your homework\". We'll see how to use n-gram models to estimate the probability of the last word of an n-gram given the previous words, and also to assign probabilities to entire sequences. In a bit of terminological ambiguity, we usually drop the word \"model\", and use the term n-gram (and bigram, etc.) to mean either the word sequence itself or the predictive model that assigns it a probability. While n-gram models are much simpler than state-of-the art neural language models based on the RNNs and transformers we will introduce in Chapter 9, they are an important foundational tool for understanding the fundamental concepts of language modeling.", "questions_and_answers": [{"answer_start": 66, "answer": "language models", "question": "Models that assign probabilities to sequences of words are called what?"}, {"answer_start": 206, "answer": "n-gram", "question": "What is the simplest model that assigns probabilities to sentences and sequences of words?"}, {"answer_start": 17, "answer": "n", "question": "What is an n-gram?"}, {"answer_start": 500, "answer": "n-gram models", "question": "What is used to estimate the probability of the last word of an n-gram given the previous words?"}, {"answer_start": 206, "answer": "n-gram", "question": "In terminological ambiguity, what term is used to mean the word sequence itself or the predictive model that assigns it a probability?"}, {"answer_start": 782, "answer": "the word sequence itself or the predictive model", "question": "What does the term n-gram mean?"}, {"answer_start": 500, "answer": "n-gram models", "question": "What is an important foundational tool for understanding the fundamental concepts of language modeling?"}]}, {"context": "Let's begin with the task of computing P(w|h), the probability of a word w given some history h. Suppose the history h is \"its water is so transparent that\" and we want to know the probability that the next word is the:", "questions_and_answers": [{"answer_start": 123, "answer": "its water is so transparent", "question": "What is the history h?"}]}, {"context": "One way to estimate this probability is from relative frequency counts: take a very large corpus, count the number of times we see its water is so transparent that, and count the number of times this is followed by the. This would be answering the question \"Out of the times we saw the history h, how many times was it followed by the word w\", as follows:", "questions_and_answers": [{"answer_start": 45, "answer": "relative frequency counts", "question": "What is one way to estimate this probability?"}, {"answer_start": 297, "answer": "how many times", "question": "How many times was the history h followed by the word w?"}]}, {"context": "P(the|its water is so transparent that) = C(its water is so transparent that the) C(its water is so transparent that) ([ 3.2 ])", "questions_and_answers": [{"answer_start": 82, "answer": "C(its water is so transparent that)", "question": "What does P(its water is so transparent that) = C(its water is so transparent that the) mean?"}]}, {"context": "With a large enough corpus, such as the web, we can compute these counts and estimate the probability from Eq. [ 3.2 ]. You should pause now, go to the web, and compute this estimate for yourself.", "questions_and_answers": [{"answer_start": 36, "answer": "the web", "question": "What is an example of a large enough corpus to compute counts?"}, {"answer_start": 113, "answer": "3.2", "question": "What is the Eq. of a large corpus?"}, {"answer_start": 161, "answer": "compute this estimate for yourself", "question": "What should you do when you go to the web?"}]}, {"context": "While this method of estimating probabilities directly from counts works fine in many cases, it turns out that even the web isn't big enough to give us good estimates in most cases. This is because language is creative; new sentences are created all the time, and we won't always be able to count entire sentences. Even simple extensions of the example sentence may have counts of zero on the web (such as \"Walden Pond's water is so transparent that the\"; well, used to have counts of zero).", "questions_and_answers": [{"answer_start": 120, "answer": "web", "question": "What isn't big enough to give us good estimates in most cases?"}, {"answer_start": 198, "answer": "language is creative", "question": "Why is the web not big enough to give us good estimates?"}, {"answer_start": 406, "answer": "\"Walden Pond's water is so transparent that the\"", "question": "What example sentence used to have counts of zero on the web?"}]}, {"context": "The intuition of the n-gram model is that instead of computing the probability of a word given its entire history, we can approximate the history by just the last few words.", "questions_and_answers": [{"answer_start": 146, "answer": "by just the last few words", "question": "How can we approximate the history of a word?"}]}, {"context": "The bigram model, for example, approximates the probability of a word given all the previous words P(w n |w 1:n\u22121 ) by using only the conditional probability of the preceding word P(w n |w n\u22121 ). In other words, instead of computing the probability", "questions_and_answers": [{"answer_start": 130, "answer": "the conditional probability of the preceding word", "question": "The bigram model approximates the probability of a word given all the previous words by using only what?"}, {"answer_start": 223, "answer": "computing the probability", "question": "The bigram model uses only the conditional probability of the preceding word P(w n |w n1 ) instead of what"}]}, {"context": "When we use a bigram model to predict the conditional probability of the next word, we are thus making the following approximation:", "questions_and_answers": [{"answer_start": 14, "answer": "bigram model", "question": "What model is used to predict the conditional probability of the next word?"}, {"answer_start": 42, "answer": "conditional probability", "question": "What does a bigram model predict?"}]}, {"context": "The assumption that the probability of a word depends only on the previous word is called a Markov assumption. Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past. We can generalize the bigram (which looks one word into the past) to the trigram (which looks two words into the past) and thus to the n-gram (which n-gram looks n \u2212 1 words into the past). Thus, the general equation for this n-gram approximation to the conditional probability of the next word in a sequence is", "questions_and_answers": [{"answer_start": 92, "answer": "Markov assumption", "question": "What is the assumption that the probability of a word depends only on the previous word called?"}, {"answer_start": 111, "answer": "Markov models", "question": "What are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past?"}, {"answer_start": 345, "answer": "trigram", "question": "What looks two words into the past?"}, {"answer_start": 526, "answer": "conditional probability of the next word in a sequence", "question": "What is the general equation for this n-gram approximation to?"}]}, {"context": "How do we estimate these bigram or n-gram probabilities? An intuitive way to estimate probabilities is called maximum likelihood estimation or MLE. We get maximum likelihood estimation the MLE estimate for the parameters of an n-gram model by getting counts from a corpus, and normalizing the counts so that they lie between 0 and 1. 1 normalize For example, to compute a particular bigram probability of a word y given a previous word x, we'll compute the count of the bigram C(xy) and normalize by the sum of all the bigrams that share the same first word x:", "questions_and_answers": [{"answer_start": 35, "answer": "n-gram", "question": "What is another name for bigram?"}, {"answer_start": 143, "answer": "MLE", "question": "What is an intuitive way to estimate bigram or n-gram probabilities called?"}, {"answer_start": 325, "answer": "0 and 1", "question": "Where do the counts lie in the MLE estimate for the parameters of an n-gram model?"}, {"answer_start": 477, "answer": "C(xy)", "question": "To compute a particular bigram probability of a word y given a previous word x, we'll compute the count of what big"}]}, {"context": "Let's move on to some examples from a slightly larger corpus than our 14-word example above. We'll use data from the now-defunct Berkeley Restaurant Project, a dialogue system from the last century that answered questions about a database of restaurants in Berkeley, California (Jurafsky et al., 1994) . Here are some textnormalized sample user queries (a sample of 9332 sentences is on the website):", "questions_and_answers": [{"answer_start": 47, "answer": "larger", "question": "How large is the corpus of data in the Berkeley Restaurant Project corpus?"}, {"answer_start": 129, "answer": "Berkeley Restaurant Project", "question": "What is the name of the dialogue system that answered questions about a database of restaurants in Berkeley, California?"}, {"answer_start": 366, "answer": "9332", "question": "How many sentences are on the Berkeley Restaurant Project website?"}]}, {"context": "can you tell me about any good cantonese restaurants close by mid priced thai food is what i'm looking for tell me about chez panisse can you give me a listing of the kinds of food that are available i'm looking for a good place to eat breakfast when is caffe venezia open during the day", "questions_and_answers": [{"answer_start": 31, "answer": "cantonese", "question": "What type of restaurants are close by mid priced thai food?"}, {"answer_start": 254, "answer": "caffe venezia", "question": "What restaurant is open during the day?"}]}, {"context": "We leave it as Exercise [ 3.2 ] to compute the probability of i want chinese food. What kinds of linguistic phenomena are captured in these bigram statistics? Some of the bigram probabilities above encode some facts that we think of as strictly syntactic in nature, like the fact that what comes after eat is usually a noun or an adjective, or that what comes after to is usually a verb. Others might be a fact about the personal assistant task, like the high probability of sentences beginning with the words I. And some might even be cultural rather than linguistic, like the higher probability that people are looking for Chinese versus English food.", "questions_and_answers": [{"answer_start": 15, "answer": "Exercise", "question": "What do we leave it as to compute the probability of i want chinese food?"}, {"answer_start": 97, "answer": "linguistic", "question": "What kind of phenomena are captured in bigram statistics?"}, {"answer_start": 317, "answer": "a noun or an adjective", "question": "What is usually what comes after eat?"}, {"answer_start": 421, "answer": "personal assistant", "question": "What is the high probability of sentences beginning with the words I?"}, {"answer_start": 625, "answer": "Chinese versus English food", "question": "What is the higher probability that people are looking for?"}]}, {"context": "The best way to evaluate the performance of a language model is to embed it in an application and measure how much the application improves. Such end-to-end evaluation is called extrinsic evaluation. Extrinsic evaluation is the only way to extrinsic evaluation know if a particular improvement in a component is really going to help the task at hand. Thus, for speech recognition, we can compare the performance of two language models by running the speech recognizer twice, once with each language model, and seeing which gives the more accurate transcription.", "questions_and_answers": [{"answer_start": 98, "answer": "measure how much the application improves", "question": "What is the best way to evaluate the performance of a language model?"}, {"answer_start": 178, "answer": "extrinsic evaluation", "question": "What is the best way to evaluate the performance of a language model?"}, {"answer_start": 200, "answer": "Extrinsic evaluation", "question": "What is the only way to know if a particular improvement in a component is really going to help the task at hand?"}, {"answer_start": 361, "answer": "speech recognition", "question": "What can we compare the performance of two language models by running the speech recognizer twice, once with each language model, and seeing which gives the more accurate"}]}, {"context": "Unfortunately, running big NLP systems end-to-end is often very expensive. Instead, it would be nice to have a metric that can be used to quickly evaluate potential improvements in a language model. An intrinsic evaluation metric is one that mea-intrinsic evaluation sures the quality of a model independent of any application.", "questions_and_answers": [{"answer_start": 64, "answer": "expensive", "question": "What is the cost of running big NLP systems end-to-end?"}, {"answer_start": 111, "answer": "metric", "question": "What could be used to quickly evaluate potential improvements in a language model?"}, {"answer_start": 202, "answer": "intrinsic evaluation", "question": "What is a metric that guarantees the quality of a model independent of any application?"}]}, {"context": "For an intrinsic evaluation of a language model we need a test set. As with many of the statistical models in our field, the probabilities of an n-gram model come from the corpus it is trained on, the training set or training corpus. We can then measure training set the quality of an n-gram model by its performance on some unseen data called the test set or test corpus. We will also sometimes call test sets and other datasets that test set are not in our training sets held out corpora because we hold them out from the held out training data.", "questions_and_answers": [{"answer_start": 56, "answer": "a test set", "question": "What do we need for an intrinsic evaluation of a language model?"}, {"answer_start": 168, "answer": "the corpus it is trained on", "question": "Where do the probabilities of an n-gram model come from?"}, {"answer_start": 348, "answer": "test set or test corpus", "question": "What is the name of the unseen data that an n-gram model performs on?"}, {"answer_start": 524, "answer": "held out training data", "question": "Where do we hold test sets out from?"}]}, {"context": "So if we are given a corpus of text and want to compare two different n-gram models, we divide the data into training and test sets, train the parameters of both models on the training set, and then compare how well the two trained models fit the test set.", "questions_and_answers": [{"answer_start": 109, "answer": "training and test sets", "question": "What do we divide the data into if we want to compare two different n-gram models?"}]}, {"context": "But what does it mean to \"fit the test set\"? The answer is simple: whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model. Given two probabilistic models, the better model is the one that has a tighter fit to the test data or that better predicts the details of the test data, and hence will assign a higher probability to the test data.", "questions_and_answers": [{"answer_start": 26, "answer": "fit the test set", "question": "What does it mean to have a tighter fit to the test data?"}, {"answer_start": 67, "answer": "whichever model assigns a higher probability to the test set", "question": "What is a better model?"}, {"answer_start": 248, "answer": "the one that has a tighter fit to the test data or that better predicts the details of the test data", "question": "What is the best model given two probabilistic models?"}]}, {"context": "Since our evaluation metric is based on test set probability, it's important not to let the test sentences into the training set. Suppose we are trying to compute the probability of a particular \"test\" sentence. If our test sentence is part of the training corpus, we will mistakenly assign it an artificially high probability when it occurs in the test set. We call this situation training on the test set. Training on the test set introduces a bias that makes the probabilities all look too high, and causes huge inaccuracies in perplexity, the probability-based metric we introduce below.", "questions_and_answers": [{"answer_start": 40, "answer": "test set probability", "question": "What is our evaluation metric based on?"}, {"answer_start": 40, "answer": "test", "question": "What is the term for a sentence that we are trying to compute the probability of?"}, {"answer_start": 297, "answer": "artificially high probability", "question": "If a test sentence is part of the training corpus, we mistakenly assign it what?"}, {"answer_start": 382, "answer": "training on the test set", "question": "What is an example of a situation where we mistakenly assign a high probability to a test sentence?"}, {"answer_start": 456, "answer": "makes the probabilities all look too high", "question": "What is the effect of training on the test set?"}]}, {"context": "Sometimes we use a particular test set so often that we implicitly tune to its characteristics. We then need a fresh test set that is truly unseen. In such cases, we call the initial test set the development test set or, devset. How do we divide our data into training, development, and test sets? We want our test set to be as large as possible, since a small test set may be accidentally unrepresentative, but we also want as much training data as possible. At the minimum, we would want to pick the smallest test set that gives us enough statistical power to measure a statistically significant difference between two potential models. In practice, we often just divide our data into 80% training, 10% development, and 10% test. Given a large corpus that we want to divide into training and test, test data can either be taken from some continuous sequence of text inside the corpus, or we can remove smaller \"stripes\" of text from randomly selected parts of our corpus and combine them into a test set.", "questions_and_answers": [{"answer_start": 56, "answer": "implicitly tune to its characteristics", "question": "What do we do when we use a particular test set so often that we need a fresh test set that is truly unseen?"}, {"answer_start": 109, "answer": "a fresh test set that is truly unseen", "question": "What do we need when we use a particular test set so often that we implicitly tune to its characteristics?"}, {"answer_start": 196, "answer": "development test set", "question": "What is the initial test set called?"}, {"answer_start": 260, "answer": "training, development, and test sets", "question": "What do we divide our data into?"}, {"answer_start": 425, "answer": "as much training data", "question": "How much training data do we want in a test set?"}, {"answer_start": 502, "answer": "smallest test set", "question": "What test set gives us enough statistical power to measure a statistically significant difference between two potential models?"}, {"answer_start": 687, "answer": "80%", "question": "What percentage of training, development, and test data do we divide in practice?"}, {"answer_start": 800, "answer": "test data", "question": "What can be taken from a continuous sequence of text inside the corpus?"}]}, {"context": "We can use the chain rule to expand the probability of W :", "questions_and_answers": [{"answer_start": 11, "answer": "the chain rule", "question": "What can we use to expand the probability of W?"}]}, {"context": "Thus, if we are computing the perplexity of W with a bigram language model, we get:", "questions_and_answers": [{"answer_start": 53, "answer": "bigram language model", "question": "What model is used to compute the perplexity of W?"}, {"answer_start": 53, "answer": "bigram language model", "question": "What model is used to compute the perplexity of W?"}]}, {"context": "There is another way to think about perplexity: as the weighted average branching factor of a language. The branching factor of a language is the number of possible next words that can follow any word. Consider the task of recognizing the digits in English (zero, one, two,..., nine), given that (both in some training set and in some test set) each of the 10 digits occurs with equal probability P = 1 10 . The perplexity of this mini-language is in fact 10. To see that, imagine a test string of digits of length", "questions_and_answers": [{"answer_start": 55, "answer": "weighted average branching factor", "question": "What is the number of possible next words that can follow any word?"}, {"answer_start": 142, "answer": "the number of possible next words that can follow any word", "question": "What is the branching factor of a language?"}, {"answer_start": 258, "answer": "zero, one, two,..., nine", "question": "What are the digits in English?"}, {"answer_start": 357, "answer": "10", "question": "What is the perplexity of a mini-language?"}, {"answer_start": 481, "answer": "a test string of digits of length", "question": "What is an example of a test string of digits of length?"}]}, {"context": "We see in Section [ 3.8 ] that perplexity is also closely related to the informationtheoretic notion of entropy.", "questions_and_answers": [{"answer_start": 104, "answer": "entropy", "question": "Perplexity is closely related to the informationtheoretic notion of what?"}, {"answer_start": 31, "answer": "perplexity", "question": "What is closely related to the informationtheoretic notion of entropy?"}]}, {"context": "Finally, let's look at an example of how perplexity can be used to compare different n-gram models. We trained unigram, bigram, and trigram grammars on 38 million words (including start-of-sentence tokens) from the Wall Street Journal, using a 19,979 word vocabulary. We then computed the perplexity of each of these models on a test set of [ 1.5 ] million words with Eq. [ 3.16 ]. The table below shows the perplexity of a [ 1.5 ] million word WSJ test set according to each of these grammars.", "questions_and_answers": [{"answer_start": 41, "answer": "perplexity", "question": "What can be used to compare different n-gram models?"}, {"answer_start": 152, "answer": "38 million", "question": "How many words did we train unigram, bigram, and trigram grammars on?"}, {"answer_start": 343, "answer": "1.5 ] million", "question": "How many words did we train on a test set?"}, {"answer_start": 374, "answer": "3.16", "question": "What was the perplexity of a test set of 1.5 million words with Eq."}, {"answer_start": 343, "answer": "1.5 ] million", "question": "The table below shows the perplexity of a [1.5 ] million word WSJ test set according to each of these grammars."}]}, {"context": "As we see above, the more information the n-gram gives us about the word sequence, the lower the perplexity (since as Eq. [ 3.15 ] showed, perplexity is related inversely to the likelihood of the test sequence according to the model).", "questions_and_answers": [{"answer_start": 17, "answer": "the more information the n-gram gives us about the word sequence", "question": "The lower the perplexity, what does the n-gram give us about the word sequence?"}, {"answer_start": 178, "answer": "likelihood of the test sequence", "question": "Perplexity is related inversely to what according to the model?"}]}, {"context": "Note that in computing perplexities, the n-gram model P must be constructed without any knowledge of the test set or any prior knowledge of the vocabulary of the test set. Any kind of knowledge of the test set can cause the perplexity to be artificially low. The perplexity of two language models is only comparable if they use identical vocabularies.", "questions_and_answers": [{"answer_start": 37, "answer": "the n-gram model", "question": "What model must be constructed without knowledge of the test set?"}, {"answer_start": 241, "answer": "artificially low", "question": "Any kind of knowledge of the test set can cause the perplexity to be what?"}, {"answer_start": 328, "answer": "identical vocabularies", "question": "The perplexity of two language models is only comparable if they use what?"}]}, {"context": "An (intrinsic) improvement in perplexity does not guarantee an (extrinsic) improvement in the performance of a language processing task like speech recognition or machine translation. Nonetheless, because perplexity often correlates with such improvements, it is commonly used as a quick check on an algorithm. But a model's improvement in perplexity should always be confirmed by an end-to-end evaluation of a real task before concluding the evaluation of the model.", "questions_and_answers": [{"answer_start": 3, "answer": "(intrinsic) improvement in perplexity", "question": "What does not guarantee an (extrinsic) improvement in the performance of a language processing task like speech recognition or machine translation?"}, {"answer_start": 282, "answer": "quick check on an algorithm", "question": "Perplexity is commonly used as what?"}, {"answer_start": 384, "answer": "end-to-end evaluation of a real task", "question": "What should a model's improvement in perplexity be confirmed by before concluding the evaluation of the model?"}]}, {"context": "One important way to visualize what kind of knowledge a language model embodies is to sample from it. Sampling from a distribution means to choose random points sampling according to their likelihood. Thus sampling from a language model-which represents a distribution over sentences-means to generate some sentences, choosing each sentence according to its likelihood as defined by the model. Thus we are more likely to generate sentences that the model thinks have a high probability and less likely to generate sentences that the model thinks have a low probability.", "questions_and_answers": [{"answer_start": 86, "answer": "sample", "question": "What is one way to visualize what kind of knowledge a language model embodies?"}, {"answer_start": 147, "answer": "random points sampling according to their likelihood", "question": "What does sampling from a distribution mean?"}, {"answer_start": 354, "answer": "its likelihood", "question": "How is each sentence chosen according to a language model?"}, {"answer_start": 490, "answer": "less likely", "question": "How likely are we to generate sentences that the model thinks have a low probability?"}]}, {"context": "The n-gram model, like many statistical models, is dependent on the training corpus. One implication of this is that the probabilities often encode specific facts about a given training corpus. Another implication is that n-grams do a better and better job of modeling the training corpus as we increase the value of N.", "questions_and_answers": [{"answer_start": 68, "answer": "training corpus", "question": "What is the n-gram model dependent on?"}, {"answer_start": 141, "answer": "encode specific facts", "question": "What do probabilities often do about a given training corpus?"}, {"answer_start": 295, "answer": "increase the value of N", "question": "How do n-grams model the training corpus?"}]}, {"context": "The longer the context on which we train the model, the more coherent the sentences. In the unigram sentences, there is no coherent relation between words or any sentence-final punctuation. The bigram sentences have some local word-to-word coherence (especially if we consider that punctuation counts as a word). The tri- .4 Eight sentences randomly generated from four n-grams computed from Shakespeare's works. All characters were mapped to lower-case and punctuation marks were treated as words. Output is hand-corrected for capitalization to improve readability.", "questions_and_answers": [{"answer_start": 4, "answer": "longer", "question": "How long is the context on which we train the model?"}, {"answer_start": 92, "answer": "unigram sentences", "question": "What sentences have no coherent relation between words or any sentence-final punctuation?"}, {"answer_start": 194, "answer": "bigram", "question": "What sentences have some local word-to-word coherence?"}, {"answer_start": 365, "answer": "four n-grams computed from Shakespeare's works", "question": "How are the tri-.4 Eight sentences randomly generated?"}, {"answer_start": 443, "answer": "lower-case", "question": "All characters were mapped to what?"}, {"answer_start": 546, "answer": "improve readability", "question": "Why is output hand-corrected for capitalization?"}]}, {"context": "gram and 4-gram sentences are beginning to look a lot like Shakespeare. Indeed, a careful investigation of the 4-gram sentences shows that they look a little too much like Shakespeare. The words It cannot be but so are directly from King John. This is because, not to put the knock on Shakespeare, his oeuvre is not very large as corpora go (N = 884, 647,V = 29, 066), and our n-gram probability matrices are ridiculously sparse. There are V 2 = 844, 000, 000 possible bigrams alone, and the number of possible 4-grams is V 4 = 7 \u00d7 10 17 . Thus, once the generator has chosen the first 4-gram (It cannot be but), there are only five possible continuations (that, I, he, thou, and so); indeed, for many 4-grams, there is only one continuation.", "questions_and_answers": [{"answer_start": 9, "answer": "4-gram", "question": "What type of sentences are beginning to look a lot like Shakespeare?"}, {"answer_start": 9, "answer": "4-gram", "question": "What sentences look a little too much like Shakespeare?"}, {"answer_start": 233, "answer": "King John", "question": "The words It cannot be but so are directly from who?"}, {"answer_start": 298, "answer": "his oeuvre is not very large", "question": "Why do the words It cannot be but so look too much like Shakespeare?"}, {"answer_start": 440, "answer": "V 2 = 844, 000, 000", "question": "How many possible bigrams are there?"}, {"answer_start": 479, "answer": "one", "question": "For many 4-grams, how many possible continuations are there?"}]}, {"context": "How should we deal with this problem when we build n-gram models? One step is to be sure to use a training corpus that has a similar genre to whatever task we are trying to accomplish. To build a language model for translating legal documents, we need a training corpus of legal documents. To build a language model for a question-answering system, we need a training corpus of questions.", "questions_and_answers": [{"answer_start": 51, "answer": "n-gram models", "question": "What type of models should we build to deal with this problem?"}, {"answer_start": 98, "answer": "training corpus", "question": "What should we use when building n-gram models?"}, {"answer_start": 98, "answer": "training", "question": "To build a language model for translating legal documents, we need what type of corpus of legal documents?"}, {"answer_start": 357, "answer": "a training corpus of questions", "question": "What do we need to build a language model for a question-answering system?"}]}, {"context": "It is equally important to get training data in the appropriate dialect or variety, especially when processing social media posts or spoken transcripts. For example some tweets will use features of African American Language (AAL)-the name for the many variations of language used in African American communities (King, 2020) . Such features include words like finna-an auxiliary verb that marks immediate future tense -that don't occur in other varieties, or spellings like den for then, in tweets like this one (Blodgett and O'Connor, 2017):", "questions_and_answers": [{"answer_start": 64, "answer": "dialect or variety", "question": "What is it important to get training data in?"}, {"answer_start": 198, "answer": "African American Language", "question": "What is the name for the many variations of language used in African American communities?"}, {"answer_start": 474, "answer": "den", "question": "What is the spelling for \"then\" in tweets like this one?"}]}, {"context": "([ 3.18 ]) Bored af den my phone finna die!!! while tweets from varieties like Nigerian English have markedly different vocabulary and n-gram patterns from American English (Jurgens et al., 2017):", "questions_and_answers": [{"answer_start": 11, "answer": "Bored af den my phone finna die", "question": "What is Nigerian English called?"}, {"answer_start": 79, "answer": "Nigerian English", "question": "What type of English has markedly different vocabulary and n-gram patterns from American English?"}]}, {"context": "Matching genres and dialects is still not sufficient. Our models may still be subject to the problem of sparsity. For any n-gram that occurred a sufficient number of times, we might have a good estimate of its probability. But because any corpus is limited, some perfectly acceptable English word sequences are bound to be missing from it. That is, we'll have many cases of putative \"zero probability n-grams\" that should really have some non-zero probability. Consider the words that follow the bigram denied the in the WSJ Treebank3 corpus, together with their counts: denied the allegations: 5 denied the speculation: 2 denied the rumors: 1 denied the report: 1", "questions_and_answers": [{"answer_start": 0, "answer": "Matching genres and dialects", "question": "What is still not sufficient?"}, {"answer_start": 104, "answer": "sparsity", "question": "Our models may still be subject to the problem of what?"}, {"answer_start": 122, "answer": "n-gram", "question": "What is a good estimate of its probability for a sufficient number of times?"}, {"answer_start": 284, "answer": "English", "question": "What language is bound to be missing from any corpus?"}, {"answer_start": 384, "answer": "zero probability n-grams", "question": "What type of n-grams should have some non-zero probability?"}, {"answer_start": 496, "answer": "bigram", "question": "What word was denied in the WSJ Treebank3 corpus?"}]}, {"context": "The previous section discussed the problem of words whose bigram probability is zero. But what about words we simply have never seen before?", "questions_and_answers": [{"answer_start": 58, "answer": "bigram probability", "question": "What is the problem of words whose probability is zero?"}, {"answer_start": 101, "answer": "words we simply have never seen before", "question": "What is the problem of words whose bigram probability is zero?"}]}, {"context": "Sometimes we have a language task in which this can't happen because we know all the words that can occur. In such a closed vocabulary system the test set can only contain words from this lexicon, and there will be no unknown words. This is a reasonable assumption in some domains, such as speech recognition or machine translation, where we have a pronunciation dictionary or a phrase table that are fixed in advance, and so the language model can only use the words in that dictionary or phrase table.", "questions_and_answers": [{"answer_start": 69, "answer": "we know all the words", "question": "Why can't a language task happen in a closed vocabulary system?"}, {"answer_start": 215, "answer": "no unknown words", "question": "In a closed vocabulary system, the test set can only contain words from this lexicon, and there will be what?"}, {"answer_start": 312, "answer": "machine translation", "question": "What is a domain where we have a pronunciation dictionary or a phrase table that are fixed in advance?"}]}, {"context": "There are two common ways to train the probabilities of the unknown word model <UNK>. The first one is to turn the problem back into a closed vocabulary one by choosing a fixed vocabulary in advance:", "questions_and_answers": [{"answer_start": 10, "answer": "two", "question": "How many common ways are there to train the probabilities of the unknown word model UNK>?"}, {"answer_start": 169, "answer": "a fixed vocabulary", "question": "The second way is to turn the problem back into a closed vocabulary one by choosing what in advance?"}]}, {"context": "What do we do with words that are in our vocabulary (they are not unknown words) but appear in a test set in an unseen context (for example they appear after a word they never appeared after in training)? To keep a language model from assigning zero probability to these unseen events, we'll have to shave off a bit of probability mass from some more frequent events and give it to the events we've never seen. This modification is called smoothing or discounting. In this section and the folsmoothing discounting lowing ones we'll introduce a variety of ways to do smoothing: Laplace (add-one) smoothing, add-k smoothing, stupid backoff, and Kneser-Ney smoothing.", "questions_and_answers": [{"answer_start": 140, "answer": "they appear after a word they never appeared after in training", "question": "What is an example of an unseen context for words that appear in a test set?"}, {"answer_start": 300, "answer": "shave off a bit of probability mass", "question": "What do we do to keep a language model from assigning zero probability to unseen events?"}, {"answer_start": 452, "answer": "discounting", "question": "What is another name for smoothing?"}, {"answer_start": 623, "answer": "stupid backoff", "question": "What is another way to do smoothing?"}]}, {"context": "Let's start with the application of Laplace smoothing to unigram probabilities. Recall that the unsmoothed maximum likelihood estimate of the unigram probability of the word w i is its count c i normalized by the total number of word tokens N:", "questions_and_answers": [{"answer_start": 36, "answer": "Laplace smoothing", "question": "What is applied to unigram probabilities?"}, {"answer_start": 209, "answer": "the total number of word tokens N", "question": "What is the unsmoothed maximum likelihood estimate of the unigram probability of the word w i normalized by?"}]}, {"context": "Laplace smoothing merely adds one to each count (hence its alternate name addone smoothing). Since there are V words in the vocabulary and each one was increadd-one mented, we also need to adjust the denominator to take into account the extra V observations. (What happens to our P values if we don't increase the denominator?)", "questions_and_answers": [{"answer_start": 74, "answer": "addone smoothing", "question": "What is Laplace smoothing's alternate name?"}, {"answer_start": 109, "answer": "V", "question": "How many words are in the vocabulary?"}, {"answer_start": 301, "answer": "increase the denominator", "question": "What happens to our P values if we don't do?"}]}, {"context": "Instead of changing both the numerator and denominator, it is convenient to describe how a smoothing algorithm affects the numerator, by defining an adjusted count c * . This adjusted count is easier to compare directly with the MLE counts and can be turned into a probability like an MLE count by normalizing by N. To define this count, since we are only changing the numerator in addition to adding 1 we'll also need to multiply by a normalization factor N N+V :", "questions_and_answers": [{"answer_start": 91, "answer": "smoothing algorithm", "question": "What affects the numerator?"}, {"answer_start": 229, "answer": "MLE counts", "question": "What is the adjusted count easier to compare with?"}]}, {"context": "We can now turn c * i into a probability P * i by normalizing by N. A related way to view smoothing is as discounting (lowering) some non-zero discounting counts in order to get the probability mass that will be assigned to the zero counts. Thus, instead of referring to the discounted counts c * , we might describe a smoothing algorithm in terms of a relative discount d c , the ratio of the discounted counts to discount the original counts:", "questions_and_answers": [{"answer_start": 106, "answer": "discounting (lowering) some non-zero discounting counts", "question": "What is a related way to view smoothing?"}, {"answer_start": 353, "answer": "relative discount d c", "question": "What is the ratio of the discounted counts to the original counts?"}]}, {"context": "Thus, each of the unigram counts given in the previous section will need to be augmented by V = 1446. The result is the smoothed bigram probabilities in Figure [ 3.7 ].", "questions_and_answers": [{"answer_start": 92, "answer": "V = 1446", "question": "Each of the unigram counts given in the previous section will need to be augmented by what?"}, {"answer_start": 153, "answer": "Figure", "question": "In what figure are the smoothed bigram probabilities?"}]}, {"context": "Note that add-one smoothing has made a very big change to the counts. C(want to) changed from 609 to 238! We can see this in probability space as well: P(to|want) decreases from .66 in the unsmoothed case to .26 in the smoothed case. Looking at the discount d (the ratio between new and old counts) shows us how strikingly the counts for each prefix word have been reduced; the discount for the bigram want to is .39, while the discount for Chinese food is .10, a factor of 10!", "questions_and_answers": [{"answer_start": 10, "answer": "add-one", "question": "What smoothing has made a very big change to the counts?"}, {"answer_start": 94, "answer": "609", "question": "C(want to) changed from what to 238?"}, {"answer_start": 208, "answer": ".26", "question": "P(to|want) decreases from.66 in the unsmoothed case to what in the smoothed case?"}, {"answer_start": 413, "answer": ".39", "question": "What is the discount for the bigram want to?"}]}, {"context": "The sharp change in counts and probabilities occurs because too much probability mass is moved to all the zeros.", "questions_and_answers": [{"answer_start": 52, "answer": "because too much probability mass is moved to all the zeros", "question": "Why does the sharp change in counts and probabilities occur?"}]}, {"context": "Add-k smoothing requires that we have a method for choosing k; this can be done, for example, by optimizing on a devset. Although add-k is useful for some tasks (including text classification), it turns out that it still doesn't work well for language modeling, generating counts with poor variances and often inappropriate discounts (Gale and Church, 1994) .", "questions_and_answers": [{"answer_start": 0, "answer": "Add-k", "question": "What smoothing requires that we have a method for choosing k?"}, {"answer_start": 243, "answer": "language modeling", "question": "Add-k still doesn't work well for what?"}]}, {"context": "The discounting we have been discussing so far can help solve the problem of zero frequency n-grams. But there is an additional source of knowledge we can draw on. If we are trying to compute P(w n |w n\u22122 w n\u22121 ) but we have no examples of a particular trigram w n\u22122 w n\u22121 w n , we can instead estimate its probability by using the bigram probability P(w n |w n\u22121 ). Similarly, if we don't have counts to compute P(w n |w n\u22121 ), we can look to the unigram P(w n ).", "questions_and_answers": [{"answer_start": 77, "answer": "zero frequency n-grams", "question": "The discounting we have been discussing so far can help solve the problem of what?"}, {"answer_start": 117, "answer": "additional source of knowledge", "question": "What can we draw on to solve the problem of zero frequency n-grams?"}, {"answer_start": 332, "answer": "bigram probability", "question": "What does P(w n |w n1 ) use?"}, {"answer_start": 448, "answer": "unigram", "question": "If we don't have counts to compute P(w n |w n1 ), we can look to what?"}]}, {"context": "In other words, sometimes using less context is a good thing, helping to generalize more for contexts that the model hasn't learned much about. There are two ways to use this n-gram \"hierarchy\". In backoff, we use the trigram if the evidence is backoff sufficient, otherwise we use the bigram, otherwise the unigram. In other words, we only \"back off\" to a lower-order n-gram if we have zero evidence for a higher-order n-gram. By contrast, in interpolation, we always mix the probability estimates from interpolation all the n-gram estimators, weighing and combining the trigram, bigram, and unigram counts.", "questions_and_answers": [{"answer_start": 93, "answer": "contexts that the model hasn't learned much about", "question": "What does using less context help to generalize more for?"}, {"answer_start": 154, "answer": "two", "question": "How many ways are there to use this n-gram hierarchy?"}, {"answer_start": 218, "answer": "trigram", "question": "What does backoff use if the evidence is backoff sufficient?"}, {"answer_start": 376, "answer": "if we have zero evidence for a higher-order n-gram", "question": "When do we back off to a lower-order n-gram?"}, {"answer_start": 444, "answer": "interpolation", "question": "In what method do we always mix the probability estimates from interpolation all the n-gram estimators?"}]}, {"context": "In simple linear interpolation, we combine different order n-grams by linearly interpolating them. Thus, we estimate the trigram probability P(w n |w n\u22122 w n\u22121 ) by mixing together the unigram, bigram, and trigram probabilities, each weighted by a", "questions_and_answers": [{"answer_start": 70, "answer": "linearly interpolating", "question": "How do we combine order n-grams?"}, {"answer_start": 206, "answer": "trigram probabilities", "question": "In linear interpolation, we combine unigram, bigram, and what else?"}]}, {"context": "In a slightly more sophisticated version of linear interpolation, each \u03bb weight is computed by conditioning on the context. This way, if we have particularly accurate counts for a particular bigram, we assume that the counts of the trigrams based on this bigram will be more trustworthy, so we can make the \u03bb s for those trigrams higher and thus give that trigram more weight in the interpolation. Equation [ 3.28 ] shows the equation for interpolation with context-conditioned weights:", "questions_and_answers": [{"answer_start": 92, "answer": "by conditioning on the context", "question": "How is each  weight computed?"}, {"answer_start": 214, "answer": "the counts of the trigrams based on this bigram", "question": "If we have particularly accurate counts for a particular bigram, we assume that what will be more trustworthy?"}, {"answer_start": 409, "answer": "3.28", "question": "What is the equation for interpolation with context-conditioned weights?"}]}, {"context": "In a backoff n-gram model, if the n-gram we need has zero counts, we approximate it by backing off to the (N-1)-gram. We continue backing off until we reach a history that has some counts.", "questions_and_answers": [{"answer_start": 106, "answer": "(N-1)-gram", "question": "In a backoff n-gram model, if the n-gram we need has zero counts, we approximate it by backing off to"}, {"answer_start": 142, "answer": "until we reach a history that has some counts", "question": "How long do we continue backing off to the (N-1)-gram?"}]}, {"context": "off we rely on a discounted probability P * if we've seen this n-gram before (i.e., if we have non-zero counts). Otherwise, we recursively back off to the Katz probability for the shorter-history (N-1)-gram. The probability for a backoff n-gram P BO is thus computed as follows:", "questions_and_answers": [{"answer_start": 17, "answer": "discounted probability", "question": "What does P * depend on if we've seen this n-gram before?"}, {"answer_start": 155, "answer": "Katz probability", "question": "What do we recursively back off to for the shorter-history (N-1)-gram?"}, {"answer_start": 63, "answer": "n-gram", "question": "What is the probability for a backoff?"}]}, {"context": "One of the most commonly used and best performing n-gram smoothing methods is the interpolated Kneser-Ney algorithm (Kneser and Ney 1995, Chen and Goodman", "questions_and_answers": [{"answer_start": 95, "answer": "Kneser-Ney algorithm", "question": "What is the most commonly used n-gram smoothing algorithm?"}, {"answer_start": 132, "answer": "1995", "question": "When was the interpolated Kneser-Ney algorithm developed?"}]}, {"context": "Kneser-Ney has its roots in a method called absolute discounting. Recall that discounting of the counts for frequent n-grams is necessary to save some probability mass for the smoothing algorithm to distribute to the unseen n-grams.", "questions_and_answers": [{"answer_start": 44, "answer": "absolute discounting", "question": "What is Kneser-Ney's method called?"}, {"answer_start": 138, "answer": "to save some probability mass", "question": "Why is discounting of the counts for frequent n-grams necessary?"}]}, {"context": "Notice in Figure 3 .9 that except for the held-out counts for 0 and 1, all the other bigram counts in the held-out set could be estimated pretty well by just subtracting [ 0.75 ] from the count in the training set! Absolute discounting formalizes this intuition by subtracting a fixed (absolute) discount d from each count. The intuition is that since we have good estimates already for the very high counts, a small discount d won't affect them much. It will mainly modify the smaller counts, for which we don't necessarily trust the estimate anyway, and Figure 3 .9 suggests that in practice this discount is actually a good one for bigrams with counts 2 through 9. The equation for interpolated absolute discounting applied to bigrams:", "questions_and_answers": [{"answer_start": 62, "answer": "0 and 1", "question": "What are the held-out counts for?"}, {"answer_start": 215, "answer": "Absolute discounting", "question": "What formalizes this intuition by subtracting a fixed (absolute) discount d from each count?"}, {"answer_start": 391, "answer": "very high counts", "question": "What counts do we already have good estimates for?"}, {"answer_start": 478, "answer": "smaller counts", "question": "What will a small discount d mainly modify?"}, {"answer_start": 685, "answer": "interpolated absolute discounting", "question": "What equation applies to bigrams?"}]}, {"context": "Kneser-Ney discounting (Kneser and Ney, 1995) augments absolute discounting with a more sophisticated way to handle the lower-order unigram distribution. Consider the job of predicting the next word in this sentence, assuming we are interpolating a bigram and a unigram model. I can't see without my reading . The word glasses seems much more likely to follow here than, say, the word Kong, so we'd like our unigram model to prefer glasses. But in fact it's Kong that is more common, since Hong Kong is a very frequent word. A standard unigram model will assign Kong a higher probability than glasses. We would like to capture the intuition that although Kong is frequent, it is mainly only frequent in the phrase Hong Kong, that is, after the word Hong. The word glasses has a much wider distribution.", "questions_and_answers": [{"answer_start": 0, "answer": "Kneser-Ney discounting", "question": "What augments absolute discounting with a more sophisticated way to handle the lower-order unigram distribution?"}, {"answer_start": 233, "answer": "interpolating a bigram and a unigram model", "question": "What does Kneser-Ney discounting assume we are doing?"}, {"answer_start": 300, "answer": "reading", "question": "What can I't see without?"}, {"answer_start": 319, "answer": "glasses", "question": "What word seems more likely to follow in this sentence than Kong?"}, {"answer_start": 490, "answer": "Hong Kong", "question": "What is a very frequent word?"}, {"answer_start": 525, "answer": "A standard unigram model", "question": "What will assign Kong a higher probability than glasses?"}, {"answer_start": 490, "answer": "Hong Kong", "question": "What phrase is Kong mainly frequent in?"}, {"answer_start": 319, "answer": "glasses", "question": "What word has a wider distribution than Kong?"}]}, {"context": "To turn this count into a probability, we normalize by the total number of word bigram types. In summary:", "questions_and_answers": [{"answer_start": 55, "answer": "the total number of word bigram types", "question": "What do we normalize to turn this count into a probability?"}, {"answer_start": 97, "answer": "summary", "question": "What is the term for the total number of word bigram types?"}]}, {"context": "An equivalent formulation based on a different metaphor is to use the number of word types seen to precede w (Eq. [ 3.31 ] repeated):", "questions_and_answers": [{"answer_start": 66, "answer": "the number of word types seen to precede w", "question": "What is an equivalent formulation based on a different metaphor?"}, {"answer_start": 116, "answer": "3.31", "question": "What is the number of word types seen to precede w?"}]}, {"context": "A frequent word (Kong) occurring in only one context (Hong) will have a low continuation probability.", "questions_and_answers": [{"answer_start": 70, "answer": "a low continuation probability", "question": "A frequent word (Kong) occurring in only one context (Hong) will have what?"}]}, {"context": ", is the normalized discount. The second term, |{w : C(w i\u22121 w) > 0}|, is the number of word types that can follow w i\u22121 or, equivalently, the number of word types that we discounted; in other words, the number of times we applied the normalized discount. The general recursive formulation is as follows: The continuation count is the number of unique single word contexts for [ \u2022 ]. At the termination of the recursion, unigrams are interpolated with the uniform distribution, where the parameter is the empty string:", "questions_and_answers": [{"answer_start": 9, "answer": "normalized discount", "question": "What is the second term for the number of word types that can follow w i1?"}, {"answer_start": 74, "answer": "the number of word types", "question": "What is the second term, |w : C(w i1 w) > 0|?"}, {"answer_start": 305, "answer": "The continuation count", "question": "What is the number of unique single word contexts for [ \u2022 ]?"}, {"answer_start": 505, "answer": "empty string", "question": "At the termination of the recursion, unigrams are interpolated with the uniform distribution, where the parameter is what?"}]}, {"context": "If we want to include an unknown word <UNK>, it's just included as a regular vocabulary entry with count zero, and hence its probability will be a lambda-weighted uniform distribution \u03bb ( ) V . The best performing version of Kneser-Ney smoothing is called modified Kneser-Ney smoothing, and is due to Chen and Goodman (1998). Rather than use a single modified Kneser-Ney fixed discount d, modified Kneser-Ney uses three different discounts d 1 , d 2 , and d 3+ for n-grams with counts of 1, 2 and three or more, respectively. See Chen and Goodman (1998, p. 19) or Heafield et al. 2013for the details.", "questions_and_answers": [{"answer_start": 99, "answer": "count zero", "question": "What does the word UNK> have to be included as a regular vocabulary entry?"}, {"answer_start": 301, "answer": "Chen and Goodman", "question": "Who created the best performing version of Kneser-Ney smoothing?"}, {"answer_start": 414, "answer": "three", "question": "How many different discounts does modified Kneser-Ney smoothing use?"}, {"answer_start": 564, "answer": "Heafield et al.", "question": "Who published a study on modified Kneser-Ney smoothing in 2013?"}, {"answer_start": 580, "answer": "2013", "question": "In what year was modified Kneser-Ney smoothing published?"}]}, {"context": "By using text from the web or other enormous collections, it is possible to build extremely large language models. The Web 1 Trillion 5-gram corpus released by Google includes various large sets of n-grams, including 1-grams through 5-grams from all the five-word sequences that appear in at least 40 distinct books from 1,024,908,267,229 words of text from publicly accessible Web pages in English (Franz and Brants, 2006) . Google has also released Google Books Ngrams corpora with n-grams drawn from their book collections, including another 800 billion tokens of n-grams from Chinese, English, French, German, Hebrew, Italian, Russian, and Spanish (Lin et al., 2012a) . Smaller but more carefully curated n-gram corpora for English include the million most frequent n-grams drawn from the COCA (Corpus of Contemporary American English) 1 billion word corpus of American English (Davies, 2020). COCA is a balanced corpora, meaning that it has roughly equal numbers of words from different genres: web, newspapers, spoken conversation transcripts, fiction, and so on, drawn from the period 1990-2019, and has the context of each n-gram as well as labels for genre and provenance).", "questions_and_answers": [{"answer_start": 36, "answer": "enormous collections", "question": "By using text from the web or other what, it is possible to build extremely large language models?"}, {"answer_start": 321, "answer": "1,024,908,267,229", "question": "How many words of text are in the Web 1 Trillion 5-gram corpus?"}, {"answer_start": 545, "answer": "800 billion", "question": "How many tokens of n-grams are in Google Books Ngrams corpora?"}, {"answer_start": 840, "answer": "1 billion", "question": "How many words are in the COCA corpus of American English?"}, {"answer_start": 793, "answer": "COCA", "question": "What is a balanced corpora?"}]}, {"context": "4-gram Count serve as the incoming 92 serve as the incubator 99 serve as the independent 794 serve as the index 223 serve as the indication 72 serve as the indicator 120 serve as the indicators Efficiency considerations are important when building language models that use such large sets of n-grams. Rather than store each word as a string, it is generally represented in memory as a 64-bit hash number, with the words themselves stored on disk. Probabilities are generally quantized using only 4-8 bits (instead of 8-byte floats), and n-grams are stored in reverse tries.", "questions_and_answers": [{"answer_start": 35, "answer": "92", "question": "How many grams serve as incubators?"}, {"answer_start": 383, "answer": "a 64-bit hash number", "question": "How is each word represented in memory?"}, {"answer_start": 496, "answer": "4-8 bits", "question": "How are probabilities quantized?"}]}, {"context": "An n-gram language model can also be shrunk by pruning, for example only storing n-grams with counts greater than some threshold (such as the count threshold of 40 used for the Google n-gram release) or using entropy to prune less-important n-grams (Stolcke, 1998) . Another option is to build approximate language models using techniques like Bloom filters (Talbot and Osborne 2007, Church et al. 2007) .", "questions_and_answers": [{"answer_start": 47, "answer": "pruning", "question": "How can an n-gram language model be shrunk?"}, {"answer_start": 344, "answer": "Bloom filters", "question": "What is a technique used to build approximate language models?"}, {"answer_start": 378, "answer": "2007", "question": "When did Church and Osborne use Bloom filters?"}]}, {"context": "Finally, efficient language model toolkits like KenLM (Heafield 2011, Heafield et al. 2013) use sorted arrays, efficiently combine probabilities and backoffs in a single value, and use merge sorts to efficiently build the probability tables in a minimal number of passes through a large corpus.", "questions_and_answers": [{"answer_start": 9, "answer": "efficient language model toolkits", "question": "What type of toolkits use sorted arrays?"}, {"answer_start": 185, "answer": "merge sorts", "question": "What does KenLM use to build probability tables?"}, {"answer_start": 96, "answer": "sorted arrays", "question": "What do efficient language model toolkits use?"}]}, {"context": "Although with these toolkits it is possible to build web-scale language models using full Kneser-Ney smoothing, Brants et al. (2007) show that with very large language models a much simpler algorithm may be sufficient. The algorithm is called stupid backoff. Stupid backoff gives up the idea of trying to make the language stupid backoff model a true probability distribution. There is no discounting of the higher-order probabilities. If a higher-order n-gram has a zero count, we simply backoff to a lower order n-gram, weighed by a fixed (context-independent) weight. This algorithm does not produce a probability distribution, so we'll follow Brants et al. (2007) in referring to it as S:", "questions_and_answers": [{"answer_start": 90, "answer": "Kneser-Ney", "question": "What kind of smoothing is used to build language models?"}, {"answer_start": 175, "answer": "a much simpler algorithm", "question": "What may be sufficient with very large language models?"}, {"answer_start": 243, "answer": "stupid backoff", "question": "What is the algorithm Brants et al. (2007) call?"}, {"answer_start": 259, "answer": "Stupid backoff", "question": "What gives up the idea of trying to make the language stupid backoff model a true probability distribution?"}, {"answer_start": 389, "answer": "discounting", "question": "There is no what in the higher-order probabilities in stupid backoff?"}, {"answer_start": 522, "answer": "weighed by a fixed (context-independent) weight", "question": "How is a lower order n-gram compared to a higher-order n-gram?"}, {"answer_start": 112, "answer": "Brants et al.", "question": "Who referred to the algorithm as stupid backoff?"}, {"answer_start": 690, "answer": "S:", "question": "What is the algorithm called that does not produce a probability distribution?"}]}, {"context": "We introduced perplexity in Section [ 3.2 ].1 as a way to evaluate n-gram models on a test set. A better n-gram model is one that assigns a higher probability to the test data, and perplexity is a normalized version of the probability of the test set. The perplexity measure actually arises from the information-theoretic concept of cross-entropy, which explains otherwise mysterious properties of perplexity (why the inverse probability, for example?) and its relationship to entropy. Entropy is a Entropy measure of information. Given a random variable X ranging over whatever we are predicting (words, letters, parts of speech, the set of which we'll call \u03c7) and with a particular probability function, call it p(x), the entropy of the random variable X is:", "questions_and_answers": [{"answer_start": 14, "answer": "perplexity", "question": "What was introduced in Section [ 3.2 ].1 as a way to evaluate n-gram models on a test set?"}, {"answer_start": 96, "answer": "A better n-gram model", "question": "What is one that assigns a higher probability to the test data?"}, {"answer_start": 300, "answer": "information-theoretic concept of cross-entropy", "question": "What does the perplexity measure originate from?"}, {"answer_start": 339, "answer": "entropy", "question": "What is the relationship between perplexity and the information-theoretic concept of cross-entropy?"}, {"answer_start": 486, "answer": "Entropy", "question": "What is a measure of information called?"}, {"answer_start": 714, "answer": "p(x)", "question": "What is the entropy of the random variable X called?"}]}, {"context": "The log can, in principle, be computed in any base. If we use log base 2, the resulting value of entropy will be measured in bits.", "questions_and_answers": [{"answer_start": 42, "answer": "any base", "question": "In principle, the log can be computed in what?"}, {"answer_start": 125, "answer": "bits", "question": "If we use log base 2, the resulting value of entropy will be measured in what?"}]}, {"context": "One intuitive way to think about entropy is as a lower bound on the number of bits it would take to encode a certain decision or piece of information in the optimal coding scheme.", "questions_and_answers": [{"answer_start": 33, "answer": "entropy", "question": "What is a lower bound on the number of bits it would take to encode a certain decision or piece of information in the optimal coding scheme?"}]}, {"context": "Consider an example from the standard information theory textbook Cover and Thomas (1991) . Imagine that we want to place a bet on a horse race but it is too far to go all the way to Yonkers Racetrack, so we'd like to send a short message to the bookie to tell him which of the eight horses to bet on. One way to encode this message is just to use the binary representation of the horse's number as the code; thus, horse 1 would be 001, horse 2 010, horse 3 011, and so on, with horse 8 coded as 000. If we spend the whole day betting and each horse is coded with 3 bits, on average we would be sending 3 bits per race.", "questions_and_answers": [{"answer_start": 66, "answer": "Cover and Thomas", "question": "What is the name of the standard information theory textbook published in 1991?"}, {"answer_start": 148, "answer": "it is too far to go all the way to Yonkers Racetrack", "question": "Why would we want to send a short message to the bookie to tell him which of the eight horses to bet on?"}, {"answer_start": 432, "answer": "001", "question": "What is the binary representation of the horse's number?"}, {"answer_start": 564, "answer": "3 bits", "question": "How many bits is each horse coded with?"}]}, {"context": "Can we do better? Suppose that the spread is the actual distribution of the bets placed and that we represent it as the prior probability of each horse as follows: The entropy of the random variable X that ranges over horses gives us a lower bound on the number of bits and is", "questions_and_answers": [{"answer_start": 10, "answer": "better", "question": "Can we do better or worse?"}, {"answer_start": 116, "answer": "the prior probability of each horse", "question": "What do we represent the spread as?"}, {"answer_start": 31, "answer": "the spread", "question": "What is the actual distribution of the bets placed?"}]}, {"context": "A code that averages 2 bits per race can be built with short encodings for more probable horses, and longer encodings for less probable horses. For example, we could encode the most likely horse with the code 0, and the remaining horses as 10, then 110, 1110, 111100, 111101, 111110, and 111111.", "questions_and_answers": [{"answer_start": 21, "answer": "2 bits", "question": "How many bits does a code average per race?"}, {"answer_start": 240, "answer": "10", "question": "What are the remaining horses encoded as?"}]}, {"context": "We could define the entropy rate (we could also think of this as the per-word entropy rate entropy) as the entropy of this sequence divided by the number of words:", "questions_and_answers": [{"answer_start": 69, "answer": "per-word", "question": "What is the entropy rate?"}]}, {"context": "The Shannon-McMillan-Breiman theorem (Algoet and Cover 1988, Cover and Thomas 1991) states that if the language is regular in certain ways (to be exact, if it is both stationary and ergodic),", "questions_and_answers": [{"answer_start": 4, "answer": "Shannon-McMillan-Breiman theorem", "question": "What theorem states that if the language is regular in certain ways?"}]}, {"context": "That is, we can take a single sequence that is long enough instead of summing over all possible sequences. The intuition of the Shannon-McMillan-Breiman theorem is that a long-enough sequence of words will contain in it many other shorter sequences and that each of these shorter sequences will reoccur in the longer sequence according to their probabilities.", "questions_and_answers": [{"answer_start": 70, "answer": "summing over all possible sequences", "question": "Instead of taking a single sequence that is long enough, what can we do?"}, {"answer_start": 128, "answer": "Shannon-McMillan-Breiman", "question": "The intuition of what theorem is that a long-enough sequence of words will contain many other shorter sequences?"}]}, {"context": "A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index. In other words, the probability distribution for words at time t is the same as the probability distribution at time t + 1. Markov models, and hence n-grams, are stationary. For example, in a bigram, P i is dependent only on P i\u22121 . So if we shift our time index by x, P i+x is still dependent on P i+x\u22121 . But natural language is not stationary, since as we show in Chapter 12, the probability of upcoming words can be dependent on events that were arbitrarily distant and time dependent. Thus, our statistical models only give an approximation to the correct distributions and entropies of natural language. To summarize, by making some incorrect but convenient simplifying assumptions, we can compute the entropy of some stochastic process by taking a very long sample of the output and computing its average log probability. Now we are ready to introduce cross-entropy. The cross-entropy is useful when cross-entropy we don't know the actual probability distribution p that generated some data. It allows us to use some m, which is a model of p (i.e., an approximation to p). The cross-entropy of m on p is defined by", "questions_and_answers": [{"answer_start": 46, "answer": "if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index", "question": "How is a stochastic process said to be stationary?"}, {"answer_start": 179, "answer": "probability distribution for words at time t", "question": "What is the same as the probability distribution at time t + 1?"}, {"answer_start": 283, "answer": "Markov models", "question": "What models are stationary?"}, {"answer_start": 359, "answer": "P i", "question": "What is dependent only on P i1 in a bigram?"}, {"answer_start": 428, "answer": "P i+x", "question": "If we shift our time index by x, what is still dependent on P i+x1?"}, {"answer_start": 470, "answer": "natural language", "question": "What is not stationary, since the probability of upcoming words can be dependent on events that were arbitrarily distant and time dependent?"}, {"answer_start": 691, "answer": "approximation", "question": "Our statistical models only give what to the correct distributions and entropies of natural language?"}, {"answer_start": 902, "answer": "by taking a very long sample of the output and computing its average log probability", "question": "How can we compute the entropy of some stochastic process?"}, {"answer_start": 1018, "answer": "cross-entropy", "question": "What is useful when we don't know the actual probability distribution p that generated some data?"}, {"answer_start": 1061, "answer": "when cross-entropy we don't know the actual probability distribution p that generated some data", "question": "When is the cross-entropy useful?"}, {"answer_start": 1178, "answer": "some m", "question": "What is a model of p?"}, {"answer_start": 422, "answer": "by", "question": "How is the cross-entropy of m on p defined?"}]}, {"context": "That is, we draw sequences according to the probability distribution p, but sum the log of their probabilities according to m.", "questions_and_answers": [{"answer_start": 76, "answer": "sum the log of their probabilities", "question": "How do we draw sequences according to the probability distribution p?"}, {"answer_start": 76, "answer": "sum the log of their probabilities", "question": "How do we draw sequences according to the probability distribution p?"}, {"answer_start": 44, "answer": "p", "question": "What is the robability distribution p?"}, {"answer_start": 76, "answer": "sum the log of their probabilities", "question": "How do we draw sequences according to the probability distribution p?"}]}, {"context": "This means that, as for entropy, we can estimate the cross-entropy of a model m on some distribution p by taking a single sequence that is long enough instead of summing over all possible sequences.", "questions_and_answers": [{"answer_start": 24, "answer": "entropy", "question": "What is the cross-entropy of a model m on some distribution p?"}, {"answer_start": 106, "answer": "taking a single sequence that is long enough", "question": "How can we estimate the cross-entropy of a model m on some distribution p?"}]}, {"context": "What makes the cross-entropy useful is that the cross-entropy H(p, m) is an upper bound on the entropy H(p). For any model m:", "questions_and_answers": [{"answer_start": 44, "answer": "the cross-entropy H(p, m)", "question": "What is an upper bound on the entropy H(p)?"}, {"answer_start": 73, "answer": "an upper bound on the entropy H(p)", "question": "What is the cross-entropy H(p, m)?"}, {"answer_start": 113, "answer": "any model m", "question": "For what model is the cross-entropy useful?"}]}, {"context": "This means that we can use some simplified model m to help estimate the true entropy of a sequence of symbols drawn according to probability p. The more accurate m is, the closer the cross-entropy H(p, m) will be to the true entropy H(p). Thus, the difference between H(p, m) and H(p) is a measure of how accurate a model is. Between two models m 1 and m 2 , the more accurate model will be the one with the lower cross-entropy. (The cross-entropy can never be lower than the true entropy, so a model cannot err by underestimating the true entropy.)", "questions_and_answers": [{"answer_start": 197, "answer": "H(p, m)", "question": "The more accurate m is, the closer the cross-entropy to the true entropy H(p)?"}, {"answer_start": 245, "answer": "the difference between H(p, m) and H(p)", "question": "What is a measure of how accurate a model is?"}, {"answer_start": 391, "answer": "the one with the lower cross-entropy", "question": "What is the more accurate model between models m 1 and m 2?"}, {"answer_start": 72, "answer": "true entropy", "question": "The cross-entropy can never be lower than what?"}]}, {"context": "We are finally ready to see the relation between perplexity and cross-entropy as we saw it in Eq. [ 3.49 ]. Cross-entropy is defined in the limit as the length of the observed word sequence goes to infinity. We will need an approximation to crossentropy, relying on a (sufficiently long) sequence of fixed length. This approximation to the cross-entropy of a model", "questions_and_answers": [{"answer_start": 49, "answer": "perplexity and cross-entropy", "question": "What are we finally ready to see the relation between?"}, {"answer_start": 100, "answer": "3.49", "question": "In Eq. 3, what is the relation between perplexity and cross-entropy?"}, {"answer_start": 198, "answer": "infinity", "question": "Cross-entropy is defined in the limit as the length of the observed word sequence goes to what?"}, {"answer_start": 221, "answer": "an approximation", "question": "What will we need to cross-entropy?"}, {"answer_start": 340, "answer": "cross-entropy of a model", "question": "What is the approximation to?"}]}, {"context": "The perplexity of a model P on a sequence of words W is now formally defined as perplexity 2 raised to the power of this cross-entropy:", "questions_and_answers": [{"answer_start": 80, "answer": "perplexity 2", "question": "What is the perplexity of a model P on a sequence of words W now formally defined as?"}]}, {"context": "This chapter introduced language modeling and the n-gram, one of the most widely used tools in language processing.", "questions_and_answers": [{"answer_start": 24, "answer": "language modeling", "question": "What is one of the most widely used tools in language processing?"}, {"answer_start": 50, "answer": "n-gram", "question": "What is one of the most widely used tools in language processing?"}]}, {"context": "[ \u2022 ] Language models offer a way to assign a probability to a sentence or other sequence of words, and to predict a word from preceding words. [ \u2022 ] n-grams are Markov models that estimate words from a fixed window of previous words. n-gram probabilities can be estimated by counting in a corpus and normalizing (the maximum likelihood estimate). [ \u2022 ] n-gram language models are evaluated extrinsically in some task, or intrinsically using perplexity. [ \u2022 ] The perplexity of a test set according to a language model is the geometric mean of the inverse test set probability computed by the model. [ \u2022 ] Smoothing algorithms provide a more sophisticated way to estimate the probability of n-grams. Commonly used smoothing algorithms for n-grams rely on lower-order n-gram counts through backoff or interpolation.", "questions_and_answers": [{"answer_start": 6, "answer": "Language models", "question": "What offers a way to assign a probability to a sentence or other sequence of words?"}, {"answer_start": 162, "answer": "Markov models", "question": "What are n-grams?"}, {"answer_start": 273, "answer": "by counting in a corpus and normalizing", "question": "How can n-gram probabilities be estimated?"}, {"answer_start": 442, "answer": "perplexity", "question": "How are n-gram language models evaluated intrinsically?"}, {"answer_start": 460, "answer": "The perplexity", "question": "What is the geometric mean of the inverse test set probability computed by the model?"}, {"answer_start": 606, "answer": "Smoothing algorithms", "question": "What provides a more sophisticated way to estimate the probability of n-grams?"}, {"answer_start": 755, "answer": "lower-order n-gram counts", "question": "What do smoothing algorithms rely on?"}]}, {"context": "[ \u2022 ] Both backoff and interpolation require discounting to create a probability distribution. [ \u2022 ] Kneser-Ney smoothing makes use of the probability of a word being a novel continuation. The interpolated Kneser-Ney smoothing algorithm mixes a discounted probability with a lower-order continuation probability.", "questions_and_answers": [{"answer_start": 45, "answer": "discounting", "question": "Both backoff and interpolation require what to create a probability distribution?"}, {"answer_start": 101, "answer": "Kneser-Ney", "question": "What smoothing algorithm uses the probability of a word being a novel continuation?"}, {"answer_start": 275, "answer": "lower-order continuation probability", "question": "The interpolated Kneser-Ney smoothing algorithm mixes a discounted probability with what?"}]}, {"context": "The underlying mathematics of the n-gram was first proposed by Markov (1913) , who used what are now called Markov chains (bigrams and trigrams) to predict whether an upcoming letter in Pushkin's Eugene Onegin would be a vowel or a consonant. Markov classified 20,000 letters as V or C and computed the bigram and trigram probability that a given letter would be a vowel given the previous one or two letters. Shannon (1948) applied n-grams to compute approximations to English word sequences. Based on Shannon's work, Markov models were commonly used in engineering, linguistic, and psychological work on modeling word sequences by the 1950s. In a series of extremely influential papers starting with Chomsky (1956) and including Chomsky (1957) and Miller and Chomsky (1963) , Noam Chomsky argued that \"finite-state Markov processes\", while a possibly useful engineering heuristic, were incapable of being a complete cognitive model of human grammatical knowledge. These arguments led many linguists and computational linguists to ignore work in statistical modeling for decades. The resurgence of n-gram models came from Jelinek and colleagues at the IBM Thomas J. Watson Research Center, who were influenced by Shannon, and Baker at CMU, who was influenced by the work of Baum and colleagues. Independently these two labs successfully used n-grams in their speech recognition systems (Baker 1975b , Jelinek 1976 , Baker 1975a , Bahl et al. 1983 , Jelinek 1990 ).", "questions_and_answers": [{"answer_start": 108, "answer": "Markov chains", "question": "What is now called bigrams and trigrams?"}, {"answer_start": 261, "answer": "20,000", "question": "How many letters did Markov classify as V or C?"}, {"answer_start": 419, "answer": "1948", "question": "When did Shannon apply n-grams to compute approximations to English word sequences?"}, {"answer_start": 519, "answer": "Markov models", "question": "What were commonly used in engineering, linguistic, and psychological work on modeling word sequences by the 1950s?"}, {"answer_start": 711, "answer": "1956", "question": "When did Chomsky publish his papers?"}, {"answer_start": 1039, "answer": "work in statistical modeling", "question": "Chomsky's arguments led many linguists and computational linguists to ignore what?"}, {"answer_start": 1153, "answer": "IBM Thomas J. Watson Research Center", "question": "Where did Jelinek and colleagues use n-gram models?"}, {"answer_start": 1394, "answer": "1975b", "question": "What year did Baker and Jelinek use n-grams in their speech recognition systems?"}, {"answer_start": 1458, "answer": "1990", "question": "When did Baker and Jelinek use n-grams in their speech recognition systems?"}]}, {"context": "Add-one smoothing derives from Laplace's 1812 law of succession and was first applied as an engineering solution to the zero frequency problem by Jeffreys (1948) based on an earlier Add-K suggestion by Johnson (1932) . Problems with the addone algorithm are summarized in Gale and Church (1994) .", "questions_and_answers": [{"answer_start": 0, "answer": "Add-one", "question": "What algorithm was first applied as an engineering solution to the zero frequency problem?"}, {"answer_start": 156, "answer": "1948", "question": "When was Add-one smoothing first applied?"}, {"answer_start": 272, "answer": "Gale and Church", "question": "Who summarized problems with the addone algorithm in 1994?"}]}, {"context": "A wide variety of different language modeling and smoothing techniques were proposed in the 80s and 90s, including Good-Turing discounting-first applied to the n-gram smoothing at IBM by Katz (N\u00e1das 1984, Church and Gale 1991)-Witten-Bell discounting (Witten and Bell, 1991) , and varieties of class-based ngram models that used information about word classes.", "questions_and_answers": [{"answer_start": 306, "answer": "ngram models", "question": "What type of models used information about word classes?"}, {"answer_start": 187, "answer": "Katz", "question": "Who first applied Good-Turing discounting to the n-gram smoothing at IBM?"}]}, {"context": "Starting in the late 1990s, Chen and Goodman performed a number of carefully controlled experiments comparing different discounting algorithms, cache models, class-based models, and other language model parameters (Chen and Goodman 1999, Goodman 2006, inter alia) . They showed the advantages of Modified Interpolated Kneser-Ney, which became the standard baseline for n-gram language modeling, especially because they showed that caches and class-based models provided only minor additional improvement. These papers are recommended for any reader with further interest in n-gram language modeling. SRILM (Stolcke, 2002) and KenLM (Heafield 2011 , Heafield et al. 2013 are publicly available toolkits for building n-gram language models.", "questions_and_answers": [{"answer_start": 28, "answer": "Chen and Goodman", "question": "Who performed a number of carefully controlled experiments comparing different discounting algorithms, cache models, class-based models, and language model parameters?"}, {"answer_start": 296, "answer": "Modified Interpolated Kneser-Ney", "question": "What became the standard baseline for n-gram language modeling?"}, {"answer_start": 538, "answer": "any reader with further interest in n-gram language modeling", "question": "Who are these papers recommended for?"}, {"answer_start": 600, "answer": "SRILM", "question": "What toolkit is publicly available for building n-gram language models?"}, {"answer_start": 674, "answer": "publicly available toolkits", "question": "What are SRILM and KenLM?"}]}, {"context": "Modern language modeling is more commonly done with neural network language models, which solve the major problems with n-grams: the number of parameters increases exponentially as the n-gram order increases, and n-grams have no way to generalize from training to test set. Neural language models instead project words into a continuous space in which words with similar contexts have similar representations. We'll introduce both feedforward language models (Bengio et al. 2006 , Schwenk 2007 in Chapter 7, and recurrent language models (Mikolov, 2012) in Chapter 9.", "questions_and_answers": [{"answer_start": 52, "answer": "neural network language models", "question": "Modern language modeling is more commonly done with what?"}, {"answer_start": 274, "answer": "Neural language models", "question": "What models project words into a continuous space in which words with similar contexts have similar representations?"}, {"answer_start": 426, "answer": "both feedforward language models", "question": "What will be introduced in Chapter 7?"}, {"answer_start": 512, "answer": "recurrent language models", "question": "What type of language model is introduced in Chapter 9?"}]}, {"context": "Classification lies at the heart of both human and machine intelligence. Deciding what letter, word, or image has been presented to our senses, recognizing faces or voices, sorting mail, assigning grades to homeworks; these are all examples of assigning a category to an input. The potential challenges of this task are highlighted by the fabulist Jorge Luis Borges 1964, who imagined classifying animals into:", "questions_and_answers": [{"answer_start": 0, "answer": "Classification", "question": "What is at the heart of both human and machine intelligence?"}, {"answer_start": 187, "answer": "assigning grades", "question": "What is one example of assigning a category to an input?"}, {"answer_start": 348, "answer": "Jorge Luis Borges", "question": "Who imagined classifying animals into categories?"}]}, {"context": "(a) those that belong to the Emperor, (b) embalmed ones, (c) those that are trained, (d) suckling pigs, (e) mermaids, (f) fabulous ones, (g) stray dogs, (h) those that are included in this classification, (i) those that tremble as if they were mad, (j) innumerable ones, (k) those drawn with a very fine camel's hair brush, (l) others, (m) those that have just broken a flower vase, (n) those that resemble flies from a distance.", "questions_and_answers": [{"answer_start": 141, "answer": "stray dogs", "question": "What type of dogs are included in this classification?"}, {"answer_start": 407, "answer": "flies", "question": "What resembles a camel's hair brush from a distance?"}, {"answer_start": 89, "answer": "suckling pigs", "question": "What are suckling pigs called?"}]}, {"context": "Many language processing tasks involve classification, although luckily our classes are much easier to define than those of Borges. In this chapter we introduce the naive Bayes algorithm and apply it to text categorization, the task of assigning a label or text categorization category to an entire text or document.", "questions_and_answers": [{"answer_start": 39, "answer": "classification", "question": "Many language processing tasks involve what?"}, {"answer_start": 236, "answer": "assigning a label or text categorization category to an entire text or document", "question": "What is the task of text categorization?"}, {"answer_start": 165, "answer": "naive Bayes algorithm", "question": "What is the name of the algorithm used in text categorization?"}]}, {"context": "Another thing we might want to know about a text is the language it's written in. Texts on social media, for example, can be in any number of languages and we'll need to apply different processing. The task of language id is thus the first language id step in most language processing pipelines. Related text classification tasks like authorship attributiondetermining a text's author-are also relevant to the digital authorship attribution humanities, social sciences, and forensic linguistics.", "questions_and_answers": [{"answer_start": 52, "answer": "the language it's written in", "question": "What is another thing we might want to know about a text?"}, {"answer_start": 91, "answer": "social media", "question": "Texts on what can be in any number of languages?"}, {"answer_start": 210, "answer": "language id", "question": "What is the first language id step in most language processing pipelines?"}, {"answer_start": 335, "answer": "authorship attribution", "question": "What is determining a text's author?"}]}, {"context": "Finally, one of the oldest tasks in text classification is assigning a library subject category or topic label to a text. Deciding whether a research paper concerns epidemiology or instead, perhaps, embryology, is an important component of information retrieval. Various sets of subject categories exist, such as the MeSH (Medical Subject Headings) thesaurus. In fact, as we will see, subject category classification is the task for which the naive Bayes algorithm was invented in 1961.", "questions_and_answers": [{"answer_start": 59, "answer": "assigning a library subject category or topic label to a text", "question": "What is one of the oldest tasks in text classification?"}, {"answer_start": 199, "answer": "embryology", "question": "What is an important component of information retrieval?"}, {"answer_start": 323, "answer": "Medical Subject Headings", "question": "What does MeSH stand for?"}, {"answer_start": 481, "answer": "1961", "question": "When was the naive Bayes algorithm invented?"}]}, {"context": "The goal of classification is to take a single observation, extract some useful features, and thereby classify the observation into one of a set of discrete classes. One method for classifying text is to use handwritten rules. There are many areas of language processing where handwritten rule-based classifiers constitute a state-ofthe-art system, or at least part of it.", "questions_and_answers": [{"answer_start": 30, "answer": "to take a single observation, extract some useful features, and thereby classify the observation into one of a set of discrete classes", "question": "What is the goal of classification?"}, {"answer_start": 208, "answer": "handwritten rules", "question": "What is one method for classifying text?"}, {"answer_start": 277, "answer": "handwritten rule-based classifiers", "question": "What constitutes a state-of-the-art system in language processing?"}]}, {"context": "Our goal is to learn a classifier that is capable of mapping from a new document d to its correct class c \u2208 C. A probabilistic classifier additionally will tell us the probability of the observation being in the class. This full distribution over the classes can be useful information for downstream decisions; avoiding making discrete decisions early on can be useful when combining systems.", "questions_and_answers": [{"answer_start": 168, "answer": "probability", "question": "What does a probabilistic classifier tell us about the observation being in the class?"}, {"answer_start": 311, "answer": "avoiding making discrete decisions early on", "question": "What can be useful when combining systems?"}]}, {"context": "Many kinds of machine learning algorithms are used to build classifiers. This chapter introduces naive Bayes; the following one introduces logistic regression. These exemplify two ways of doing classification. Generative classifiers like naive Bayes build a model of how a class could generate some input data. Given an observation, they return the class most likely to have generated the observation. Discriminative classifiers like logistic regression instead learn what features from the input are most useful to discriminate between the different possible classes. While discriminative systems are often more accurate and hence more commonly used, generative classifiers still have a role.", "questions_and_answers": [{"answer_start": 14, "answer": "machine learning algorithms", "question": "What is used to build classifiers?"}, {"answer_start": 97, "answer": "naive Bayes", "question": "Which machine learning algorithm is introduced in this chapter?"}, {"answer_start": 176, "answer": "two", "question": "How many ways of doing classification do naive Bayes and logistic regression exemplify?"}, {"answer_start": 210, "answer": "Generative classifiers", "question": "What type of classifier builds a model of how a class could generate some input data?"}, {"answer_start": 345, "answer": "the class most likely to have generated the observation", "question": "What do Generative classifiers return when given an observation?"}, {"answer_start": 468, "answer": "what features from the input are most useful to discriminate between the different possible classes", "question": "What do discriminative classifiers learn?"}, {"answer_start": 652, "answer": "generative classifiers", "question": "What type of classifiers still have a role?"}]}, {"context": "This idea of Bayesian inference has been known since the work of Bayes (1763), and was first applied to text classification by Mosteller and Wallace (1964) . The intuition of Bayesian classification is to use Bayes' rule to transform Eq. [ 4.1 ] into other probabilities that have some useful properties. Bayes' rule is presented in Eq. [ 4.2 ]; it gives us a way to break down any conditional probability P(x|y) into three other probabilities:", "questions_and_answers": [{"answer_start": 127, "answer": "Mosteller and Wallace", "question": "Who first applied Bayesian inference to text classification?"}, {"answer_start": 209, "answer": "Bayes' rule", "question": "What does the intuition of Bayesian classification use to transform Eq. [ 4.1 ] into other probabilities that have some useful properties?"}, {"answer_start": 251, "answer": "other probabilities", "question": "What does Bayes' rule transform Eq. [ 4.1 ] into?"}, {"answer_start": 406, "answer": "P(x|y)", "question": "What conditional probability does Bayes' rule break down into three other probabilities?"}]}, {"context": "We can conveniently simplify Eq. [ 4.3 ] by dropping the denominator P(d). This is possible because we will be computing P(d|c)P(c)", "questions_and_answers": [{"answer_start": 20, "answer": "simplify", "question": "How can we simplify Eq. [ 4.3 ] by dropping the denominator P(d)?"}, {"answer_start": 44, "answer": "dropping the denominator", "question": "How can we simplify Eq. [ 4.3 ]?"}, {"answer_start": 44, "answer": "dropping the denominator", "question": "How can we simplify Eq. [ 4.3 ]?"}, {"answer_start": 111, "answer": "computing P(d|c)P(c)", "question": "How can we simplify Eq. [ 4.3 ] by dropping the denominator P(d)?"}]}, {"context": "for each possible class. But P(d) doesn't change for each class; we are always asking about the most likely class for the same document d, which must have the same probability P(d). Thus, we can choose the class that maximizes this simpler formula:", "questions_and_answers": [{"answer_start": 9, "answer": "possible class", "question": "What does P(d) not change for each class?"}, {"answer_start": 29, "answer": "P(d) doesn't change", "question": "How does P(d) change for each class?"}, {"answer_start": 202, "answer": "the class that maximizes this simpler formula", "question": "What can we choose?"}]}, {"context": "We call Naive Bayes a generative model because we can read Eq. [ 4.4 ] as stating a kind of implicit assumption about how a document is generated: first a class is sampled from P(c), and then the words are generated by sampling from P(d|c). (In fact we could imagine generating artificial documents, or at least their word counts, by following this process). We'll say more about this intuition of generative models in Chapter 5.", "questions_and_answers": [{"answer_start": 22, "answer": "generative model", "question": "What is Naive Bayes called?"}, {"answer_start": 177, "answer": "P(c)", "question": "What is the first class sampled from?"}, {"answer_start": 278, "answer": "artificial documents", "question": "What could we imagine generating by following the process of sampling from P(d|c)?"}, {"answer_start": 419, "answer": "Chapter 5", "question": "In what chapter will we discuss the intuition of generative models?"}]}, {"context": "To return to classification: we compute the most probable class\u0109 given some document d by choosing the class which has the highest product of two probabilities: the prior probability of the class P(c) and the likelihood of the document P(d|c):", "questions_and_answers": [{"answer_start": 161, "answer": "the prior probability of the class P(c) and the likelihood of the document P(d|c)", "question": "What are the two probabilities that determine the most probable class?"}]}, {"context": "The first is the bag of words assumption discussed intuitively above: we assume position doesn't matter, and that the word \"love\" has the same effect on classification whether it occurs as the 1st, 20th, or last word in the document. Thus we assume that the features f 1 , f 2 , ..., f n only encode word identity and not position.", "questions_and_answers": [{"answer_start": 124, "answer": "love", "question": "What word has the same effect on classification whether it occurs as the 1st, 20th, or last word in a document?"}, {"answer_start": 293, "answer": "encode word identity", "question": "What do the features f 1, f 2,..., f n only do?"}]}, {"context": "The second is commonly called the naive Bayes assumption: this is the condi-naive Bayes assumption tional independence assumption that the probabilities P( f i |c) are independent given the class c and hence can be 'naively' multiplied as follows:", "questions_and_answers": [{"answer_start": 30, "answer": "the naive Bayes assumption", "question": "What is the second term for the condi-naive Bayes assumption tional independence assumption?"}, {"answer_start": 186, "answer": "the class c", "question": "What are the probabilities P( f i |c) independent given?"}]}, {"context": "The final equation for the class chosen by a naive Bayes classifier is thus:", "questions_and_answers": [{"answer_start": 0, "answer": "The final equation", "question": "What is the final equation for the class chosen by a naive Bayes classifier?"}]}, {"context": "To apply the naive Bayes classifier to text, we need to consider word positions, by simply walking an index through every word position in the document:", "questions_and_answers": [{"answer_start": 81, "answer": "by simply walking an index through every word position", "question": "How do we apply the naive Bayes classifier to text?"}]}, {"context": "ear function of input features. Classifiers that use a linear combination of the inputs", "questions_and_answers": [{"answer_start": 0, "answer": "ear function", "question": "What is a classifier that uses a linear combination of inputs?"}, {"answer_start": 55, "answer": "linear combination", "question": "Classifiers that use what type of combination of inputs?"}]}, {"context": "To learn the probability P( f i |c), we'll assume a feature is just the existence of a word in the document's bag of words, and so we'll want P(w i |c), which we compute as the fraction of times the word w i appears among all words in all documents of topic c. We first concatenate all documents with category c into one big \"category c\" text. Then we use the frequency of w i in this concatenated document to give a maximum likelihood estimate of the probability:", "questions_and_answers": [{"answer_start": 144, "answer": "w i", "question": "What is the fraction of times the word w i appears among all words in all documents of topic c?"}, {"answer_start": 356, "answer": "the frequency of w i", "question": "What is used to give a maximum likelihood estimate of the probability?"}]}, {"context": "Here the vocabulary V consists of the union of all the word types in all classes, not just the words in one class c.", "questions_and_answers": [{"answer_start": 47, "answer": "all the word types in all classes", "question": "What does the vocabulary V consist of?"}]}, {"context": "There is a problem, however, with maximum likelihood training. Imagine we are trying to estimate the likelihood of the word \"fantastic\" given class positive, but suppose there are no training documents that both contain the word \"fantastic\" and are classified as positive. Perhaps the word \"fantastic\" happens to occur (sarcastically?) in the class negative. In such a case the probability for this feature will be zero:P (\"fantastic\"|positive) = count(\"fantastic\", positive)", "questions_and_answers": [{"answer_start": 34, "answer": "maximum likelihood training", "question": "What is a problem with?"}, {"answer_start": 162, "answer": "suppose there are no training documents", "question": "What is the problem with estimating the likelihood of the word \"fantastic\" given class positive?"}, {"answer_start": 320, "answer": "sarcastically", "question": "How does the word \"fantastic\" happen in a negative class?"}, {"answer_start": 349, "answer": "negative", "question": "What class does the word \"fantastic\" occur in?"}, {"answer_start": 447, "answer": "count(\"fantastic\", positive)", "question": "What is the probability for the word \"fantastic\" in a class negative?"}]}, {"context": "But since naive Bayes naively multiplies all the feature likelihoods together, zero probabilities in the likelihood term for any class will cause the probability of the class to be zero, no matter the other evidence! The simplest solution is the add-one (Laplace) smoothing introduced in Chapter 3. While Laplace smoothing is usually replaced by more sophisticated smoothing algorithms in language modeling, it is commonly used in naive Bayes text categorization:P", "questions_and_answers": [{"answer_start": 10, "answer": "naive Bayes", "question": "What naively multiplies all the feature likelihoods together?"}, {"answer_start": 246, "answer": "add-one", "question": "What is the simplest solution?"}, {"answer_start": 255, "answer": "Laplace", "question": "What smoothing algorithm is used in naive Bayes text categorization?"}]}, {"context": "Note once again that it is crucial that the vocabulary V consists of the union of all the word types in all classes, not just the words in one class c (try to convince yourself why this must be true; see the exercise at the end of the chapter). What do we do about words that occur in our test data but are not in our vocabulary at all because they did not occur in any training document in any class? The solution for such unknown words is to ignore them-remove them from the test unknown word document and not include any probability for them at all.", "questions_and_answers": [{"answer_start": 82, "answer": "all the word types in all classes", "question": "What does the vocabulary V consist of?"}, {"answer_start": 344, "answer": "they did not occur in any training document in any class", "question": "Why are words not in our vocabulary?"}, {"answer_start": 444, "answer": "ignore them", "question": "What is the solution for unknown words?"}]}, {"context": "for each class c \u2208 C # Calculate P(c) terms N doc = number of documents in D N c = number of documents from D in class c logprior[c] \u2190 log N c N doc V \u2190 vocabulary of D bigdoc[c] \u2190 append(d) for d \u2208 D with class c for each word w in V # Calculate P(w|c) terms count(w,c) \u2190 # of occurrences of w in bigdoc[c] loglikelihood[w,c] \u2190 log count(w, c) + 1 w in V (count (w , c) + 1) return logprior, loglikelihood, V function TEST NAIVE BAYES(testdoc, logprior, loglikelihood, C, V) returns best c for each class c \u2208 C sum[c] \u2190 logprior[c] for each position i in testdoc word \u2190 testdoc[i] if word \u2208 V sum[c] \u2190 sum[c]+ loglikelihood[word,c] return argmax c sum[c]", "questions_and_answers": [{"answer_start": 640, "answer": "argmax c sum[c]", "question": "What is returned for each class c if word  testdoc[i]  testdoc[i]  testdoc[i"}]}, {"context": "Let's walk through an example of training and testing naive Bayes with add-one smoothing. We'll use a sentiment analysis domain with the two classes positive (+) and negative (-), and take the following miniature training and test documents simplified from actual movie reviews. : P(\u2212) = 3 5 P(+) = 2 5 The word with doesn't occur in the training set, so we drop it completely (as mentioned above, we don't use unknown word models for naive Bayes). The likelihoods from the training set for the remaining three words \"predictable\", \"no\", and \"fun\", are as follows, from Eq. [ 4.14 ] (computing the probabilities for the remainder of the words in the training set is left as an exercise for the reader): P(\"predictable\"|\u2212) = 1 + 1 14 + 20 P(\"predictable\"|+) = 0 + 1 9 + 20 P(\"no\"|\u2212) = 1 + 1 14 + 20 P(\"no\"|+) = 0 + 1 9 + 20 P(\"fun\"|\u2212) = 0 + 1 14 + 20 P(\"fun\"", "questions_and_answers": [{"answer_start": 71, "answer": "add-one", "question": "What type of smoothing does naive Bayes use?"}, {"answer_start": 257, "answer": "actual movie reviews", "question": "What are the miniature training and test documents simplified from?"}, {"answer_start": 411, "answer": "unknown word models", "question": "What do we not use for naive Bayes?"}, {"answer_start": 517, "answer": "\"predictable\", \"no\", and \"fun\"", "question": "What are the likelihoods for the remaining three words in the training set?"}, {"answer_start": 576, "answer": "4.14", "question": "What is the Eq. for \"predictable\", \"no\" and \"fun\"?"}]}, {"context": "For the test sentence S = \"predictable with no fun\", after removing the word 'with', the chosen class, via Eq. [ 4.9 ], is therefore computed as follows:", "questions_and_answers": [{"answer_start": 27, "answer": "predictable with no fun", "question": "What is the test sentence S =?"}, {"answer_start": 113, "answer": "4.9", "question": "What is the Eq. of the chosen class?"}]}, {"context": "\u2212 it was pathetic the worst part was the boxing scenes \u2212 no plot twists or great scenes + and satire and great plot twists + great scenes great film After per-document binarization: A second important addition commonly made when doing text classification for sentiment is to deal with negation. Consider the difference between I really like this movie (positive) and I didn't like this movie (negative). The negation expressed by didn't completely alters the inferences we draw from the predicate like. Similarly, negation can modify a negative word to produce a positive review (don't dismiss this film, doesn't let us get bored).", "questions_and_answers": [{"answer_start": 285, "answer": "negation", "question": "What is a second important addition when doing text classification for sentiment?"}, {"answer_start": 353, "answer": "positive", "question": "What type of review does I really like?"}, {"answer_start": 393, "answer": "negative", "question": "What is the difference between I really like this movie and I didn't like this movie?"}, {"answer_start": 285, "answer": "negation", "question": "What does not completely alter the inferences we draw from the predicate like?"}, {"answer_start": 393, "answer": "negative", "question": "Negation can modify what word to produce a positive review?"}]}, {"context": "A very simple baseline that is commonly used in sentiment analysis to deal with negation is the following: during text normalization, prepend the prefix NOT to every word after a token of logical negation (n't, not, no, never) until the next punctuation mark. Thus the phrase didn't like this movie , but I becomes didn't NOT_like NOT_this NOT_movie , but I Newly formed 'words' like NOT like, NOT recommend will thus occur more often in negative document and act as cues for negative sentiment, while words like NOT bored, NOT dismiss will acquire positive associations. We will return in Chapter 16 to the use of parsing to deal more accurately with the scope relationship between these negation words and the predicates they modify, but this simple baseline works quite well in practice.", "questions_and_answers": [{"answer_start": 146, "answer": "prefix NOT", "question": "What do you prepend to every word after a token of logical negation?"}, {"answer_start": 438, "answer": "negative", "question": "What type of document will words like NOT like, NOT recommend occur more often in?"}, {"answer_start": 590, "answer": "Chapter 16", "question": "When will we return to the use of parsing to deal more accurately with the scope relationship between negation words and the predicates they modify?"}]}, {"context": "Finally, in some situations we might have insufficient labeled training data to train accurate naive Bayes classifiers using all words in the training set to estimate positive and negative sentiment. In such cases we can instead derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment. Four popular lexicons are the General Inquirer (Stone et al., 1966) , LIWC (Pennebaker et al., 2007) , the opinion lexicon", "questions_and_answers": [{"answer_start": 42, "answer": "insufficient labeled training data", "question": "In some situations we might have what to train accurate Bayes classifiers using all words in the training set to estimate positive and negative sentiment?"}, {"answer_start": 281, "answer": "sentiment lexicons", "question": "What are lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment?"}, {"answer_start": 498, "answer": "the opinion lexicon", "question": "What popular lexicon is the General Inquirer?"}]}, {"context": "of Hu and Liu (2004a) and the MPQA Subjectivity Lexicon (Wilson et al., 2005) . For example the MPQA subjectivity lexicon has 6885 words, 2718 positive and 4912 negative, each marked for whether it is strongly or weakly biased. Some samples of positive and negative words from the MPQA lexicon include: + : admirable, beautiful, confident, dazzling, ecstatic, favor, glee, great \u2212 : awful, bad, bias, catastrophe, cheat, deny, envious, foul, harsh, hate A common way to use lexicons in a naive Bayes classifier is to add a feature that is counted whenever a word from that lexicon occurs. Thus we might add a feature called 'this word occurs in the positive lexicon', and treat all instances of words in the lexicon as counts for that one feature, instead of counting each word separately. Similarly, we might add as a second feature 'this word occurs in the negative lexicon' of words in the negative lexicon. If we have lots of training data, and if the test data matches the training data, using just two features won't work as well as using all the words. But when training data is sparse or not representative of the test set, using dense lexicon features instead of sparse individual-word features may generalize better.", "questions_and_answers": [{"answer_start": 57, "answer": "Wilson et al.", "question": "Who published the MPQA Subjectivity Lexicon?"}, {"answer_start": 138, "answer": "2718", "question": "How many positive words does the MPQA subjectivity lexicon have?"}, {"answer_start": 539, "answer": "counted whenever a word from that lexicon occurs", "question": "What is a feature that is added to lexicons in a naive Bayes classifier?"}, {"answer_start": 625, "answer": "this word occurs in the positive lexicon", "question": "What is a feature that is counted whenever a word from a lexicon occurs called?"}, {"answer_start": 835, "answer": "this word occurs in the negative lexicon", "question": "What is a feature that is counted whenever a word occurs in the negative lexicon?"}, {"answer_start": 1004, "answer": "two", "question": "How many features won't work if the training data matches the training data?"}, {"answer_start": 1086, "answer": "sparse", "question": "When training data is not representative of the test set, using dense lexicon features instead of sparse individual-word features may generalize better."}]}, {"context": "We'll return to this use of lexicons in Chapter 20, showing how these lexicons can be learned automatically, and how they can be applied to many other tasks beyond sentiment classification.", "questions_and_answers": [{"answer_start": 28, "answer": "lexicons", "question": "In Chapter 20, we'll discuss how lexicons can be learned automatically?"}, {"answer_start": 164, "answer": "sentiment classification", "question": "What other task can lexicons be applied to?"}]}, {"context": "In the previous section we pointed out that naive Bayes doesn't require that our classifier use all the words in the training data as features. In fact features in naive Bayes can express any property of the input text we want.", "questions_and_answers": [{"answer_start": 96, "answer": "all the words in the training data", "question": "What does naive Bayes not require a classifier to use as features?"}, {"answer_start": 188, "answer": "any property of the input text", "question": "What can features in naive Bayes express?"}]}, {"context": "Consider the task of spam detection, deciding if a particular piece of email is spam detection an example of spam (unsolicited bulk email) -and one of the first applications of naive Bayes to text classification (Sahami et al., 1998) . A common solution here, rather than using all the words as individual features, is to predefine likely sets of words or phrases as features, combined with features that are not purely linguistic. For example the open-source SpamAssassin tool 1 predefines features like the phrase \"one hundred percent guaranteed\", or the feature mentions millions of dollars, which is a regular expression that matches suspiciously large sums of money. But it also includes features like HTML has a low ratio of text to image area, that aren't purely linguistic and might require some sophisticated computation, or totally non-linguistic features about, say, the path that the email took to arrive. More sample SpamAssassin features:", "questions_and_answers": [{"answer_start": 21, "answer": "spam detection", "question": "What is the task of deciding if a particular piece of email is spam detection?"}, {"answer_start": 322, "answer": "predefine likely sets of words or phrases as features, combined with features that are not purely linguistic", "question": "What is a common solution to deciding if a particular piece of email is spam detection?"}, {"answer_start": 517, "answer": "one hundred percent guaranteed", "question": "What phrase does the open-source SpamAssassin tool 1 predefine?"}, {"answer_start": 707, "answer": "HTML", "question": "What has a low ratio of text to image area?"}, {"answer_start": 930, "answer": "SpamAssassin features", "question": "What is an example of a feature that isn't purely linguistic?"}]}, {"context": "[ \u2022 ] Email subject line is all capital letters [ \u2022 ] Contains phrases of urgency like \"urgent reply\" [ \u2022 ] Email subject line contains \"online pharmaceutical\"", "questions_and_answers": [{"answer_start": 88, "answer": "urgent reply", "question": "What is an example of urgency in an email subject line?"}]}, {"context": "[ \u2022 ] HTML has unbalanced \"head\" tags [ \u2022 ] Claims you can be removed from the list For other tasks, like language id-determining what language a given piece language id of text is written in-the most effective naive Bayes features are not words at all, but character n-grams, 2-grams ('zw') 3-grams ('nya', ' Vo'), or 4-grams ('ie z', 'thei'), or, even simpler byte n-grams, where instead of using the multibyte Unicode character representations called codepoints, we just pretend everything is a string of raw bytes. Because spaces count as a byte, byte n-grams can model statistics about the beginning or ending of words. A widely used naive Bayes system, langid.py (Lui and Baldwin, 2012) begins with all possible n-grams of lengths 1-4, using feature selection to winnow down to the most informative 7000 final features. Language ID systems are trained on multilingual text, such as Wikipedia (Wikipedia text in 68 different languages was used in (Lui and Baldwin, 2011)), or newswire. To make sure that this multilingual text correctly reflects different regions, dialects, and socioeconomic classes, systems also add Twitter text in many languages geotagged to many regions (important for getting world English dialects from countries with large Anglophone populations like Nigeria or India), Bible and Quran translations, slang websites like Urban Dictionary, corpora of African American Vernacular English (Blodgett et al., 2016) , and so on (Jurgens et al., 2017).", "questions_and_answers": [{"answer_start": 362, "answer": "byte n-grams", "question": "What is a naive Bayes feature that pretends everything is a string of raw bytes?"}, {"answer_start": 362, "answer": "byte n-grams", "question": "What can model statistics about the beginning or ending of words?"}, {"answer_start": 659, "answer": "langid.py", "question": "What is a widely used naive Bayes system?"}, {"answer_start": 861, "answer": "multilingual text", "question": "What are language ID systems trained on?"}, {"answer_start": 1281, "answer": "Nigeria or India", "question": "What are two countries with large Anglophone populations?"}]}, {"context": "As we saw in the previous section, naive Bayes classifiers can use any sort of feature: dictionaries, URLs, email addresses, network features, phrases, and so on. But if, as in the previous section, we use only individual word features, and we use all of the words in the text (not a subset), then naive Bayes has an important similarity to language modeling. Specifically, a naive Bayes model can be viewed as a set of class-specific unigram language models, in which the model for each class instantiates a unigram language model.", "questions_and_answers": [{"answer_start": 88, "answer": "dictionaries, URLs, email addresses, network features, phrases", "question": "What can naive Bayes classifiers use?"}, {"answer_start": 341, "answer": "language modeling", "question": "What does naive Bayes have an important similarity to?"}, {"answer_start": 411, "answer": "a set of class-specific unigram language models", "question": "What can a naive Bayes model be viewed as?"}]}, {"context": "Since the likelihood features from the naive Bayes model assign a probability to each word P(word|c), the model also assigns a probability to each sentence:", "questions_and_answers": [{"answer_start": 66, "answer": "probability", "question": "What do the likelihood features from the naive Bayes model assign to each word P(word|c)?"}, {"answer_start": 66, "answer": "probability", "question": "What do the likelihood features from the naive Bayes model assign to each word P(word|c)?"}]}, {"context": "Thus consider a naive Bayes model with the classes positive (+) and negative (-) and the following model parameters:", "questions_and_answers": [{"answer_start": 51, "answer": "positive", "question": "What are the classes of a naive Bayes model?"}, {"answer_start": 68, "answer": "negative", "question": "What is the class of the Bayes model?"}, {"answer_start": 51, "answer": "positive", "question": "What are the classes of a naive Bayes model?"}, {"answer_start": 51, "answer": "positive", "question": "What are the classes of a naive Bayes model?"}]}, {"context": "Each of the two columns above instantiates a language model that can assign a probability to the sentence \"I love this fun film\": P(\"I love this fun film\"|+) = [ 0.1 ] \u00d7 [ 0.1 ] \u00d7 [ 0.01 ] \u00d7 [ 0.05 ] \u00d7 [ 0.1 ] = [ 0.0000005 ] P(\"I love this fun film\"|\u2212) = [ 0.2 ] \u00d7 [ 0.001 ] \u00d7 [ 0.01 ] \u00d7 [ 0.005 ] \u00d7 [ 0.1 ] = .0000000010", "questions_and_answers": [{"answer_start": 311, "answer": ".0000000010", "question": "What is the probability of the sentence \"I love this fun film\"?"}]}, {"context": "As it happens, the positive model assigns a higher probability to the sentence: P(s|pos) > P(s|neg). Note that this is just the likelihood part of the naive Bayes model; once we multiply in the prior a full naive Bayes model might well make a different classification decision.", "questions_and_answers": [{"answer_start": 80, "answer": "P(s|pos) > P(s|neg)", "question": "What does the positive model assign a higher probability to the sentence?"}, {"answer_start": 124, "answer": "the likelihood part of the naive Bayes model", "question": "What part of the naive Bayes model does the positive model assign a higher probability to?"}]}, {"context": "To introduce the methods for evaluating text classification, let's first consider some simple binary detection tasks. For example, in spam detection, our goal is to label every text as being in the spam category (\"positive\") or not in the spam category (\"negative\"). For each item (email document) we therefore need to know whether our system called it spam or not. We also need to know whether the email is actually spam or not, i.e. the human-defined labels for each document that we are trying to match. We will refer to these human labels as the gold labels.", "questions_and_answers": [{"answer_start": 94, "answer": "binary", "question": "What type of detection tasks do we first consider?"}, {"answer_start": 214, "answer": "positive", "question": "What is the definition of a spam category?"}, {"answer_start": 255, "answer": "negative", "question": "What is the meaning of the word \"spam\"?"}, {"answer_start": 324, "answer": "whether our system called it spam or not", "question": "For each item (email document) we need to know what?"}, {"answer_start": 387, "answer": "whether the email is actually spam or not", "question": "What do we need to know?"}, {"answer_start": 439, "answer": "human-defined labels", "question": "What do we refer to as the gold labels?"}, {"answer_start": 550, "answer": "gold labels", "question": "What are the human labels for each document that we are trying to match?"}]}, {"context": "Or imagine you're the CEO of the Delicious Pie Company and you need to know what people are saying about your pies on social media, so you build a system that detects tweets concerning Delicious Pie. Here the positive class is tweets about Delicious Pie and the negative class is all other tweets.", "questions_and_answers": [{"answer_start": 33, "answer": "Delicious Pie", "question": "What is the name of the company that you're the CEO of?"}, {"answer_start": 227, "answer": "tweets about Delicious Pie", "question": "What is the positive class?"}]}, {"context": "In both cases, we need a metric for knowing how well our spam detector (or pie-tweet-detector) is doing. To evaluate any system for detecting things, we start by building a confusion matrix like the one shown in Figure 4", "questions_and_answers": [{"answer_start": 25, "answer": "metric", "question": "What do we need in order to know how well a spam detector is doing?"}, {"answer_start": 173, "answer": "confusion matrix", "question": "What do we build to evaluate a system for detecting things?"}]}, {"context": "is a table for visualizing how an algorithm performs with respect to the human gold labels, using two dimensions (system output and gold labels), and each cell labeling a set of possible outcomes. In the spam detection case, for example, true positives are documents that are indeed spam (indicated by human-created gold labels) that our system correctly said were spam. False negatives are documents that are indeed spam but our system incorrectly labeled as non-spam.", "questions_and_answers": [{"answer_start": 3, "answer": "a table", "question": "What is a table for visualizing how an algorithm performs with respect to the human gold labels?"}, {"answer_start": 238, "answer": "true positives", "question": "What are documents that are indeed spam that our system correctly said were spam?"}, {"answer_start": 371, "answer": "False negatives", "question": "What are documents that are indeed spam but our system incorrectly labeled as non-spam?"}]}, {"context": "To the bottom right of the table is the equation for accuracy, which asks what percentage of all the observations (for the spam or pie examples that means all emails or tweets) our system labeled correctly. Although accuracy might seem a natural metric, we generally don't use it for text classification tasks. That's because accuracy doesn't work well when the classes are unbalanced (as indeed they are with spam, which is a large majority of email, or with tweets, which are mainly not about pie). To make this more explicit, imagine that we looked at a million tweets, and let's say that only 100 of them are discussing their love (or hatred) for our pie,", "questions_and_answers": [{"answer_start": 53, "answer": "accuracy", "question": "To the bottom right of the table is the equation for what?"}, {"answer_start": 284, "answer": "text classification tasks", "question": "What do we generally don't use accuracy for?"}, {"answer_start": 326, "answer": "accuracy doesn't work well when the classes are unbalanced", "question": "Why don't we use accuracy for text classification tasks?"}, {"answer_start": 597, "answer": "100", "question": "How many tweets are discussing their love or hatred for our pie?"}]}, {"context": "while the other 999,900 are tweets about something completely unrelated. Imagine a simple classifier that stupidly classified every tweet as \"not about pie\". This classifier would have 999,900 true negatives and only 100 false negatives for an accuracy of 999,900/1,000,000 or [ 99.99 ]%! What an amazing accuracy level! Surely we should be happy with this classifier? But of course this fabulous 'no pie' classifier would be completely useless, since it wouldn't find a single one of the customer comments we are looking for. In other words, accuracy is not a good metric when the goal is to discover something that is rare, or at least not completely balanced in frequency, which is a very common situation in the world.", "questions_and_answers": [{"answer_start": 16, "answer": "999,900", "question": "How many tweets are about something completely unrelated?"}, {"answer_start": 142, "answer": "not about pie", "question": "What would a simple classifier classify every tweet as?"}, {"answer_start": 217, "answer": "100", "question": "How many false negatives would a classifier have?"}, {"answer_start": 297, "answer": "amazing accuracy level", "question": "What is the result of a classifier that classified every tweet as \"not about pie\"?"}, {"answer_start": 321, "answer": "Surely we should be happy with this classifier", "question": "What is the accuracy level of the classifier?"}, {"answer_start": 452, "answer": "it wouldn't find a single one of the customer comments", "question": "What would a 'no pie' classifier be useless for?"}, {"answer_start": 620, "answer": "rare", "question": "What is a common situation in the world where accuracy is not a good metric?"}]}, {"context": "That's why instead of accuracy we generally turn to two other metrics shown in Precision and recall will help solve the problem with the useless \"nothing is pie\" classifier. This classifier, despite having a fabulous accuracy of [ 99.99 ]%, has a terrible recall of 0 (since there are no true positives, and 100 false negatives, the recall is 0/100). You should convince yourself that the precision at finding relevant tweets is equally problematic. Thus precision and recall, unlike accuracy, emphasize true positives: finding the things that we are supposed to be looking for.", "questions_and_answers": [{"answer_start": 79, "answer": "Precision and recall", "question": "What two metrics help solve the problem with the useless \"nothing is pie\" classifier?"}, {"answer_start": 266, "answer": "0", "question": "What is the recall rating of the \"nothing is pie\" classifier?"}, {"answer_start": 410, "answer": "relevant tweets", "question": "What is a problem with the \"nothing is pie\" classifier?"}, {"answer_start": 288, "answer": "true positives", "question": "What do precision and recall emphasize?"}]}, {"context": "There are many ways to define a single metric that incorporates aspects of both precision and recall. The simplest of these combinations is the F-measure (van F-measure Rijsbergen, 1975) , defined as:", "questions_and_answers": [{"answer_start": 80, "answer": "precision and recall", "question": "What are two aspects of a single metric?"}, {"answer_start": 181, "answer": "1975", "question": "When was the F-measure defined?"}]}, {"context": "F-measure comes from a weighted harmonic mean of precision and recall. The harmonic mean of a set of numbers is the reciprocal of the arithmetic mean of reciprocals:", "questions_and_answers": [{"answer_start": 21, "answer": "a weighted harmonic mean of precision and recall", "question": "What does the F-measure come from?"}, {"answer_start": 71, "answer": "The harmonic mean", "question": "What is the reciprocal of the arithmetic mean of reciprocals?"}]}, {"context": "Harmonic mean is used because it is a conservative metric; the harmonic mean of two values is closer to the minimum of the two values than the arithmetic mean is. Thus it weighs the lower of the two numbers more heavily.", "questions_and_answers": [{"answer_start": 0, "answer": "Harmonic mean", "question": "What is used because it is a conservative metric?"}, {"answer_start": 171, "answer": "weighs the lower of the two numbers", "question": "Why is the harmonic mean used?"}]}, {"context": "As the figure shows, a microaverage is dominated by the more frequent class (in this case spam), since the counts are pooled. The macroaverage better reflects the statistics of the smaller classes, and so is more appropriate when performance on all the classes is equally important.", "questions_and_answers": [{"answer_start": 52, "answer": "the more frequent class", "question": "What is a microaverage dominated by?"}, {"answer_start": 90, "answer": "spam", "question": "What class dominates the microaverage?"}, {"answer_start": 130, "answer": "macroaverage", "question": "What is more appropriate when performance on all classes is equally important?"}]}, {"context": "The training and testing procedure for text classification follows what we saw with language modeling (Section [ 3.2 ]): we use the training set to train the model, then use the development test set (also called a devset) to perhaps tune some parameters, and in general decide what the best model is. Once we come up with what we think is the best model, we run it on the (hitherto unseen) test set to report its performance.", "questions_and_answers": [{"answer_start": 212, "answer": "a devset", "question": "What is another name for a development test set?"}, {"answer_start": 190, "answer": "test set", "question": "What is the name of the set that we run a model on?"}]}, {"context": "While the use of a devset avoids overfitting the test set, having a fixed training set, devset, and test set creates another problem: in order to save lots of data for training, the test set (or devset) might not be large enough to be representative. Wouldn't it be better if we could somehow use all our data for training and still use all our data for test? We can do this by cross-validation.", "questions_and_answers": [{"answer_start": 33, "answer": "overfitting", "question": "What does the use of a devset avoid?"}, {"answer_start": 297, "answer": "all our data", "question": "Wouldn't it be better if we could use what for training and still use all our data for test?"}, {"answer_start": 378, "answer": "cross-validation", "question": "What is a way to use all our data for training and still use our data for test?"}]}, {"context": "In building systems we often need to compare the performance of two systems. How can we know if the new system we just built is better than our old one? Or better than the some other system described in the literature? This is the domain of statistical hypothesis testing, and in this section we introduce tests for statistical significance for NLP classifiers, drawing especially on the work of Dror et al. 2020 such as F 1 , or accuracy. Perhaps we want to know if our logistic regression sentiment classifier A (Chapter 5) gets a higher F 1 score than our naive Bayes sentiment classifier B on a particular test set x. Let's call M(A, x) the score that system A gets on test set x, and \u03b4 (x) the performance difference between A and B on x:", "questions_and_answers": [{"answer_start": 64, "answer": "two", "question": "In building systems, we often need to compare the performance of how many systems?"}, {"answer_start": 100, "answer": "new system we just built", "question": "What is better than our old system?"}, {"answer_start": 128, "answer": "better", "question": "How can we know if the new system we just built is better or worse than the other system described in the literature?"}, {"answer_start": 241, "answer": "statistical hypothesis testing", "question": "What is the domain of how can we know if a new system is better than another system described in the literature?"}, {"answer_start": 430, "answer": "accuracy", "question": "What is another term for F 1?"}, {"answer_start": 533, "answer": "higher", "question": "What is the F 1 score of our logistic regression sentiment classifier A?"}, {"answer_start": 633, "answer": "M(A, x)", "question": "What is the score that system A gets on test set x?"}]}, {"context": "We would like to know if \u03b4 (x) > 0, meaning that our logistic regression classifier has a higher F 1 than our naive Bayes classifier on X. \u03b4 (x) is called the effect size;", "questions_and_answers": [{"answer_start": 155, "answer": "the effect size", "question": "What is  (x) called?"}, {"answer_start": 155, "answer": "the effect size", "question": "What is  (x) called?"}]}, {"context": "effect size a bigger \u03b4 means that A seems to be way better than B; a small \u03b4 means A seems to be only a little better. Why don't we just check if \u03b4 (x) is positive? Suppose we do, and we find that the F 1 score of A is higher than B's by .04. Can we be certain that A is better? We cannot! That's because A might just be accidentally better than B on this particular x. We need something more: we want to know if A's superiority over B is likely to hold again if we checked another test set x , or under some other set of circumstances.", "questions_and_answers": [{"answer_start": 34, "answer": "A seems to be way better than B", "question": "What does a bigger  mean?"}, {"answer_start": 0, "answer": "effect size", "question": "What does a bigger  mean that A seems to be way better than B?"}, {"answer_start": 149, "answer": "x", "question": "What is?"}, {"answer_start": 238, "answer": ".04", "question": "What is the F 1 score of A higher than B's?"}, {"answer_start": 266, "answer": "A is better", "question": "Can we be certain that A is better than B?"}, {"answer_start": 279, "answer": "We cannot", "question": "Can we be certain that A is better than B?"}, {"answer_start": 305, "answer": "A might just be accidentally better than B", "question": "Why can't we be certain that A is better?"}, {"answer_start": 410, "answer": "if A's superiority over B is likely to hold again", "question": "What do we want to know if we checked another test set x?"}]}, {"context": "In the paradigm of statistical hypothesis testing, we test this by formalizing two hypotheses.", "questions_and_answers": [{"answer_start": 67, "answer": "formalizing two", "question": "How are hypotheses tested in the paradigm of statistical hypothesis testing?"}]}, {"context": "The hypothesis H 0 , called the null hypothesis, supposes that \u03b4 (x) is actually neganull hypothesis tive or zero, meaning that A is not better than B. We would like to know if we can confidently rule out this hypothesis, and instead support H 1 , that A is better.", "questions_and_answers": [{"answer_start": 28, "answer": "the null hypothesis", "question": "What is the hypothesis H 0 called?"}, {"answer_start": 242, "answer": "H 1", "question": "What hypothesis does the null hypothesis support?"}]}, {"context": "There are two common non-parametric tests used in NLP: approximate randomization (Noreen, 1989) and the bootstrap test. We will describe bootstrap approximate randomization below, showing the paired version of the test, which again is most common in NLP. Paired tests are those in which we compare two sets of observations that are aligned: paired each observation in one set can be paired with an observation in another. This happens naturally when we are comparing the performance of two systems on the same test set; we can pair the performance of system A on an individual observation x i with the performance of system B on the same x i .", "questions_and_answers": [{"answer_start": 55, "answer": "approximate randomization", "question": "What is the most common non-parametric test used in NLP?"}, {"answer_start": 137, "answer": "bootstrap approximate randomization", "question": "What is the most common non-parametric test used in NLP?"}, {"answer_start": 255, "answer": "Paired tests", "question": "What are those in which we compare two sets of observations that are aligned?"}, {"answer_start": 445, "answer": "when we are comparing the performance of two systems on the same test set", "question": "When does paired testing happen naturally?"}]}, {"context": "The bootstrap test (Efron and Tibshirani, 1993) can apply to any metric; from prebootstrap test cision, recall, or F1 to the BLEU metric used in machine translation. The word bootstrapping refers to repeatedly drawing large numbers of smaller samples with bootstrapping replacement (called bootstrap samples) from an original larger sample. The intuition of the bootstrap test is that we can create many virtual test sets from an observed test set by repeatedly sampling from it. The method only makes the assumption that the sample is representative of the population.", "questions_and_answers": [{"answer_start": 4, "answer": "bootstrap test", "question": "What can apply to any metric from prebootstrap test cision, recall, or F1 to the BLEU metric used in machine"}, {"answer_start": 290, "answer": "bootstrap samples", "question": "What are bootstrapping replacements called?"}, {"answer_start": 399, "answer": "many virtual test sets", "question": "What is the intuition of the bootstrap test?"}, {"answer_start": 536, "answer": "representative of the population", "question": "The bootstrap test only makes the assumption that the sample is what?"}]}, {"context": "(We use the notation 1(x) to mean \"1 if x is true, and 0 otherwise\".) However, although it's generally true that the expected value of \u03b4 (X) over many test sets, (again assuming A isn't better than B) is 0, this isn't true for the bootstrapped test sets we created. That's because we didn't draw these samples from a distribution with 0 mean; we happened to create them from the original test set x, which happens to be biased (by .20) in favor of A. So to measure how surprising is our observed \u03b4 (x), we actually compute the p-value by counting over many test sets how often \u03b4 (x (i) ) exceeds the expected value of \u03b4 (x) by \u03b4 (x) or more:", "questions_and_answers": [{"answer_start": 35, "answer": "1 if x is true, and 0 otherwise", "question": "What does 1(x) mean?"}, {"answer_start": 231, "answer": "bootstrapped test sets", "question": "What type of test sets did we create?"}, {"answer_start": 431, "answer": ".20", "question": "How much bias did the original test set x have in favor of A?"}, {"answer_start": 527, "answer": "p-value", "question": "What is computed by counting over many test sets how often  (x (i) ) exceeds the expected value of  (x"}]}, {"context": "So if for example we have 10,000 test sets x (i) and a threshold of .01, and in only 47 of the test sets do we find that \u03b4 (x (i) ) \u2265 2\u03b4 (x), the resulting p-value of .0047 is smaller than .01, indicating \u03b4 (x) is indeed sufficiently surprising, and we can reject the null hypothesis and conclude A is better than B.", "questions_and_answers": [{"answer_start": 85, "answer": "47", "question": "How many test sets do we find that x (i)  2 (x)?"}, {"answer_start": 26, "answer": "10,000", "question": "How many test sets does x (i) have?"}]}, {"context": "b # on what % of the b samples did algorithm A beat expectations? return p-value(x) # if very few did, our observed \u03b4 is probably not accidental The full algorithm for the bootstrap is shown in Figure 4 .9. It is given a test set x, a number of samples b, and counts the percentage of the b bootstrap test sets in which", "questions_and_answers": [{"answer_start": 0, "answer": "b", "question": "What percentage of the b samples did algorithm A beat expectations?"}, {"answer_start": 73, "answer": "p-value(x)", "question": "What value does algorithm A return if very few did?"}, {"answer_start": 53, "answer": "x", "question": "The full algorithm for the bootstrap is shown in Figure 4.9. It is given a test set of what?"}]}, {"context": "It is important to avoid harms that may result from classifiers, harms that exist both for naive Bayes classifiers and for the other classification algorithms we introduce in later chapters.", "questions_and_answers": [{"answer_start": 25, "answer": "harms", "question": "What is important to avoid that may result from classifiers?"}, {"answer_start": 91, "answer": "naive Bayes classifiers", "question": "What type of classifiers are harms that may result from classifiers?"}]}, {"context": "One class of harms is representational harms (Crawford 2017, Blodgett et al. 2020), harms caused by a system that demeans a social group, for example by perpetuating negative stereotypes about them. For example Kiritchenko and Mohammad (2018) examined the performance of 200 sentiment analysis systems on pairs of sentences that were identical except for containing either a common African American first name (like Shaniqua) or a common European American first name (like Stephanie), chosen from the Caliskan et al. (2017) study discussed in Chapter 6. They found that most systems assigned lower sentiment and more negative emotion to sentences with African American names, reflecting and perpetuating stereotypes that associate African Americans with negative emotions (Popp et al., 2003) . In other tasks classifiers may lead to both representational harms and other harms, such as censorship. For example the important text classification task of toxicity detection is the task of detecting hate speech, abuse, harassment, or other toxicity detection kinds of toxic language. While the goal of such classifiers is to help reduce societal harm, toxicity classifiers can themselves cause harms. For example, researchers have shown that some widely used toxicity classifiers incorrectly flag as being toxic sentences that are non-toxic but simply mention minority identities like women (Park et al., 2018), blind people (Hutchinson et al., 2020) or gay people (Dixon et al., 2018), or simply use linguistic features characteristic of varieties like African-American Vernacular English (Sap et al. 2019 , Davidson et al. 2019 . Such false positive errors, if employed by toxicity detection systems without human oversight, could lead to the censoring of discourse by or about these groups.", "questions_and_answers": [{"answer_start": 22, "answer": "representational harms", "question": "What class of harms are caused by a system that demeans a social group?"}, {"answer_start": 114, "answer": "demeans", "question": "What are representational harms caused by a system that perpetuates negative stereotypes about a social group?"}, {"answer_start": 473, "answer": "Stephanie", "question": "What is a common European American first name?"}, {"answer_start": 543, "answer": "Chapter 6", "question": "Where did Caliskan and Mohammad examine the performance of 200 sentiment analysis systems on pairs of sentences that were identical except for a common African American"}, {"answer_start": 773, "answer": "Popp et al., 2003", "question": "Who found that most systems assigned lower sentiment and more negative emotion to sentences with African American names?"}, {"answer_start": 886, "answer": "censorship", "question": "Classifiers can lead to both representational harms and what other harm?"}, {"answer_start": 952, "answer": "toxicity detection", "question": "What is the important text classification task of detecting hate speech, abuse, harassment, or other kinds of toxic language?"}, {"answer_start": 1122, "answer": "help reduce societal harm", "question": "What is the goal of toxicity detection?"}, {"answer_start": 1498, "answer": "linguistic features", "question": "What characteristic of varieties like African-American Vernacular English do some toxicity classifiers incorrectly flag as being toxic?"}, {"answer_start": 1606, "answer": "Davidson et al.", "question": "Who published a study on linguistic features characteristic of African-American Vernacular English in 2019?"}, {"answer_start": 1599, "answer": "2019", "question": "What year did Davidson et al. publish a study on linguistic features characteristic of African-American Vernacular English?"}, {"answer_start": 1634, "answer": "false positive errors", "question": "What could lead to the censoring of discourse by or about minority identities?"}]}, {"context": "These model problems can be caused by biases or other problems in the training data; in general, machine learning systems replicate and even amplify the biases in their training data. But these problems can also be caused by the labels (for example due to biases in the human labelers), by the resources used (like lexicons, or model components like pretrained embeddings), or even by model architecture (like what the model is trained to optimized). While the mitigation of these biases (for example by carefully considering the training data sources) is an important area of research, we currently don't have general solutions. For this reason it's important, when introducing any NLP model, to study these these kinds of factors and make them clear. One way to do this is by releasing a model card (Mitchell et al., 2019) model card for each version of a model. A model card documents a machine learning model with information like:", "questions_and_answers": [{"answer_start": 38, "answer": "biases or other problems in the training data", "question": "What can model problems be caused by?"}, {"answer_start": 229, "answer": "labels", "question": "What can cause model problems?"}, {"answer_start": 461, "answer": "mitigation", "question": "What is an important area of research?"}, {"answer_start": 736, "answer": "make them clear", "question": "What is important when introducing a NLP model?"}, {"answer_start": 802, "answer": "Mitchell et al., 2019", "question": "Who released a model card for each version of a model?"}, {"answer_start": 790, "answer": "model card", "question": "What documents a machine learning model with information like:"}]}, {"context": "[ \u2022 ] training algorithms and parameters [ \u2022 ] training data sources, motivation, and preprocessing [ \u2022 ] evaluation data sources, motivation, and preprocessing [ \u2022 ] intended use and users [ \u2022 ] model performance across different demographic or other groups and environmental situations", "questions_and_answers": [{"answer_start": 167, "answer": "intended use and users", "question": "What are two types of evaluation data sources?"}, {"answer_start": 167, "answer": "intended use and users", "question": "What are two types of evaluation data sources?"}]}, {"context": "This chapter introduced the naive Bayes model for classification and applied it to the text categorization task of sentiment analysis.", "questions_and_answers": [{"answer_start": 83, "answer": "the text categorization task of sentiment analysis", "question": "What task did this chapter apply the Bayes model to?"}, {"answer_start": 28, "answer": "naive Bayes model", "question": "What model did this chapter introduce?"}]}, {"context": "[ \u2022 ] Text categorization, in which an entire text is assigned a class from a finite set, includes such tasks as sentiment analysis, spam detection, language identification, and authorship attribution. [ \u2022 ] Sentiment analysis classifies a text as reflecting the positive or negative orientation (sentiment) that a writer expresses toward some object. [ \u2022 ] Naive Bayes is a generative model that makes the bag of words assumption (position doesn't matter) and the conditional independence assumption (words are conditionally independent of each other given the class) [ \u2022 ] Naive Bayes with binarized features seems to work better for many text classification tasks. [ \u2022 ] Classifiers are evaluated based on precision and recall.", "questions_and_answers": [{"answer_start": 6, "answer": "Text categorization", "question": "What is it called when an entire text is assigned a class from a finite set?"}, {"answer_start": 263, "answer": "positive or negative orientation", "question": "What does sentiment analysis classify a text as reflecting?"}, {"answer_start": 358, "answer": "Naive Bayes", "question": "What is a generative model that makes the bag of words assumption (position doesn't matter) and the conditional independence assumption (words are"}, {"answer_start": 709, "answer": "precision and recall", "question": "What are classifiers evaluated based on?"}]}, {"context": "[ \u2022 ] Classifiers are trained using distinct training, dev, and test sets, including the use of cross-validation in the training set. [ \u2022 ] Statistical significance tests should be used to determine whether we can be confident that one version of a classifier is better than another. [ \u2022 ] Designers of classifiers should carefully consider harms that may be caused by the model, including its training data and other components, and report model characteristics in a model card.", "questions_and_answers": [{"answer_start": 36, "answer": "distinct training, dev, and test sets", "question": "What are classifiers trained using?"}, {"answer_start": 140, "answer": "Statistical significance tests", "question": "What should be used to determine whether one version of a classifier is better than another?"}, {"answer_start": 341, "answer": "harms", "question": "What should designers of classifiers carefully consider that may be caused by the model?"}]}, {"context": "Multinomial naive Bayes text classification was proposed by Maron (1961) at the RAND Corporation for the task of assigning subject categories to journal abstracts. His model introduced most of the features of the modern form presented here, approximating the classification task with one-of categorization, and implementing add-\u03b4 smoothing and information-based feature selection.", "questions_and_answers": [{"answer_start": 60, "answer": "Maron", "question": "Who proposed multinomial naive Bayes text classification?"}, {"answer_start": 80, "answer": "RAND Corporation", "question": "What company did Maron work for in 1961?"}, {"answer_start": 284, "answer": "one-of categorization", "question": "Maron's model approximated the classification task with what?"}]}, {"context": "The conditional independence assumptions of naive Bayes and the idea of Bayesian analysis of text seems to have arisen multiple times. The same year as Maron's paper, Minsky (1961) proposed a naive Bayes classifier for vision and other artificial intelligence problems, and Bayesian techniques were also applied to the text classification task of authorship attribution by Mosteller and Wallace (1963) . It had long been known that Alexander Hamilton, John Jay, and James Madison wrote the anonymously-published Federalist papers in 1787-1788 to persuade New York to ratify the United States Constitution. Yet although some of the 85 essays were clearly attributable to one author or another, the authorship of 12 were in dispute between Hamilton and Madison. Mosteller and Wallace (1963) trained a Bayesian probabilistic model of the writing of Hamilton and another model on the writings of Madison, then computed the maximum-likelihood author for each of the disputed essays. Naive Bayes was first applied to spam detection in Heckerman et al. (1998) .", "questions_and_answers": [{"answer_start": 4, "answer": "conditional independence", "question": "What assumptions of naive Bayes and the idea of Bayesian analysis of text seem to have arisen multiple times?"}, {"answer_start": 167, "answer": "Minsky", "question": "Who proposed a naive Bayes classifier for vision and artificial intelligence problems?"}, {"answer_start": 533, "answer": "1787-1788", "question": "When were the anonymously published Federalist papers published?"}, {"answer_start": 711, "answer": "12", "question": "How many essays were in dispute between Hamilton and Madison?"}, {"answer_start": 396, "answer": "1963", "question": "When did Mosteller and Wallace train a Bayesian probabilistic model of the writing of Hamilton?"}, {"answer_start": 1029, "answer": "Heckerman et al.", "question": "Who first applied naive Bayes to spam detection?"}, {"answer_start": 1047, "answer": "1998", "question": "When was naive Bayes first applied to spam detection?"}]}, {"context": "Metsis et al. 2006, Pang et al. 2002, and Wang and Manning 2012show that using boolean attributes with multinomial naive Bayes works better than full counts. Binary multinomial naive Bayes is sometimes confused with another variant of naive Bayes that also use a binary representation of whether a term occurs in a document: Multivariate Bernoulli naive Bayes. The Bernoulli variant instead estimates P(w|c) as the fraction of documents that contain a term, and includes a probability for whether a term is not in a document. McCallum and Nigam (1998) and Wang and Manning (2012) show that the multivariate Bernoulli variant of naive Bayes doesn't work as well as the multinomial algorithm for sentiment or other text tasks.", "questions_and_answers": [{"answer_start": 0, "answer": "Metsis", "question": "Who et al. 2006 showed that using boolean attributes with multinomial naive Bayes works better than full"}, {"answer_start": 14, "answer": "2006", "question": "When was Metsis et al. published?"}, {"answer_start": 32, "answer": "2002", "question": "When was Pang et al. published?"}, {"answer_start": 325, "answer": "Multivariate Bernoulli naive Bayes", "question": "What is another variant of naive Bayes that uses a binary representation of whether a term occurs in a document called?"}, {"answer_start": 401, "answer": "P(w|c)", "question": "What does the Bernoulli variant estimate as the fraction of documents that contain a term?"}, {"answer_start": 594, "answer": "multivariate Bernoulli", "question": "What variant of naive Bayes doesn't work as well as the multinomial algorithm for sentiment or text tasks?"}]}, {"context": "There are a variety of sources covering the many kinds of text classification tasks. For sentiment analysis see Pang and Lee (2008) , and Liu and Zhang (2012). Stamatatos (2009) surveys authorship attribute algorithms. On language identification see Jauhiainen et al. (2018); Jaech et al. (2016) is an important early neural system. The task of newswire indexing was often used as a test case for text classification algorithms, based on the Reuters-21578 collection of newswire articles.", "questions_and_answers": [{"answer_start": 58, "answer": "text classification tasks", "question": "What are there a variety of sources covering?"}, {"answer_start": 112, "answer": "Pang and Lee", "question": "Who wrote about sentiment analysis?"}, {"answer_start": 186, "answer": "authorship attribute algorithms", "question": "What does Stamatatos survey?"}, {"answer_start": 222, "answer": "language identification", "question": "What is an important early neural system?"}, {"answer_start": 276, "answer": "Jaech et al.", "question": "What is an important early neural system?"}, {"answer_start": 312, "answer": "early neural system", "question": "What is language identification an important part of?"}, {"answer_start": 345, "answer": "newswire indexing", "question": "What was often used as a test case for text classification algorithms?"}]}, {"context": "See Manning et al. (2008) and Aggarwal and Zhai (2012) on text classification; classification in general is covered in machine learning textbooks (Hastie et al. 2001 , Witten and Frank 2005 , Bishop 2006 , Murphy 2012 .", "questions_and_answers": [{"answer_start": 4, "answer": "Manning", "question": "Who et al. (2008) covered text classification?"}, {"answer_start": 119, "answer": "machine learning textbooks", "question": "Where is classification in general covered?"}, {"answer_start": 185, "answer": "2005", "question": "In what year did Witten and Frank publish a textbook on text classification?"}]}, {"context": "Non-parametric methods for computing statistical significance were used first in NLP in the MUC competition (Chinchor et al., 1993) , and even earlier in speech recognition (Gillick and Cox 1989, Bisani and Ney 2004) . Our description of the bootstrap draws on the description in Berg-Kirkpatrick et al. (2012) . Recent work has focused on issues including multiple test sets and multiple metrics (S\u00f8gaard et al. 2014 , Dror et al. 2017 .", "questions_and_answers": [{"answer_start": 0, "answer": "Non-parametric methods", "question": "What was used first in NLP in the MUC competition?"}, {"answer_start": 280, "answer": "Berg-Kirkpatrick et al.", "question": "Where did our description of the bootstrap draw on?"}, {"answer_start": 304, "answer": "(2012)", "question": "In what year was Berg-Kirkpatrick et al. published?"}, {"answer_start": 340, "answer": "issues including multiple test sets and multiple metrics", "question": "What has recent work focused on?"}, {"answer_start": 420, "answer": "Dror", "question": "Who et al. 2017 focused on multiple test sets and multiple metrics?"}, {"answer_start": 432, "answer": "2017", "question": "In what year did Dror et al. publish their work on multiple test sets and multiple metrics?"}]}, {"context": "Feature selection is a method of removing features that are unlikely to generalize well. Features are generally ranked by how informative they are about the classification decision. A very common metric, information gain, tells us how many bits of information gain information the presence of the word gives us for guessing the class. Other feature selection metrics include \u03c7 2 , pointwise mutual information, and GINI index; see Yang and Pedersen (1997) for a comparison and Guyon and Elisseeff (2003) for an introduction to feature selection.", "questions_and_answers": [{"answer_start": 0, "answer": "Feature selection", "question": "What is a method of removing features that are unlikely to generalize well?"}, {"answer_start": 122, "answer": "how informative they are about the classification decision", "question": "What are features generally ranked by?"}, {"answer_start": 204, "answer": "information gain", "question": "What tells us how many bits of information gain information the presence of a word gives us for guessing the class?"}, {"answer_start": 415, "answer": "GINI index", "question": "What is another feature selection metric?"}]}, {"context": "Detective stories are as littered with clues as texts are with words. Yet for the poor reader it can be challenging to know how to weigh the author's clues in order to make the crucial classification task: deciding whodunnit.", "questions_and_answers": [{"answer_start": 39, "answer": "clues", "question": "Detective stories are as littered with what as texts are with words?"}, {"answer_start": 82, "answer": "poor reader", "question": "For what type of reader can it be difficult to know how to weigh the author's clues in order to make the crucial classification task?"}]}, {"context": "In this chapter we introduce an algorithm that is admirably suited for discovering the link between features or cues and some particular outcome: logistic regression.", "questions_and_answers": [{"answer_start": 146, "answer": "logistic regression", "question": "What is the name of the algorithm that is suited for discovering the link between features or cues and some particular outcome?"}]}, {"context": "Indeed, logistic regression is one of the most important analytic tools in the social and natural sciences. In natural language processing, logistic regression is the baseline supervised machine learning algorithm for classification, and also has a very close relationship with neural networks. As we will see in Chapter 7, a neural network can be viewed as a series of logistic regression classifiers stacked on top of each other. Thus the classification and machine learning techniques introduced here will play an important role throughout the book.", "questions_and_answers": [{"answer_start": 8, "answer": "logistic regression", "question": "What is one of the most important analytic tools in the social and natural sciences?"}, {"answer_start": 111, "answer": "natural language processing", "question": "What is the baseline supervised machine learning algorithm for classification?"}, {"answer_start": 402, "answer": "stacked on top of each other", "question": "How can a neural network be viewed?"}, {"answer_start": 460, "answer": "machine learning techniques", "question": "What will play an important role throughout the book?"}]}, {"context": "Logistic regression can be used to classify an observation into one of two classes (like 'positive sentiment' and 'negative sentiment'), or into one of many classes. Because the mathematics for the two-class case is simpler, we'll describe this special case of logistic regression first in the next few sections, and then briefly summarize the use of multinomial logistic regression for more than two classes in Section [ 5.6 ].", "questions_and_answers": [{"answer_start": 0, "answer": "Logistic regression", "question": "What can be used to classify an observation into one of two classes?"}, {"answer_start": 216, "answer": "simpler", "question": "What is the mathematics for the two-class case?"}]}, {"context": "We'll introduce the mathematics of logistic regression in the next few sections. But let's begin with some high-level issues.", "questions_and_answers": [{"answer_start": 35, "answer": "logistic regression", "question": "What math will we introduce in the next few sections?"}, {"answer_start": 107, "answer": "high-level issues", "question": "What do we begin with?"}]}, {"context": "Generative and Discriminative Classifiers: The most important difference between naive Bayes and logistic regression is that logistic regression is a discriminative classifier while naive Bayes is a generative classifier.", "questions_and_answers": [{"answer_start": 97, "answer": "logistic regression", "question": "What is a discriminative classifier?"}, {"answer_start": 199, "answer": "generative", "question": "What type of classifier is naive Bayes?"}, {"answer_start": 199, "answer": "generative", "question": "What type of classifier is naive Bayes?"}]}, {"context": "These are two very different frameworks for how to build a machine learning model. Consider a visual metaphor: imagine we're trying to distinguish dog images from cat images. A generative model would have the goal of understanding what dogs look like and what cats look like. You might literally ask such a model to 'generate', i.e., draw, a dog. Given a test image, the system then asks whether it's the cat model or the dog model that better fits (is less surprised by) the image, and chooses that as its label.", "questions_and_answers": [{"answer_start": 10, "answer": "two", "question": "How many different frameworks for how to build a machine learning model?"}, {"answer_start": 94, "answer": "visual metaphor", "question": "What is a framework for building a machine learning model?"}, {"answer_start": 217, "answer": "understanding what dogs look like and what cats look like", "question": "What would a generative model have the goal of?"}, {"answer_start": 334, "answer": "draw", "question": "What does a generative model do to a dog?"}, {"answer_start": 401, "answer": "the cat model or the dog model", "question": "What is the best fit for a generative model?"}]}, {"context": "A discriminative model, by contrast, is only trying to learn to distinguish the classes (perhaps without learning much about them). So maybe all the dogs in the training data are wearing collars and the cats aren't. If that one feature neatly separates the classes, the model is satisfied. If you ask such a model what it knows about cats all it can say is that they don't wear collars.", "questions_and_answers": [{"answer_start": 2, "answer": "discriminative model", "question": "What type of model is trying to learn to distinguish classes?"}, {"answer_start": 187, "answer": "collars", "question": "What are all the dogs in training data wearing?"}, {"answer_start": 279, "answer": "satisfied", "question": "If a model separates the classes neatly, what is the result?"}, {"answer_start": 203, "answer": "cats", "question": "What animal does a model know about?"}]}, {"context": "More formally, recall that the naive Bayes assigns a class c to a document d not by directly computing P(c|d) but by computing a likelihood and a prior", "questions_and_answers": [{"answer_start": 114, "answer": "by computing a likelihood and a prior", "question": "How does Bayes assign a class c to a document d?"}]}, {"context": "expresses how to generate the features of a document if we knew it was of class c. By contrast a discriminative model in this text categorization scenario  attempts to directly compute P(c|d). Perhaps it will learn to assign a high weight to document features that directly improve its ability to discriminate between possible classes, even if it couldn\u2019t generate an example of one of the classes.", "questions_and_answers": [{"answer_start": 185, "answer": "P(c|d)", "question": "What does a discriminative model attempt to directly compute?"}, {"answer_start": 227, "answer": "high", "question": "What weight will a discriminative model learn to assign to document features?"}]}, {"context": "Components of a probabilistic machine learning classifier: Like naive Bayes, logistic regression is a probabilistic classifier that makes use of supervised machine learning. Machine learning classifiers require a training corpus of m input/output pairs (x (i) , y (i) ). (We'll use superscripts in parentheses to refer to individual instances in the training set-for sentiment classification each instance might be an individual document to be classified). A machine learning system for classification then has four components:", "questions_and_answers": [{"answer_start": 145, "answer": "supervised machine learning", "question": "What does logistic regression make use of?"}, {"answer_start": 232, "answer": "m input/output pairs", "question": "What do machine learning classifiers require a training corpus of?"}, {"answer_start": 282, "answer": "superscripts", "question": "What will we use in parentheses to refer to individual instances in the training set?"}, {"answer_start": 511, "answer": "four", "question": "How many components does a machine learning system for classification have?"}]}, {"context": "[ 2. ] A classification function that computes\u0177, the estimated class, via p(y|x). In the next section we will introduce the sigmoid and softmax tools for classification.", "questions_and_answers": [{"answer_start": 0, "answer": "[ 2. ]", "question": "What is the classification function that computes, the estimated class?"}, {"answer_start": 74, "answer": "p(y|x)", "question": "A classification function that computes, the estimated class, via what?"}, {"answer_start": 136, "answer": "softmax", "question": "The sigmoid and what other tool will be introduced?"}]}, {"context": "training: we train the system (specifically the weights w and b) using stochastic gradient descent and the cross-entropy loss.", "questions_and_answers": [{"answer_start": 44, "answer": "the weights w and b", "question": "What do we train the system specifically?"}, {"answer_start": 71, "answer": "stochastic gradient descent and the cross-entropy loss", "question": "What do we use to train the weights w and b?"}]}, {"context": "test: Given a test example x we compute p(y|x) and return the higher probability label y = 1 or y = 0.", "questions_and_answers": [{"answer_start": 87, "answer": "y = 1 or y = 0.", "question": "What is the higher probability label?"}, {"answer_start": 40, "answer": "p(y|x)", "question": "What do we compute given a test example x and return the higher probability label y = 1 or y = 0."}]}, {"context": "The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation. Here we introduce the sigmoid classifier that will help us make this decision. Consider a single input observation x, which we will represent by a vector of features [x 1 , x 2 , ..., x n ] (we'll show sample features in the next subsection). The classifier output y can be 1 (meaning the observation is a member of the class) or 0 (the observation is not a member of the class). We want to know the probability P(y = 1|x) that this observation is a member of the class. So perhaps the decision is \"positive sentiment\" versus \"negative sentiment\", the features represent counts of words in a document, P(y = 1|x) is the probability that the document has positive sentiment, and P(y = 0|x) is the probability that the document has negative sentiment. Logistic regression solves this task by learning, from a training set, a vector of weights and a bias term. Each weight w i is a real number, and is associated with one of the input features x i . The weight w i represents how important that input feature is to the classification decision, and can be positive (providing evidence that the instance being classified belongs in the positive class) or negative (providing evidence that the instance being classified belongs in the negative class). Thus we might expect in a sentiment task the word awesome to have a high positive weight, and abysmal to have a very negative weight. The bias term, also called the intercept, is bias term intercept another real number that's added to the weighted inputs.", "questions_and_answers": [{"answer_start": 12, "answer": "binary logistic regression", "question": "What is the goal of training a classifier that can make a binary decision about the class of a new input observation?"}, {"answer_start": 162, "answer": "sigmoid", "question": "What classifier will help us make a binary decision about the class of a new input observation?"}, {"answer_start": 255, "answer": "x", "question": "What is a single input observation?"}, {"answer_start": 309, "answer": "1", "question": "What is the classifier output y?"}, {"answer_start": 540, "answer": "probability", "question": "What does P(y = 1|x) want to know about a single input observation?"}, {"answer_start": 639, "answer": "positive sentiment", "question": "What is the probability P(y = 1|x) that the observation is a member of the class?"}, {"answer_start": 890, "answer": "Logistic regression", "question": "What solves this task by learning, from a training set, a vector of weights and a bias term?"}, {"answer_start": 1017, "answer": "a real number", "question": "What is each weight w i?"}, {"answer_start": 639, "answer": "positive", "question": "What can the weight w i be?"}, {"answer_start": 1436, "answer": "awesome", "question": "What word might have a high positive weight in a sentiment task?"}, {"answer_start": 1547, "answer": "the intercept", "question": "What is another name for the bias term?"}]}, {"context": "To make a decision on a test instance-after we've learned the weights in training-the classifier first multiplies each x i by its weight w i , sums up the weighted features, and adds the bias term b. The resulting single number z expresses the weighted sum of the evidence for the class.", "questions_and_answers": [{"answer_start": 183, "answer": "the bias term b", "question": "What does the classifier add to make a decision on a test instance?"}, {"answer_start": 103, "answer": "multiplies each x i by its weight w i", "question": "What does the classifier do to make a decision on a test instance?"}, {"answer_start": 240, "answer": "the weighted sum of the evidence for the class", "question": "What does the single number z express?"}]}, {"context": "In the rest of the book we'll represent such sums using the dot product notation from dot product linear algebra. The dot product of two vectors a and b, written as a [ \u2022 ] b is the sum of the products of the corresponding elements of each vector. Thus the following is an equivalent formation to Eq. [ 5.2 ]:", "questions_and_answers": [{"answer_start": 86, "answer": "dot product linear algebra", "question": "From what algebra is the dot product notation derived?"}, {"answer_start": 145, "answer": "a and b", "question": "The dot product of two vectors, written as a [ \u2022 ] b, is the sum of the products of the corresponding elements"}, {"answer_start": 273, "answer": "equivalent formation", "question": "What is the following formation to Eq. [ 5.2 ]?"}, {"answer_start": 303, "answer": "5.2", "question": "What is the equivalent formation to Eq."}]}, {"context": "But note that nothing in Eq. [ 5.3 ] forces z to be a legal probability, that is, to lie between 0 and 1. In fact, since weights are real-valued, the output might even be negative; z ranges from \u2212\u221e to \u221e. To create a probability, we'll pass z through the sigmoid function, \u03c3 (z). The sigmoid sigmoid function (named because it looks like an s) is also called the logistic function, and gives logistic regression its name. The sigmoid has the following equation,", "questions_and_answers": [{"answer_start": 14, "answer": "nothing", "question": "What forces z to be a legal probability?"}, {"answer_start": 89, "answer": "between 0 and 1", "question": "What is the legal probability of z?"}, {"answer_start": 44, "answer": "z", "question": "What ranges from  to?"}, {"answer_start": 254, "answer": "sigmoid function", "question": "To create a probability, we'll pass z through what?"}, {"answer_start": 362, "answer": "logistic function", "question": "What is the sigmoid sigmoid function also called?"}, {"answer_start": 451, "answer": "equation", "question": "What does the sigmoid have?"}]}, {"context": "(For the rest of the book, we'll use the notation exp(x) to mean e x .) The sigmoid has a number of advantages; it takes a real-valued number and maps it into the range [0, 1], which is just what we want for a probability. Because it is nearly linear around 0 but flattens toward the ends, it tends to squash outlier values toward 0 or 1. And it's differentiable, which as we'll see in Section [ 5.8 ] will be handy for learning.", "questions_and_answers": [{"answer_start": 50, "answer": "exp(x)", "question": "What is the notation used to mean e x?"}, {"answer_start": 115, "answer": "takes a real-valued number and maps it into the range", "question": "What does the sigmoid do?"}, {"answer_start": 331, "answer": "0 or 1", "question": "The sigmoid tends to squash outlier values toward what?"}, {"answer_start": 348, "answer": "differentiable", "question": "What is the advantage of the sigmoid?"}]}, {"context": "We're almost there. If we apply the sigmoid to the sum of the weighted features, we get a number between 0 and 1. To make it a probability, we just need to make sure that the two cases, p(y = 1) and p(y = 0), sum to 1. We can do this as follows:", "questions_and_answers": [{"answer_start": 0, "answer": "We're almost there", "question": "How far are we?"}, {"answer_start": 105, "answer": "0 and 1", "question": "If we apply the sigmoid to the sum of the weighted features, we get a number between what?"}, {"answer_start": 186, "answer": "p(y = 1) and p(y = 0),", "question": "What are the two cases that we need to make it a probability?"}, {"answer_start": 234, "answer": "as follows", "question": "How can we make sure that the two cases, p(y = 1) and p(y = 0), sum to 1?"}]}, {"context": "Now we have an algorithm that given an instance x computes the probability P(y = 1|x). How do we make a decision? For a test instance x, we say yes if the probability P(y = 1|x) is more than .5, and no otherwise. We call .5 the decision boundary:", "questions_and_answers": [{"answer_start": 75, "answer": "P(y = 1|x)", "question": "What does the algorithm compute when given an instance x?"}, {"answer_start": 97, "answer": "make a decision", "question": "What do we do with the algorithm that computes the probability P(y = 1|x)?"}, {"answer_start": 191, "answer": ".5", "question": "If the probability P(y = 1|x) is more than what, what is the decision boundary?"}, {"answer_start": 191, "answer": ".5", "question": "What is the decision boundary?"}]}, {"context": "Let's assume for the moment that we've already learned a real-valued weight for each of these features, and that the 6 weights corresponding to the 6 features are [[ 2.5 ], \u2212[ 5.0 ], \u2212[ 1.2 ], [ 0.5 ], [ 2.0 ], [ 0.7 ]], while b = [ 0.1 ]. (We'll discuss in the next section how the weights are learned.) The weight w 1 , for example indicates how important a feature the number of positive lexicon words (great, nice, enjoyable, etc.) is to a positive sentiment decision, while w 2 tells us the importance of negative lexicon words. Note that w 1 = [ 2.5 ] is positive, while w 2 = \u2212[ 5.0 ], meaning that negative words are negatively associated with a positive sentiment decision, and are about twice as important as positive words.", "questions_and_answers": [{"answer_start": 233, "answer": "0.1", "question": "What is the value of the weight b?"}, {"answer_start": 275, "answer": "how the weights are learned", "question": "What will we discuss in the next section?"}, {"answer_start": 316, "answer": "w 1", "question": "What weight indicates how important a feature the number of positive lexicon words is to a positive sentiment decision?"}, {"answer_start": 444, "answer": "positive sentiment decision", "question": "What does the weight w 1 indicate how important a feature the number of positive lexicon words is to?"}, {"answer_start": 606, "answer": "negative words", "question": "What words are negatively associated with a positive sentiment decision?"}]}, {"context": "Logistic regression is commonly applied to all sorts of NLP tasks, and any property of the input can be a feature. Consider the task of period disambiguation: deciding if a period is the end of a sentence or part of a word, by classifying each period into one of two classes EOS (end-of-sentence) and not-EOS. We might use features like x 1 below expressing that the current word is lower case (perhaps with a positive weight), or that the current word is in our abbreviations dictionary (\"Prof.\") (perhaps with a negative weight). A feature can also express a quite complex combination of properties. For example a period following an upper case word is likely to be an EOS, but if the word itself is St. and the previous word is capitalized, then the period is likely part of a shortening of the word street.", "questions_and_answers": [{"answer_start": 0, "answer": "Logistic regression", "question": "What is commonly applied to all sorts of NLP tasks?"}, {"answer_start": 280, "answer": "end-of-sentence", "question": "What does EOS stand for?"}, {"answer_start": 337, "answer": "x 1", "question": "What feature can be used to indicate that the current word is lower case?"}, {"answer_start": 561, "answer": "quite complex combination of properties", "question": "What can a feature express?"}, {"answer_start": 702, "answer": "St", "question": "If the word itself is what, the period is likely part of a shortening of the word street?"}]}, {"context": "Designing features: Features are generally designed by examining the training set with an eye to linguistic intuitions and the linguistic literature on the domain. A careful error analysis on the training set or devset of an early version of a system often provides insights into features.", "questions_and_answers": [{"answer_start": 97, "answer": "linguistic intuitions and the linguistic literature", "question": "What are features designed by examining the training set with an eye to?"}, {"answer_start": 20, "answer": "Features", "question": "What are generally designed by examining the training set with an eye to linguistic intuitions and the linguistic literature on the domain?"}, {"answer_start": 164, "answer": "A careful error analysis", "question": "What provides insights into features?"}]}, {"context": "For some tasks it is especially helpful to build complex features that are combinations of more primitive features. We saw such a feature for period disambiguation above, where a period on the word St. was less likely to be the end of the sentence if the previous word was capitalized. For logistic regression and naive Bayes these combination features or feature interactions have to be designed by hand.", "questions_and_answers": [{"answer_start": 49, "answer": "complex features", "question": "For some tasks it is especially helpful to build what that are combinations of more primitive features?"}, {"answer_start": 142, "answer": "period disambiguation", "question": "What is an example of a feature that is a combination of more primitive features?"}, {"answer_start": 397, "answer": "by hand", "question": "How are logistic regression and naive Bayes designed?"}]}, {"context": "For many tasks (especially when feature values can reference specific words) we'll need large numbers of features. Often these are created automatically via feature templates, abstract specifications of features. For example a bigram template feature templates for period disambiguation might create a feature for every pair of words that occurs before a period in the training set. Thus the feature space is sparse, since we only have to create a feature if that n-gram exists in that position in the training set. The feature is generally created as a hash from the string descriptions. A user description of a feature as, \"bigram(American breakfast)\" is hashed into a unique integer i that becomes the feature number f i .", "questions_and_answers": [{"answer_start": 88, "answer": "large numbers of features", "question": "For many tasks, what do we need?"}, {"answer_start": 157, "answer": "feature templates", "question": "What are abstract specifications of features called?"}, {"answer_start": 227, "answer": "bigram template feature templates", "question": "What can create a feature for every pair of words that occurs before a period in the training set?"}, {"answer_start": 392, "answer": "feature space is sparse", "question": "What is the result of a bigram template feature templates for period disambiguation?"}, {"answer_start": 552, "answer": "a hash", "question": "What is a feature usually created as from the string descriptions?"}, {"answer_start": 626, "answer": "bigram(American breakfast)", "question": "What is a user description of a feature called?"}]}, {"context": "In order to avoid the extensive human effort of feature design, recent research in NLP has focused on representation learning: ways to learn features automatically in an unsupervised way from the input. We'll introduce methods for representation learning in Chapter 6 and Chapter 7.", "questions_and_answers": [{"answer_start": 48, "answer": "feature design", "question": "What human effort does NLP avoid?"}, {"answer_start": 258, "answer": "Chapter 6 and Chapter 7", "question": "Where will we introduce methods for representation learning?"}]}, {"context": "Choosing a classifier Logistic regression has a number of advantages over naive Bayes. Naive Bayes has overly strong conditional independence assumptions. Consider two features which are strongly correlated; in fact, imagine that we just add the same feature f 1 twice. Naive Bayes will treat both copies of f 1 as if they were separate, multiplying them both in, overestimating the evidence. By contrast, logistic regression is much more robust to correlated features; if two features f 1 and f 2 are perfectly correlated, regression will simply assign part of the weight to w 1 and part to w 2 . Thus when there are many correlated features, logistic regression will assign a more accurate probability than naive Bayes. So logistic regression generally works better on larger documents or datasets and is a common default.", "questions_and_answers": [{"answer_start": 22, "answer": "Logistic regression", "question": "What classifier has a number of advantages over naive Bayes?"}, {"answer_start": 117, "answer": "conditional independence assumptions", "question": "What assumptions do naive Bayes have that are overly strong?"}, {"answer_start": 259, "answer": "f 1 twice", "question": "How many times would you add the same feature to two features that are strongly correlated?"}, {"answer_start": 259, "answer": "f 1", "question": "What feature does naive Bayes treat as if they were separate?"}, {"answer_start": 449, "answer": "correlated features", "question": "What is logistic regression more robust to than naive Bayes?"}, {"answer_start": 678, "answer": "more accurate probability", "question": "What does logistic regression assign when there are many correlated features?"}, {"answer_start": 771, "answer": "larger documents or datasets", "question": "Where does logistic regression generally work better than naive Bayes?"}]}, {"context": "Despite the less accurate probabilities, naive Bayes still often makes the correct classification decision. Furthermore, naive Bayes can work extremely well (sometimes even better than logistic regression) on very small datasets (Ng and Jordan, 2002) or short documents (Wang and Manning, 2012). Furthermore, naive Bayes is easy to implement and very fast to train (there's no optimization step). So it's still a reasonable approach to use in some situations.", "questions_and_answers": [{"answer_start": 83, "answer": "classification decision", "question": "What does naive Bayes often make?"}, {"answer_start": 185, "answer": "logistic regression", "question": "What is naive Bayes sometimes better than?"}, {"answer_start": 41, "answer": "naive Bayes", "question": "What is easy to implement and very fast to train?"}, {"answer_start": 411, "answer": "a reasonable approach", "question": "What is naive Bayes to use in some situations?"}]}, {"context": "How are the parameters of the model, the weights w and bias b, learned? Logistic regression is an instance of supervised classification in which we know the correct label y (either 0 or 1) for each observation x. What the system produces via Eq. [ 5.5 ] is\u0177, the system's estimate of the true y. We want to learn parameters (meaning w and b) that make\u0177 for each training observation as close as possible to the true y.", "questions_and_answers": [{"answer_start": 8, "answer": "the parameters of the model", "question": "What are the weights w and bias b?"}, {"answer_start": 72, "answer": "Logistic regression", "question": "What is an instance of supervised classification in which we know the correct label y (either 0 or 1) for each observation x?"}, {"answer_start": 259, "answer": "the system's estimate of the true y", "question": "What does the system produce via Eq. [ 5.5 ]?"}, {"answer_start": 383, "answer": "as close as possible to the true y", "question": "What do we want to learn parameters that make for each training observation?"}]}, {"context": "The second thing we need is an optimization algorithm for iteratively updating the weights so as to minimize this loss function. The standard algorithm for this is gradient descent; we'll introduce the stochastic gradient descent algorithm in the following section.", "questions_and_answers": [{"answer_start": 28, "answer": "an optimization algorithm", "question": "What is needed for iteratively updating the weights?"}, {"answer_start": 202, "answer": "stochastic gradient descent algorithm", "question": "What algorithm will we introduce in the following section?"}, {"answer_start": 164, "answer": "gradient descent", "question": "What is the standard algorithm for optimizing weights?"}]}, {"context": "We do this via a loss function that prefers the correct class labels of the training examples to be more likely. This is called conditional maximum likelihood estimation: we choose the parameters w, b that maximize the log probability of the true y labels in the training data given the observations x. The resulting loss function is the negative log likelihood loss, generally called the cross-entropy loss.", "questions_and_answers": [{"answer_start": 15, "answer": "a loss function", "question": "What is used to prefer the correct class labels of the training examples to be more likely?"}, {"answer_start": 128, "answer": "conditional maximum likelihood estimation", "question": "What is the loss function that prefers the correct class labels of the training examples to be more likely called?"}, {"answer_start": 389, "answer": "cross-entropy loss", "question": "What is another name for the negative log likelihood loss?"}]}, {"context": "Let's derive this loss function, applied to a single observation x. We'd like to learn weights that maximize the probability of the correct label p(y|x). Since there are only two discrete outcomes (1 or 0), this is a Bernoulli distribution, and we can express the probability p(y|x) that our classifier produces for one observation as the following (keeping in mind that if y=1, Eq. [ 5.9 ] simplifies to\u0177; if y=0, Eq. [ 5.9 ] simplifies to 1 \u2212\u0177):", "questions_and_answers": [{"answer_start": 65, "answer": "x", "question": "Let's derive this loss function, applied to a single observation what?"}, {"answer_start": 146, "answer": "p(y|x)", "question": "What do we want to learn weights that maximize the probability of the correct label?"}, {"answer_start": 217, "answer": "Bernoulli", "question": "What distribution is the loss function p(y|x) a part of?"}, {"answer_start": 410, "answer": "y=0", "question": "What does Eq. [ 5.9 ] simplify to?"}, {"answer_start": 198, "answer": "1", "question": "If y=0, Eq. [ 5.9 ] simplifies to what?"}]}, {"context": "Now we take the log of both sides. This will turn out to be handy mathematically, and doesn't hurt us; whatever values maximize a probability will also maximize the log of the probability:", "questions_and_answers": [{"answer_start": 16, "answer": "log of both sides", "question": "What is the log of the probability?"}, {"answer_start": 103, "answer": "whatever values maximize a probability", "question": "What will also maximize the log of the probability?"}]}, {"context": "By contrast, let's pretend instead that the example in Figure 5 .2 was actually negative, i.e., y = 0 (perhaps the reviewer went on to say \"But bottom line, the movie is terrible! I beg you not to see it!\"). In this case our model is confused and we'd want the loss to be higher. Now if we plug y = 0 and 1 \u2212 \u03c3 (w [ \u2022 ] x + b) = .31 from Eq. [ 5.7 ] into Eq. [ 5.12 ], the left side of the equation drops out:", "questions_and_answers": [{"answer_start": 96, "answer": "y = 0", "question": "What is the result of Figure 5.2?"}, {"answer_start": 180, "answer": "I beg you not to see it", "question": "What did the reviewer say about the movie?"}, {"answer_start": 272, "answer": "higher", "question": "What would we want the loss to be in this case?"}, {"answer_start": 329, "answer": ".31", "question": "What is the left side of the equation if we plug y = 0 and 1   (w [ \u2022 ] x"}, {"answer_start": 344, "answer": "5.7", "question": "What is Eq. [ 5.12]?"}, {"answer_start": 369, "answer": "the left side of the equation", "question": "If we plug y = 0 and 1   (w [ \u2022 ] x + b) =.31 into"}]}, {"context": "Sure enough, the loss for the first classifier (.37) is less than the loss for the second classifier ([ 1.17 ]). Why does minimizing this negative log probability do what we want? A perfect classifier would assign probability 1 to the correct outcome (y=1 or y=0) and probability 0 to the incorrect outcome. That means the higher\u0177 (the closer it is to 1), the better the classifier; the lower\u0177 is (the closer it is to 0), the worse the classifier. The negative log of this probability is a convenient loss metric since it goes from 0 (negative log of 1, no loss) to infinity (negative log of 0, infinite loss). This loss function also ensures that as the probability of the correct answer is maximized, the probability of the incorrect answer is minimized; since the two sum to one, any increase in the probability of the correct answer is coming at the expense of the incorrect answer. It's called the cross-entropy loss, because Eq. [ 5.10 ] is also the formula for the cross-entropy between the true probability distribution y and our estimated distribution\u0177.", "questions_and_answers": [{"answer_start": 48, "answer": ".37", "question": "What is the loss for the first classifier?"}, {"answer_start": 138, "answer": "negative log probability", "question": "What does minimizing the loss for the first classifier do?"}, {"answer_start": 214, "answer": "probability 1", "question": "What would a perfect classifier assign to the correct outcome?"}, {"answer_start": 332, "answer": "the closer it is to 1)", "question": "What is the higher the classifier, the better it is?"}, {"answer_start": 535, "answer": "negative log of 1, no loss", "question": "What is the negative log of the probability?"}, {"answer_start": 703, "answer": "the probability of the incorrect answer is minimized", "question": "What happens when the probability of the correct answer is maximized?"}, {"answer_start": 903, "answer": "cross-entropy loss", "question": "What is the loss function that ensures that as the probability of the correct answer is maximized, the probability of the incorrect answer is minimized?"}, {"answer_start": 937, "answer": "5.10", "question": "What is the formula for the cross-entropy between the true probability distribution y and our estimated distribution?"}]}, {"context": "Now we know what we want to minimize; in the next section, we'll see how to find the minimum.", "questions_and_answers": [{"answer_start": 28, "answer": "minimize", "question": "What do we want to do?"}]}, {"context": "How shall we find the minimum of this (or any) loss function? Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters \u03b8 ) the function's slope is rising the most steeply, and moving in the opposite direction. The intuition is that if you are hiking in a canyon and trying to descend most quickly down to the river at the bottom, you might look around yourself 360 degrees, find the direction where the ground is sloping the steepest, and walk downhill in that direction.", "questions_and_answers": [{"answer_start": 0, "answer": "How shall we find the minimum", "question": "What is the purpose of Gradient descent?"}, {"answer_start": 62, "answer": "Gradient descent", "question": "What is a method that finds a minimum of a function by figuring out in which direction the function's slope is rising the most steep"}, {"answer_start": 435, "answer": "360", "question": "How many degrees would you look around yourself to find the direction where the ground is sloping the steepest?"}]}, {"context": "For logistic regression, this loss function is conveniently convex. A convex funcconvex tion has just one minimum; there are no local minima to get stuck in, so gradient descent starting from any point is guaranteed to find the minimum. (By contrast, the loss for multi-layer neural networks is non-convex, and gradient descent may get stuck in local minima for neural network training and never find the global optimum.) Although the algorithm (and the concept of gradient) are designed for direction vectors, let's first consider a visualization of the case where the parameter of our system is just a single scalar w, shown in Figure 5 .3.", "questions_and_answers": [{"answer_start": 60, "answer": "convex", "question": "What is the loss function for logistic regression?"}, {"answer_start": 102, "answer": "one minimum", "question": "How many minimums does a convex funcconvex tion have?"}, {"answer_start": 295, "answer": "non-convex", "question": "What is the loss for multi-layer neural networks?"}, {"answer_start": 492, "answer": "direction vectors", "question": "What is the algorithm and concept of gradient designed for?"}]}, {"context": "Given a random initialization of w at some value w 1 , and assuming the loss function L happened to have the shape in Figure 5 .3, we need the algorithm to tell us whether at the next iteration we should move left (making w 2 smaller than w 1 ) or right (making w 2 bigger than w 1 ) to reach the minimum. .3 The first step in iteratively finding the minimum of this loss function, by moving w in the reverse direction from the slope of the function. Since the slope is negative, we need to move w in a positive direction, to the right. Here superscripts are used for learning steps, so w 1 means the initial value of w (which is 0), w 2 at the second step, and so on.", "questions_and_answers": [{"answer_start": 222, "answer": "w 2", "question": "What is smaller than w 1?"}, {"answer_start": 382, "answer": "by moving w in the reverse direction from the slope of the function", "question": "What is the first step in iteratively finding the minimum of the loss function?"}, {"answer_start": 503, "answer": "positive", "question": "In order to find the minimum of the loss function, we need to move w in what direction?"}, {"answer_start": 542, "answer": "superscripts", "question": "What are used for learning steps?"}]}, {"context": "Now let's extend the intuition from a function of one scalar variable w to many variables, because we don't just want to move left or right, we want to know where in the N-dimensional space (of the N parameters that make up \u03b8 ) we should move. The gradient is just such a vector; it expresses the directional components of the sharpest slope along each of those N dimensions. If we're just imagining two weight dimensions (say for one weight w and one bias b), the gradient might be a vector with two orthogonal components, each of which tells us how much the ground slopes in the w dimension and in the b dimension. In an actual logistic regression, the parameter vector w is much longer than 1 or 2, since the input feature vector x can be quite long, and we need a weight w i for each x i . For each dimension/variable w i in w (plus the bias b), the gradient will have a component that tells us the slope with respect to that variable. Essentially we're asking: \"How much would a small change in that variable w i influence the total loss function L?\"", "questions_and_answers": [{"answer_start": 170, "answer": "N-dimensional space", "question": "Where do we want to know where to move?"}, {"answer_start": 244, "answer": "The gradient", "question": "What is a vector that expresses the directional components of the sharpest slope along each of the N dimensions?"}, {"answer_start": 400, "answer": "two weight dimensions", "question": "What is a vector with two orthogonal components that tells us how much the ground slopes in the w dimension and in the b"}, {"answer_start": 682, "answer": "longer than 1 or 2", "question": "In an actual logistic regression, the parameter vector w is much what?"}, {"answer_start": 899, "answer": "the slope", "question": "For each dimension/variable w i in w (plus the bias b), the gradient will have a component that tells us"}, {"answer_start": 967, "answer": "How much would a small change in that variable w i influence the total loss function L?", "question": "How much would a small change in a variable w i influence the total loss function L?"}]}, {"context": "In each dimension w i , we express the slope as a partial derivative \u2202 \u2202 w i of the loss function. The gradient is then defined as a vector of these partials. We'll represent\u0177 as f (x; \u03b8 ) to make the dependence on \u03b8 more obvious:", "questions_and_answers": [{"answer_start": 18, "answer": "w i", "question": "In which dimension is the slope expressed as a partial derivative   w i of the loss function?"}, {"answer_start": 131, "answer": "a vector", "question": "What is the gradient defined as?"}, {"answer_start": 78, "answer": "f", "question": "We'll represent the gradient as what?"}]}, {"context": "In order to update \u03b8 , we need a definition for the gradient \u2207L( f (x; \u03b8 ), y). Recall that for logistic regression, the cross-entropy loss function is:", "questions_and_answers": [{"answer_start": 76, "answer": "y", "question": "In order to update , we need a definition for the gradient L( f (x);  ), what is"}, {"answer_start": 121, "answer": "cross-entropy loss function", "question": "What function is used for logistic regression?"}]}, {"context": "Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example, and nudging \u03b8 in the right direction (the opposite direction of the gradient). (an \"online algorithm\" is one that processes its input example by example, rather than waiting until it sees the entire input). x is the set of training inputs", "questions_and_answers": [{"answer_start": 0, "answer": "Stochastic gradient descent", "question": "What is an online algorithm that minimizes the loss function by computing its gradient after each training example?"}, {"answer_start": 219, "answer": "an \"online algorithm\"", "question": "What is one that processes its input example by example, rather than waiting until it sees the entire input?"}, {"answer_start": 131, "answer": "x", "question": "What is the set of training inputs?"}]}, {"context": "The learning rate \u03b7 is a hyperparameter that must be adjusted. If it's too high, hyperparameter the learner will take steps that are too large, overshooting the minimum of the loss function. If it's too low, the learner will take steps that are too small, and take too long to get to the minimum. It is common to start with a higher learning rate and then slowly decrease it, so that it is a function of the iteration k of training; the notation \u03b7 k can be used to mean the value of the learning rate at iteration k.", "questions_and_answers": [{"answer_start": 25, "answer": "hyperparameter", "question": "What is the learning rate?"}, {"answer_start": 96, "answer": "the learner will take steps that are too large", "question": "What happens if the learning rate is too high?"}, {"answer_start": 225, "answer": "take steps that are too small, and take too long to get to the minimum", "question": "What happens if the learning rate is too low?"}, {"answer_start": 408, "answer": "iteration k", "question": "What is the learning rate a function of?"}]}, {"context": "We'll discuss hyperparameters in more detail in Chapter 7, but briefly they are a special kind of parameter for any machine learning model. Unlike regular parameters of a model (weights like w and b), which are learned by the algorithm from the training set, hyperparameters are special parameters chosen by the algorithm designer that affect how the algorithm works.", "questions_and_answers": [{"answer_start": 14, "answer": "hyperparameters", "question": "What is a special kind of parameter for any machine learning model?"}, {"answer_start": 14, "answer": "hyperparameters", "question": "What are special parameters chosen by the algorithm designer that affect how the algorithm works?"}]}, {"context": "x 2 = 2 (count of negative lexicon words) Let's assume the initial weights and bias in \u03b8 0 are all set to 0, and the initial learning rate \u03b7 is [ 0.1 ]:", "questions_and_answers": [{"answer_start": 0, "answer": "x 2 = 2", "question": "What is the number of negative lexicon words?"}]}, {"context": "The single update step requires that we compute the gradient, multiplied by the learning rate", "questions_and_answers": [{"answer_start": 48, "answer": "the gradient", "question": "What is computed in a single update step?"}, {"answer_start": 76, "answer": "the learning rate", "question": "What is the gradient multiplied by?"}]}, {"context": "Note that this observation x happened to be a positive example. We would expect that after seeing more negative examples with high counts of negative words, that the weight w 2 would shift to have a negative value.", "questions_and_answers": [{"answer_start": 27, "answer": "x", "question": "What was a positive example?"}, {"answer_start": 103, "answer": "negative", "question": "What type of examples did we expect to see more of?"}]}, {"context": "Stochastic gradient descent is called stochastic because it chooses a single random example at a time, moving the weights so as to improve performance on that single example. That can result in very choppy movements, so it's common to compute the gradient over batches of training instances rather than a single instance.", "questions_and_answers": [{"answer_start": 0, "answer": "Stochastic gradient descent", "question": "What is called stochastic because it chooses a single random example at a time?"}, {"answer_start": 194, "answer": "very choppy movements", "question": "What can stochastic gradient descent result in?"}]}, {"context": "For example in batch training we compute the gradient over the entire dataset.", "questions_and_answers": [{"answer_start": 41, "answer": "the gradient", "question": "In batch training, what is computed over the entire dataset?"}]}, {"context": "By seeing so many examples, batch training offers a superb estimate of which direction to move the weights, at the cost of spending a lot of time processing every single example in the training set to compute this perfect direction.", "questions_and_answers": [{"answer_start": 28, "answer": "batch training", "question": "What offers a superb estimate of which direction to move the weights?"}]}, {"context": "A compromise is mini-batch training: we train on a group of m examples (permini-batch haps 512, or 1024) that is less than the whole dataset. (If m is the size of the dataset, then we are doing batch gradient descent; if m = 1, we are back to doing stochastic gradient descent). Mini-batch training also has the advantage of computational efficiency. The mini-batches can easily be vectorized, choosing the size of the minibatch based on the computational resources. This allows us to process all the examples in one mini-batch in parallel and then accumulate the loss, something that's not possible with individual or batch training. We just need to define mini-batch versions of the cross-entropy loss function we defined in Section [ 5.3 ] and the gradient in Section [ 5.4 ].1. Let's extend the crossentropy loss for one example from Eq. [ 5.11 ] to mini-batches of size m. We'll continue to use the notation that x (i) and y (i) mean the ith training features and training label, respectively. We make the assumption that the training examples are independent:", "questions_and_answers": [{"answer_start": 16, "answer": "mini-batch training", "question": "What is a compromise?"}, {"answer_start": 4, "answer": "m", "question": "What is the size of the dataset?"}, {"answer_start": 325, "answer": "computational efficiency", "question": "What advantage does mini-batch training have?"}, {"answer_start": 351, "answer": "The mini-batches", "question": "What can easily be vectorized?"}, {"answer_start": 549, "answer": "accumulate the loss", "question": "What is not possible with individual or batch training?"}, {"answer_start": 727, "answer": "Section [ 5.3 ] and the gradient in Section [ 5.4 ].1", "question": "Where did we define mini-batch versions of the cross-entropy loss function?"}, {"answer_start": 601, "answer": "ith", "question": "What do x and y mean?"}, {"answer_start": 1053, "answer": "independent", "question": "We make the assumption that the training examples are what?"}]}, {"context": "Now the cost function for the mini-batch of m examples is the average loss for each example:", "questions_and_answers": [{"answer_start": 58, "answer": "the average loss for each example", "question": "What is the cost function for the mini-batch of m examples?"}]}, {"context": "There is a problem with learning weights that make the model perfectly match the training data. If a feature is perfectly predictive of the outcome because it happens to only occur in one class, it will be assigned a very high weight. The weights for features will attempt to perfectly fit details of the training set, in fact too perfectly, modeling noisy factors that just accidentally correlate with the class. This problem is called overfitting. A good model should be able to generalize well from the training overfitting generalize data to the unseen test set, but a model that overfits will have poor generalization.", "questions_and_answers": [{"answer_start": 24, "answer": "learning weights", "question": "What makes the model perfectly match the training data?"}, {"answer_start": 156, "answer": "it happens to only occur in one class", "question": "Why is a feature assigned a high weight?"}, {"answer_start": 351, "answer": "noisy factors", "question": "What will the weights for features accidentally correlate with the class?"}, {"answer_start": 437, "answer": "overfitting", "question": "What is the problem with learning weights that model noisy factors that just accidentally correlate with the class called?"}, {"answer_start": 603, "answer": "poor generalization", "question": "What will a model that overfits have?"}]}, {"context": "the weight values, named because it uses the (square of the) L2 norm of the weight values. The L2 norm, ||\u03b8 || 2 , is the same as the Euclidean distance of the vector \u03b8 from the origin. If \u03b8 consists of n weights, then:", "questions_and_answers": [{"answer_start": 61, "answer": "L2", "question": "The weight values are named because it uses the square of what norm of the weight values?"}, {"answer_start": 134, "answer": "Euclidean distance", "question": "The L2 norm is the same as what distance of the vector  from the origin?"}, {"answer_start": 203, "answer": "n weights", "question": "What does  consist of?"}]}, {"context": "L1 regularization is a linear function of the weight values, named after the L1 norm L1 regularization ||W || 1 , the sum of the absolute values of the weights, or Manhattan distance (the Manhattan distance is the distance you'd have to walk between two points in a city with a street grid like New York):", "questions_and_answers": [{"answer_start": 164, "answer": "Manhattan distance", "question": "What is the distance you'd have to walk between two points in a city with a street grid like New York called?"}, {"answer_start": 164, "answer": "Manhattan", "question": "What is the distance you'd have to walk between two points in a city with a street grid like New York?"}]}, {"context": "These kinds of regularization come from statistics, where L1 regularization is called lasso regression (Tibshirani, 1996) and L2 regularization is called ridge regression, lasso ridge and both are commonly used in language processing. L2 regularization is easier to optimize because of its simple derivative (the derivative of \u03b8 2 is just 2\u03b8 ), while L1 regularization is more complex (the derivative of |\u03b8 | is non-continuous at zero).", "questions_and_answers": [{"answer_start": 86, "answer": "lasso regression", "question": "What is L1 regularization called?"}, {"answer_start": 154, "answer": "ridge regression", "question": "What is L2 regularization called?"}, {"answer_start": 290, "answer": "simple derivative", "question": "Why is L2 regularization easier to optimize?"}]}, {"context": "But where L2 prefers weight vectors with many small weights, L1 prefers sparse solutions with some larger weights but many more weights set to zero. Thus L1 regularization leads to much sparser weight vectors, that is, far fewer features.", "questions_and_answers": [{"answer_start": 72, "answer": "sparse solutions", "question": "What type of weight vectors does L1 prefer?"}, {"answer_start": 154, "answer": "L1 regularization", "question": "What leads to much sparser weight vectors?"}]}, {"context": "If we multiply each weight by a Gaussian prior on the weight, we are thus maximizing the following constraint:", "questions_and_answers": [{"answer_start": 74, "answer": "maximizing", "question": "If we multiply each weight by a Gaussian prior on the weight, we are what?"}, {"answer_start": 30, "answer": "a Gaussian prior", "question": "If we multiply each weight by what on the weight, we are maximizing the following constraint?"}]}, {"context": "Sometimes we need more than two classes. Perhaps we might want to do 3-way sentiment classification (positive, negative, or neutral). Or we could be assigning some of the labels we will introduce in Chapter 8, like the part of speech of a word (choosing from 10, 30, or even 50 different parts of speech), or the named entity type of a phrase (choosing from tags like person, location, organization). In such cases we use multinomial logistic regression, also called softmax regression (or, historically, the maxent classifier). In multinomial logistic regression the target y is a variable that ranges over more than two classes; we want to know the probability of y being in each potential class c \u2208 C, p(y = c|x).", "questions_and_answers": [{"answer_start": 18, "answer": "more than two classes", "question": "Sometimes we need how many classes?"}, {"answer_start": 101, "answer": "positive, negative, or neutral", "question": "What is a 3-way sentiment classification?"}, {"answer_start": 259, "answer": "10, 30, or even 50", "question": "How many different parts of speech can a word be chosen from?"}, {"answer_start": 467, "answer": "softmax regression", "question": "What is another name for multinomial logistic regression?"}, {"answer_start": 73, "answer": "y", "question": "What is a variable that ranges over more than two classes in multinomial logistic regression?"}]}, {"context": "The denominator k i=1 exp (z i ) is used to normalize all the values into probabilities. Thus for example given a vector:", "questions_and_answers": [{"answer_start": 27, "answer": "z i", "question": "What is the denominator used to normalize all values into probabilities?"}, {"answer_start": 16, "answer": "k i=1 exp", "question": "What is the denominator used to normalize all values into probabilities?"}, {"answer_start": 114, "answer": "vector", "question": "What is an example of a vector?"}]}, {"context": "the resulting (rounded) softmax(z) is [[ 0.055 ], [ 0.090 ], [ 0.006 ], [ 0.099 ], [ 0.74 ], [ 0.010 ]] Again like the sigmoid, the input to the softmax will be the dot product between a weight vector w and an input vector x (plus a bias). But now we'll need separate weight vectors (and bias) for each of the K classes.", "questions_and_answers": [{"answer_start": 119, "answer": "sigmoid", "question": "The input to the softmax will be the dot product between a weight vector w and an input vector x (plus a bias)"}, {"answer_start": 153, "answer": "w", "question": "What is the dot product between a weight vector w and an input vector x?"}, {"answer_start": 30, "answer": "x", "question": "What is the resulting softma?"}, {"answer_start": 259, "answer": "separate weight vectors", "question": "What do we need for each of the K classes?"}]}, {"context": "Like the sigmoid, the softmax has the property of squashing values toward 0 or 1. Thus if one of the inputs is larger than the others, it will tend to push its probability toward 1, and suppress the probabilities of the smaller inputs.", "questions_and_answers": [{"answer_start": 50, "answer": "squashing values toward 0 or 1", "question": "What property does the softmax have?"}, {"answer_start": 151, "answer": "push its probability toward 1,", "question": "What will the softmax do if one of the inputs is larger than the others?"}]}, {"context": "Features in multinomial logistic regression function similarly to binary logistic regression, with one difference that we'll need separate weight vectors (and biases) for each of the K classes. Recall our binary exclamation point feature x 5 from page 80:", "questions_and_answers": [{"answer_start": 130, "answer": "separate weight vectors", "question": "What do we need for each of the K classes?"}, {"answer_start": 247, "answer": "page 80", "question": "Where is our binary exclamation point feature x 5 from?"}]}, {"context": "In binary classification a positive weight w 5 on a feature influences the classifier toward y = 1 (positive sentiment) and a negative weight influences it toward y = 0 (negative sentiment) with the absolute value indicating how important the feature is. For multinominal logistic regression, by contrast, with separate weights for each class, a feature can be evidence for or against each individual class.", "questions_and_answers": [{"answer_start": 100, "answer": "positive sentiment", "question": "What does a positive weight w 5 on a feature influence the classifier toward y = 1?"}, {"answer_start": 170, "answer": "negative sentiment", "question": "What does a negative weight influence a classifier toward y = 0?"}, {"answer_start": 100, "answer": "positive sentiment", "question": "What does a positive weight w 5 on a feature influence the classifier toward y = 1?"}, {"answer_start": 361, "answer": "evidence for or against each individual class", "question": "What can a feature be in multinominal logistic regression?"}]}, {"context": "In 3-way multiclass sentiment classification, for example, we must assign each document one of the 3 classes +, \u2212, or 0 (neutral). Now a feature related to exclamation marks might have a negative weight for 0 documents, and a positive weight for + or \u2212 documents:", "questions_and_answers": [{"answer_start": 121, "answer": "neutral", "question": "In 3-way multiclass sentiment classification, what class is assigned to each document?"}, {"answer_start": 156, "answer": "exclamation marks", "question": "What feature might have a negative weight for 0 documents?"}]}, {"context": "Because these feature weights are dependent both on the input text and the output class, we sometimes make this dependence explicit and represent the features themselves as f (x, y): a function of both the input and the class. Using such a notation f 5 (x) above could be represented as three features f 5 (x, +), f 5 (x, \u2212), and f 5 (x, 0), each of which has a single weight.", "questions_and_answers": [{"answer_start": 14, "answer": "feature weights", "question": "What are dependent both on the input text and the output class?"}, {"answer_start": 307, "answer": "x, +", "question": "What are the three features f 5 (x), f 5 (x, ), and f 5 (x, 0) represented"}, {"answer_start": 335, "answer": "x, 0", "question": "What is the weight of f 5?"}]}, {"context": "The loss function for multinomial logistic regression generalizes the loss function for binary logistic regression from 2 to K classes. Recall that that the cross-entropy loss for binary logistic regression (repeated from Eq. [ 5.11 ]) is:", "questions_and_answers": [{"answer_start": 4, "answer": "loss function for multinomial logistic regression", "question": "What generalizes the loss function for binary logistic regression from 2 to K classes?"}, {"answer_start": 157, "answer": "cross-entropy loss", "question": "What is the loss function for binary logistic regression?"}, {"answer_start": 228, "answer": "5.11", "question": "What is the cross-entropy loss for binary logistic regression?"}]}, {"context": "The loss function for multinominal logistic regression generalizes the two terms in Eq. [ 5.33 ] (one that is non-zero when y = 1 and one that is non-zero when y = 0) to K terms. The loss function for a single example x is thus the sum of the logs of the K output classes, each weighted by y k , the probability of the true class :", "questions_and_answers": [{"answer_start": 22, "answer": "multinominal logistic regression", "question": "What generalizes the two terms in Eq. [ 5.33 ] (one that is non-zero when y = 1 and one"}, {"answer_start": 98, "answer": "one", "question": "What term is non-zero when y = 1 and one that is non-zero when y = 0?"}, {"answer_start": 228, "answer": "the sum of the logs of the K output classes", "question": "What is the loss function for a single example x?"}]}, {"context": "The gradient for a single example turns out to be very similar to the gradient for binary logistic regression, although we don't show the derivation here. It is the difference between the value for the true class k (which is 1) and the probability the classifier outputs for class k, weighted by the value of the input x i corresponding to the ith element of the weight for class k w k,i :", "questions_and_answers": [{"answer_start": 83, "answer": "binary logistic regression", "question": "The gradient for a single example turns out to be very similar to the gradient for what?"}, {"answer_start": 161, "answer": "the difference between the value for the true class k (which is 1) and the probability the classifier outputs for class k", "question": "What is the gradient for a single example?"}]}, {"context": "Often we want to know more than just the correct classification of an observation. We want to know why the classifier made the decision it did. That is, we want our decision to be interpretable. Interpretability can be hard to define strictly, but the interpretable core idea is that as humans we should know why our algorithms reach the conclusions they do. Because the features to logistic regression are often human-designed, one way to understand a classifier's decision is to understand the role each feature plays in the decision. Logistic regression can be combined with statistical tests (the likelihood ratio test, or the Wald test); investigating whether a particular feature is significant by one of these tests, or inspecting its magnitude (how large is the weight w associated with the feature?) can help us interpret why the classifier made the decision it makes. This is enormously important for building transparent models. Furthermore, in addition to its use as a classifier, logistic regression in NLP and many other fields is widely used as an analytic tool for testing hypotheses about the effect of various explanatory variables (features). In text classification, perhaps we want to know if logically negative words (no, not, never) are more likely to be associated with negative sentiment, or if negative reviews of movies are more likely to discuss the cinematography. However, in doing so it's necessary to control for potential confounds: other factors that might influence sentiment (the movie genre, the year it was made, perhaps the length of the review in words). Or we might be studying the relationship between NLP-extracted linguistic features and non-linguistic outcomes (hospital readmissions, political outcomes, or product sales), but need to control for confounds (the age of the patient, the county of voting, the brand of the product). In such cases, logistic regression allows us to test whether some feature is associated with some outcome above and beyond the effect of other features.", "questions_and_answers": [{"answer_start": 22, "answer": "more", "question": "What do we often want to know more than just the correct classification of an observation?"}, {"answer_start": 99, "answer": "why the classifier made the decision it did", "question": "What do we want to know?"}, {"answer_start": 180, "answer": "interpretable", "question": "What do we want our decision to be?"}, {"answer_start": 309, "answer": "why our algorithms reach the conclusions they do", "question": "What is the interpretable core idea?"}, {"answer_start": 478, "answer": "to understand the role each feature plays in the decision", "question": "What is one way to understand a classifier's decision?"}, {"answer_start": 601, "answer": "likelihood ratio test, or the Wald test", "question": "What are two statistical tests that can be combined with logistic regression?"}, {"answer_start": 831, "answer": "why the classifier made the decision it makes", "question": "What can logistic regression help us interpret?"}, {"answer_start": 920, "answer": "transparent models", "question": "What is the importance of understanding why a classifier made the decision it made?"}, {"answer_start": 1063, "answer": "analytic", "question": "What type of tool is logistic regression widely used for in NLP?"}, {"answer_start": 1293, "answer": "negative sentiment", "question": "What are logically negative words more likely to be associated with?"}, {"answer_start": 1444, "answer": "potential confounds", "question": "What do we need to control in order to know if logically negative words are more likely to be associated with negative sentiment?"}, {"answer_start": 1803, "answer": "the age of the patient, the county of voting, the brand of the product", "question": "What are some confounds that can be controlled by logistic regression?"}, {"answer_start": 383, "answer": "logistic regression", "question": "What allows us to test whether some feature is associated with some outcome above and beyond the effect of other features?"}]}, {"context": "In this section we give the derivation of the gradient of the cross-entropy loss function L CE for logistic regression. Let's start with some quick calculus refreshers. First, the derivative of ln(x):", "questions_and_answers": [{"answer_start": 42, "answer": "the gradient of the cross-entropy loss function", "question": "What is the L CE for logistic regression?"}, {"answer_start": 142, "answer": "quick calculus refreshers", "question": "What are we going to start with?"}, {"answer_start": 194, "answer": "ln(x)", "question": "What is the derivative of?"}]}, {"context": "First, we want to know the derivative of the loss function with respect to a single weight w j (we'll need to compute it for each weight, and for the bias):", "questions_and_answers": [{"answer_start": 23, "answer": "the derivative of the loss function", "question": "What do we want to know with respect to a single weight w j?"}]}, {"context": "[ \u2022 ] Logistic regression is a supervised machine learning classifier that extracts real-valued features from the input, multiplies each by a weight, sums them, and passes the sum through a sigmoid function to generate a probability. A threshold is used to make a decision. [ \u2022 ] Logistic regression can be used with two classes (e.g., positive and negative sentiment) or with multiple classes (multinomial logistic regression, for example for n-ary text classification, part-of-speech labeling, etc.). [ \u2022 ] Multinomial logistic regression uses the softmax function to compute probabilities. [ \u2022 ] The weights (vector w and bias b) are learned from a labeled training set via a loss function, such as the cross-entropy loss, that must be minimized. [ \u2022 ] Minimizing this loss function is a convex optimization problem, and iterative algorithms like gradient descent are used to find the optimal weights. [ \u2022 ] Regularization is used to avoid overfitting.", "questions_and_answers": [{"answer_start": 31, "answer": "supervised machine learning classifier", "question": "What is logistic regression?"}, {"answer_start": 236, "answer": "threshold", "question": "What is used to make a decision in logistic regression?"}, {"answer_start": 336, "answer": "positive and negative sentiment", "question": "Logistic regression can be used with two classes (e.g., positive and negative sentiment) or with multiple classes (multinomial logistic regression"}, {"answer_start": 546, "answer": "the softmax function", "question": "What does multinomial logistic regression use to compute probabilities?"}, {"answer_start": 706, "answer": "cross-entropy loss", "question": "What is a loss function that must be minimized?"}, {"answer_start": 791, "answer": "convex optimization", "question": "What is the problem with minimizing a loss function?"}, {"answer_start": 911, "answer": "Regularization", "question": "What is used to avoid overfitting?"}]}, {"context": "[ \u2022 ] Logistic regression is also one of the most useful analytic tools, because of its ability to transparently study the importance of individual features.", "questions_and_answers": [{"answer_start": 6, "answer": "Logistic regression", "question": "What is one of the most useful analytic tools?"}]}, {"context": "Logistic regression was developed in the field of statistics, where it was used for the analysis of binary data by the 1960s, and was particularly common in medicine (Cox, 1969) . Starting in the late 1970s it became widely used in linguistics as one of the formal foundations of the study of linguistic variation (Sankoff and Labov, 1979) . Nonetheless, logistic regression didn't become common in natural language processing until the 1990s, when it seems to have appeared simultaneously from two directions. The first source was the neighboring fields of information retrieval and speech processing, both of which had made use of regression, and both of which lent many other statistical techniques to NLP. Indeed a very early use of logistic regression for document routing was one of the first NLP applications to use (LSI) embeddings as word representations (Sch\u00fctze et al., 1995) .", "questions_and_answers": [{"answer_start": 50, "answer": "statistics", "question": "Where was logistic regression developed?"}, {"answer_start": 232, "answer": "linguistics", "question": "In what field did logistic regression become widely used?"}, {"answer_start": 437, "answer": "1990s", "question": "When did logistic regression become common in natural language processing?"}, {"answer_start": 558, "answer": "information retrieval and speech processing", "question": "What two fields made use of logistic regression?"}, {"answer_start": 761, "answer": "document routing", "question": "What was one of the first NLP applications to use (LSI) embeddings as word representations?"}]}, {"context": "At the same time in the early 1990s logistic regression was developed and applied to NLP at IBM Research under the name maximum entropy modeling or maximum entropy maxent (Berger et al., 1996) , seemingly independent of the statistical literature. Under that name it was applied to language modeling (Rosenfeld, 1996) , part-of-speech tagging (Ratnaparkhi, 1996) , parsing (Ratnaparkhi, 1997), coreference resolution (Kehler, 1997b) , and text classification (Nigam et al., 1999) . More on classification can be found in machine learning textbooks (Hastie et al. 2001 , Witten and Frank 2005 , Bishop 2006 , Murphy 2012", "questions_and_answers": [{"answer_start": 92, "answer": "IBM Research", "question": "Where was logistic regression developed and applied to NLP in the early 1990s?"}, {"answer_start": 282, "answer": "language modeling", "question": "What was logistic regression applied to in the early 1990s?"}, {"answer_start": 521, "answer": "machine learning textbooks", "question": "Where can more information about classification be found?"}, {"answer_start": 570, "answer": "Witten and Frank", "question": "Who published a book on classification in 2005?"}]}, {"context": "Nets are for fish; Once you get the fish, you can forget the net.", "questions_and_answers": [{"answer_start": 13, "answer": "fish", "question": "What are nets for?"}]}, {"context": "Words are for meaning; Once you get the meaning, you can forget the words", "questions_and_answers": [{"answer_start": 14, "answer": "meaning", "question": "Words are for what?"}]}, {"context": "The asphalt that Los Angeles is famous for occurs mainly on its freeways. But in the middle of the city is another patch of asphalt, the La Brea tar pits, and this asphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleistocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly recognizable by its long canines. Five million years ago or so, a completely different sabre-tooth tiger called Thylacosmilus lived in Argentina and other parts of South America. Thylacosmilus was a marsupial whereas Smilodon was a placental mammal, but Thylacosmilus had the same long upper canines and, like Smilodon, had a protective bone flange on the lower jaw. The similarity of these two mammals is one of many examples of parallel or convergent evolution, in which particular contexts or environments lead to the evolution of very similar structures in different species (Gould, 1980) . The role of context is also important in the similarity of a less biological kind of organism: the word. Words that occur in similar contexts tend to have similar meanings. This link between similarity in how words are distributed and similarity in what they mean is called the distributional hypothesis. The hypothesis was distributional hypothesis first formulated in the 1950s by linguists like Joos (1950), Harris (1954) , and Firth (1957), who noticed that words which are synonyms (like oculist and eye-doctor) tended to occur in the same environment (e.g., near words like eye or examined) with the amount of meaning difference between two words \"corresponding roughly to the amount of difference in their environments\" (Harris, 1954, 157) . In this chapter we introduce vector semantics, which instantiates this linguistic vector semantics hypothesis by learning representations of the meaning of words, called embeddings, embeddings directly from their distributions in texts. These representations are used in every natural language processing application that makes use of meaning, and the static embeddings we introduce here underlie the more powerful dynamic or contextualized embeddings like BERT that we will see in Chapter 11.", "questions_and_answers": [{"answer_start": 64, "answer": "freeways", "question": "Where is the asphalt that Los Angeles is famous for?"}, {"answer_start": 137, "answer": "La Brea tar pits", "question": "What is the name of the patch of asphalt in the middle of Los Angeles?"}, {"answer_start": 291, "answer": "Smilodon", "question": "What is the name of the saber-toothed tiger?"}, {"answer_start": 447, "answer": "Thylacosmilus", "question": "What sabre-tooth tiger lived in Argentina and other parts of South America?"}, {"answer_start": 534, "answer": "marsupial", "question": "What was Thylacosmilus?"}, {"answer_start": 765, "answer": "parallel or convergent evolution", "question": "What type of evolution is the similarity of the two mammals one of many examples of?"}, {"answer_start": 1025, "answer": "the word", "question": "The role of context is important in the similarity of a less biological kind of organism: what?"}, {"answer_start": 706, "answer": "similar", "question": "Words that occur in what context tend to have similar meanings?"}, {"answer_start": 1208, "answer": "distributional hypothesis", "question": "What is the link between similarity in how words are distributed and similarity in what they mean called?"}, {"answer_start": 1313, "answer": "linguists", "question": "Who first formulated the distributional hypothesis?"}, {"answer_start": 1708, "answer": "vector semantics", "question": "What instantiates this linguistic vector semantics hypothesis by learning representations of the meaning of words?"}, {"answer_start": 1956, "answer": "natural language processing", "question": "What application uses embeddings to make use of meaning?"}]}, {"context": "These word representations are also the first example in this book of representation learning, automatically learning useful representations of the input text.", "questions_and_answers": [{"answer_start": 6, "answer": "word representations", "question": "What are the first examples in this book of representation learning?"}]}, {"context": "Finding such self-supervised ways to learn representations of the input, instead of creating representations by hand via feature engineering, is an important focus of NLP research (Bengio et al., 2013).", "questions_and_answers": [{"answer_start": 121, "answer": "feature engineering", "question": "What is an important focus of NLP research?"}]}, {"context": "Representing the meaning of a word by capitalizing it is a pretty unsatisfactory model. You might have seen a joke due originally to semanticist Barbara Partee (Carlson, 1977) : Q: What's the meaning of life? A: LIFE' Surely we can do better than this! After all, we'll want a model of word meaning to do all sorts of things for us. It should tell us that some words have similar meanings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some have positive connotations (happy) while others have negative connotations (sad). It should represent the fact that the meanings of buy, sell, and pay offer differing perspectives on the same underlying purchasing event (If I buy something from you, you've probably sold it to me, and I likely paid you). More generally, a model of word meaning should allow us to draw inferences to address meaning-related tasks like question-answering or dialogue.", "questions_and_answers": [{"answer_start": 35, "answer": "by capitalizing it", "question": "How is the meaning of a word represented?"}, {"answer_start": 145, "answer": "Barbara Partee", "question": "Who was the original author of a joke?"}, {"answer_start": 212, "answer": "LIFE", "question": "What is the meaning of life?"}, {"answer_start": 305, "answer": "all sorts of things", "question": "What do we want a model of word meaning to do for us?"}, {"answer_start": 498, "answer": "happy", "question": "What is a positive connotation of a word?"}, {"answer_start": 602, "answer": "buy, sell, and pay", "question": "What three words offer different perspectives on the same underlying purchasing event?"}, {"answer_start": 888, "answer": "question-answering or dialogue", "question": "A model of word meaning should allow us to draw inferences to address what meaning-related tasks?"}]}, {"context": "In this section we summarize some of these desiderata, drawing on results in the linguistic study of word meaning, which is called lexical semantics; we'll return to lexical semantics and expand on this list in Chapter 18 and Chapter 10.", "questions_and_answers": [{"answer_start": 131, "answer": "lexical semantics", "question": "What is the linguistic study of word meaning called?"}, {"answer_start": 131, "answer": "lexical semantics", "question": "What is the linguistic study of word meaning called?"}]}, {"context": "Lemmas and Senses Let's start by looking at how one word (we'll choose mouse) might be defined in a dictionary (simplified from the online dictionary WordNet): mouse (N) 1. any of numerous small rodents... 2. a hand-operated device that controls a cursor...", "questions_and_answers": [{"answer_start": 71, "answer": "mouse", "question": "What word might be defined in a dictionary?"}, {"answer_start": 71, "answer": "mouse", "question": "What word might be defined in a dictionary?"}, {"answer_start": 71, "answer": "mouse", "question": "What word might be defined in a dictionary?"}]}, {"context": "Here the form mouse is the lemma, also called the citation form. The form lemma citation form mouse would also be the lemma for the word mice; dictionaries don't have separate definitions for inflected forms like mice. Similarly sing is the lemma for sing, sang, sung. In many languages the infinitive form is used as the lemma for the verb, so Spanish dormir \"to sleep\" is the lemma for duermes \"you sleep\". The specific forms sung or carpets or sing or duermes are called wordforms.", "questions_and_answers": [{"answer_start": 46, "answer": "the citation form", "question": "What is another name for the lemma?"}, {"answer_start": 137, "answer": "mice", "question": "The form lemma citation form mouse would also be the lemma for what word?"}, {"answer_start": 229, "answer": "sing", "question": "What is the lemma for sing, sang, sung?"}, {"answer_start": 291, "answer": "infinitive form", "question": "What is used as the lemma for the verb in many languages?"}, {"answer_start": 474, "answer": "wordforms", "question": "What are the specific forms sung or carpets or sing or duermes called?"}]}, {"context": "wordform As the example above shows, each lemma can have multiple meanings; the lemma mouse can refer to the rodent or the cursor control device. We call each of these aspects of the meaning of mouse a word sense. The fact that lemmas can be polysemous (have multiple senses) can make interpretation difficult (is someone who types \"mouse info\" into a search engine looking for a pet or a tool?). Chapter 18 will discuss the problem of polysemy, and introduce word sense disambiguation, the task of determining which sense of a word is being used in a particular context.", "questions_and_answers": [{"answer_start": 109, "answer": "rodent or the cursor control device", "question": "What can the lemma mouse refer to?"}, {"answer_start": 202, "answer": "word sense", "question": "What do we call each aspect of the meaning of a mouse?"}, {"answer_start": 259, "answer": "multiple senses", "question": "What does polysemous mean?"}, {"answer_start": 397, "answer": "Chapter 18", "question": "What chapter will discuss the problem of polysemy?"}]}, {"context": "Synonymy One important component of word meaning is the relationship between word senses. For example when one word has a sense whose meaning is identical to a sense of another word, or nearly identical, we say the two senses of those two words are synonyms. Synonyms include such pairs as couch[ /sofa vomit/ ]throw up filbert[ /hazelnut car/ ]automobile A more formal definition of synonymy (between words rather than senses) is that two words are synonymous if they are substitutable for one another in any sentence without changing the truth conditions of the sentence, the situations in which the sentence would be true. We often say in this case that the two words have the same propositional meaning.", "questions_and_answers": [{"answer_start": 52, "answer": "the relationship between word senses", "question": "What is one important component of word meaning?"}, {"answer_start": 249, "answer": "synonyms", "question": "What do we call the two senses of a word whose meaning is identical to a sense of another word?"}, {"answer_start": 436, "answer": "two words are synonymous if they are substitutable for one another in any sentence without changing the truth conditions of the sentence", "question": "What is a more formal definition of synonymy?"}, {"answer_start": 685, "answer": "propositional", "question": "What type of meaning do two words have?"}]}, {"context": "While substitutions between some pairs of words like car [ / automobile or water / ] H 2 O are truth preserving, the words are still not identical in meaning. Indeed, probably no two words are absolutely identical in meaning. One of the fundamental tenets of semantics, called the principle of contrast (Girard 1718, Br\u00e9al 1897, Clark principle of contrast 1987), states that a difference in linguistic form is always associated with some difference in meaning. For example, the word H 2 O is used in scientific contexts and would be inappropriate in a hiking guide-water would be more appropriate-and this genre difference is part of the meaning of the word. In practice, the word synonym is therefore used to describe a relationship of approximate or rough synonymy.", "questions_and_answers": [{"answer_start": 6, "answer": "substitutions", "question": "What is truth preserving between some pairs of words like car [ / automobile or water / ] H 2 O?"}, {"answer_start": 176, "answer": "no two words are absolutely identical in meaning", "question": "What does the principle of contrast state?"}, {"answer_start": 281, "answer": "principle of contrast", "question": "What fundamental tenet of semantics states that a difference in linguistic form is always associated with some difference in meaning?"}, {"answer_start": 501, "answer": "scientific", "question": "In what context is the word H 2 O used?"}, {"answer_start": 682, "answer": "synonym", "question": "What is used to describe a relationship of approximate or rough synonymy?"}]}, {"context": "One common kind of relatedness between words is if they belong to the same semantic field. A semantic field is a set of words which cover a particular semantic semantic field domain and bear structured relations with each other. For example, words might be related by being in the semantic field of hospitals (surgeon, scalpel, nurse, anesthetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof, kitchen, family, bed). Semantic fields are also related to topic models, like Latent topic models Dirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts to induce sets of associated words from text. Semantic fields and topic models are very useful tools for discovering topical structure in documents.", "questions_and_answers": [{"answer_start": 75, "answer": "semantic field", "question": "What is a common kind of relatedness between words if they belong to the same?"}, {"answer_start": 91, "answer": "A semantic field", "question": "What is a set of words which cover a particular semantic field domain and bear structured relations with each other?"}, {"answer_start": 299, "answer": "hospitals", "question": "What is an example of a semantic field?"}, {"answer_start": 487, "answer": "topic models", "question": "What are semantic fields related to?"}, {"answer_start": 656, "answer": "Semantic fields and topic models", "question": "What are very useful tools for discovering topical structure in documents?"}]}, {"context": "Knowing that buy and sell have this relation makes it possible for a system to know that a sentence like Sam bought the book from Ling could be paraphrased as Ling sold the book to Sam, and that Sam has the role of the buyer in the frame and Ling the seller. Being able to recognize such paraphrases is important for question answering, and can help in shifting perspective for machine translation.", "questions_and_answers": [{"answer_start": 130, "answer": "Ling", "question": "Who did Sam buy the book from?"}, {"answer_start": 105, "answer": "Sam", "question": "Who bought the book from Ling?"}, {"answer_start": 378, "answer": "machine translation", "question": "What can being able to recognize paraphrases help shift perspective for?"}]}, {"context": "Connotation Finally, words have affective meanings or connotations. The word connotations has different meanings in different fields, but here we use it to mean the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations. For example some words have positive connotations (happy) while others have negative connotations (sad). Even words whose meanings are similar in other ways can vary in connotation; consider the difference in connotations between fake, knockoff, forgery, on the one hand, and copy, replica, reproduction on the other, or innocent (positive connotation) and naive (negative connotation). Some words describe positive evaluation (great, love) and others negative evaluation (terrible, hate). Positive or negative evaluation language is called sentiment, as we saw in Chapter 4, and word sentiment plays a role in important sentiment tasks like sentiment analysis, stance detection, and applications of NLP to the language of politics and consumer reviews.", "questions_and_answers": [{"answer_start": 32, "answer": "affective", "question": "What type of meanings do words have?"}, {"answer_start": 234, "answer": "emotions, sentiment, opinions, or evaluations", "question": "What are the aspects of a word's meaning that are related to a writer or reader's?"}, {"answer_start": 380, "answer": "sad", "question": "What is a negative connotation of a word?"}, {"answer_start": 511, "answer": "fake, knockoff, forgery, on the one hand, and copy, replica, reproduction on the other, or innocent", "question": "What words have positive and negative connotations?"}, {"answer_start": 754, "answer": "terrible, hate", "question": "What are some words that describe negative evaluation?"}, {"answer_start": 244, "answer": "sentiment", "question": "What is positive or negative evaluation language called?"}]}, {"context": "Early work on affective meaning (Osgood et al., 1957) found that words varied along three important dimensions of affective meaning:", "questions_and_answers": [{"answer_start": 84, "answer": "three", "question": "How many dimensions of affective meaning did early work on affective meaning find?"}]}, {"context": "valence: the pleasantness of the stimulus arousal: the intensity of emotion provoked by the stimulus dominance: the degree of control exerted by the stimulus Thus words like happy or satisfied are high on valence, while unhappy or annoyed are low on valence. Excited is high on arousal, while calm is low on arousal.", "questions_and_answers": [{"answer_start": 0, "answer": "valence", "question": "What is the pleasantness of the stimulus arousal?"}, {"answer_start": 220, "answer": "unhappy or annoyed", "question": "What words are low on valence?"}, {"answer_start": 259, "answer": "Excited", "question": "What is high on arousal?"}]}, {"context": "Controlling is high on dominance, while awed or influenced are low on dominance. Each word is thus represented by three numbers, corresponding to its value on each of the three dimensions: (1957) noticed that in using these 3 numbers to represent the meaning of a word, the model was representing each word as a point in a threedimensional space, a vector whose three dimensions corresponded to the word's rating on the three scales. This revolutionary idea that word meaning could be represented as a point in space (e.g., that part of the meaning of heartbreak can be represented as the point [[ 2.45 ], [ 5.65 ], [ 3.58 ]]) was the first expression of the vector semantics models that we introduce next.", "questions_and_answers": [{"answer_start": 0, "answer": "Controlling", "question": "What is high on dominance?"}, {"answer_start": 114, "answer": "three", "question": "How many numbers are used to represent each word?"}, {"answer_start": 552, "answer": "heartbreak", "question": "What can be represented as a point in space?"}]}, {"context": "Vectors semantics is the standard way to represent word meaning in NLP, helping vector semantics us model many of the aspects of word meaning we saw in the previous section. The roots of the model lie in the 1950s when two big ideas converged: Osgood's 1957 idea mentioned above to use a point in three-dimensional space to represent the connotation of a word, and the proposal by linguists like Joos (1950), Harris (1954), and Firth (1957) to define the meaning of a word by its distribution in language use, meaning its neighboring words or grammatical environments. Their idea was that two words that occur in very similar distributions (whose neighboring words are similar) have similar meanings.", "questions_and_answers": [{"answer_start": 0, "answer": "Vectors semantics", "question": "What is the standard way to represent word meaning in NLP?"}, {"answer_start": 208, "answer": "1950s", "question": "When did two big ideas converge?"}, {"answer_start": 618, "answer": "similar", "question": "What distributions did linguists propose to define the meaning of a word?"}]}, {"context": "For example, suppose you didn't know the meaning of the word ongchoi (a recent borrowing from Cantonese) but you see it in the following contexts: The fact that ongchoi occurs with words like rice and garlic and delicious and salty, as do words like spinach, chard, and collard greens might suggest that ongchoi is a leafy green similar to these other leafy greens. 1 We can do the same thing computationally by just counting words in the context of ongchoi.", "questions_and_answers": [{"answer_start": 315, "answer": "a leafy green", "question": "What type of green might ongchoi be similar to?"}, {"answer_start": 417, "answer": "counting", "question": "How can we do the same thing computationally?"}]}, {"context": "The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors. Vectors for representing words are called embeddings (although embeddings the term is sometimes more strictly applied only to dense vectors like word2vec (Section [ 6.8 ]), rather than sparse tf-idf or PPMI vectors (Section [ 6.3 ]-Section [ 6.6 ])). The word \"embedding\" derives from its mathematical sense as a mapping from one space or structure to another, although the meaning has shifted; see the end of the chapter. Figure 6 .1 A two-dimensional (t-SNE) projection of embeddings for some words and phrases, showing that words with similar meanings are nearby in space. The original 60dimensional embeddings were trained for sentiment analysis. Simplified from Li et al. 2015with colors added for explanation.", "questions_and_answers": [{"answer_start": 12, "answer": "vector semantics", "question": "What is the idea of representing a word as a point in a multidimensional semantic space?"}, {"answer_start": 220, "answer": "embeddings", "question": "What are vectors for representing words called?"}, {"answer_start": 463, "answer": "its mathematical sense as a mapping from one space or structure to another", "question": "What does the word embedding derive from?"}, {"answer_start": 632, "answer": "t-SNE", "question": "What is the two-dimensional projection of embeddings?"}, {"answer_start": 809, "answer": "sentiment analysis", "question": "What were the original embeddings trained for?"}, {"answer_start": 845, "answer": "Li et al.", "question": "Who simplified embeddings for sentiment analysis?"}, {"answer_start": 855, "answer": "2015", "question": "When were the embeddings simplified?"}]}, {"context": "The fine-grained model of word similarity of vector semantics offers enormous power to NLP applications. NLP applications like the sentiment classifiers of Chapter 4 or Chapter 5 depend on the same words appearing in the training and test sets. But by representing words as embeddings, classifiers can assign sentiment as long as it sees some words with similar meanings. And as we'll see, vector semantic models can be learned automatically from text without supervision.", "questions_and_answers": [{"answer_start": 4, "answer": "fine-grained model of word similarity of vector semantics", "question": "What offers enormous power to NLP applications?"}, {"answer_start": 193, "answer": "same words appearing in the training and test sets", "question": "What do NLP applications depend on?"}, {"answer_start": 274, "answer": "embeddings", "question": "What can NLP classifiers represent words as?"}, {"answer_start": 452, "answer": "without supervision", "question": "How can vector semantic models be learned?"}]}, {"context": "In this chapter we'll introduce the two most commonly used models. In the tf-idf model, an important baseline, the meaning of a word is defined by a simple function of the counts of nearby words. We will see that this method results in very long vectors that are sparse, i.e. mostly zeros (since most words simply never occur in the context of others). We'll introduce the word2vec model family for constructing short, dense vectors that have useful semantic properties. We'll also introduce the cosine, the standard way to use embeddings to compute semantic similarity, between two words, two sentences, or two documents, an important tool in practical applications like question answering, summarization, or automatic essay grading.", "questions_and_answers": [{"answer_start": 36, "answer": "two", "question": "How many commonly used models will we introduce in this chapter?"}, {"answer_start": 74, "answer": "tf-idf", "question": "What model defines the meaning of a word by a simple function of the counts of nearby words?"}, {"answer_start": 263, "answer": "sparse", "question": "What kind of long vectors are produced by the tf-idf model?"}, {"answer_start": 283, "answer": "zeros", "question": "What are the sparse vectors in the tf-idf model?"}, {"answer_start": 373, "answer": "word2vec", "question": "What model family will be introduced for constructing short, dense vectors that have useful semantic properties?"}, {"answer_start": 496, "answer": "cosine", "question": "What is the standard way to use embeddings to compute semantic similarity?"}]}, {"context": "\"The most important attributes of a vector in 3-space are {Location, Location, Location}\" Randall Munroe, https:/[ /xkcd.com/ ]2358/ Vector or distributional models of meaning are generally based on a co-occurrence matrix, a way of representing how often words co-occur. We'll look at two popular matrices: the term-document matrix and the term-term matrix.", "questions_and_answers": [{"answer_start": 199, "answer": "a co-occurrence matrix", "question": "What are vector or distributional models of meaning generally based on?"}, {"answer_start": 311, "answer": "term-document matrix and the term-term matrix", "question": "What are two popular matrices?"}]}, {"context": "The term-document matrix of Figure 6 .2 was first defined as part of the vector space model of information retrieval (Salton, 1971). In this model, a document is represented as a count vector, a column in Figure [ 6.3 ].", "questions_and_answers": [{"answer_start": 126, "answer": "1971", "question": "When was the term-document matrix first defined?"}, {"answer_start": 177, "answer": "a count vector", "question": "In the vector space model of information retrieval, a document is represented as what?"}]}, {"context": "To review some basic linear algebra, a vector is, at heart, just a list or array of numbers. So As You Like It is represented as the list [1,114,36,20] (the first column vector in Figure [ 6.3 ]) and Julius Caesar is represented as the list [7,62,1,2] (the third column vector). A vector space is a collection of vectors, characterized by their  dimension.", "questions_and_answers": [{"answer_start": 65, "answer": "a list or array of numbers", "question": "What is a vector?"}, {"answer_start": 200, "answer": "Julius Caesar", "question": "Who is represented as the third column vector?"}, {"answer_start": 313, "answer": "vectors", "question": "A vector space is a collection of what?"}]}, {"context": "In the example in Figure 6 .3, the document vectors are of dimension 4, dimension just so they fit on the page; in real term-document matrices, the vectors representing each document would have dimensionality |V |, the vocabulary size. The ordering of the numbers in a vector space indicates different meaningful dimensions on which documents vary. Thus the first dimension for both these vectors corresponds to the number of times the word battle occurs, and we can compare each dimension, noting for example that the vectors for As You Like It and Twelfth Night have similar values (1 and 0, respectively) for the first dimension. Figure 6 .3 The term-document matrix for four words in four Shakespeare plays. The red boxes show that each document is represented as a column vector of length four.", "questions_and_answers": [{"answer_start": 59, "answer": "dimension 4", "question": "In the example in Figure 6.3, the document vectors are of what dimension?"}, {"answer_start": 236, "answer": "The ordering of the numbers in a vector space", "question": "What indicates different meaningful dimensions on which documents vary?"}, {"answer_start": 412, "answer": "the number of times the word battle occurs", "question": "The first dimension for both vectors corresponds to what?"}, {"answer_start": 674, "answer": "four", "question": "How many words are in four Shakespeare plays?"}, {"answer_start": 716, "answer": "red boxes", "question": "What indicates that each document is represented as a column vector of length four?"}]}, {"context": "A real term-document matrix, of course, wouldn't just have 4 rows and columns, let alone 2. More generally, the term-document matrix has |V | rows (one for each word type in the vocabulary) and D columns (one for each document in the collection); as we'll see, vocabulary sizes are generally in the tens of thousands, and the number of documents can be enormous (think about all the pages on the web).", "questions_and_answers": [{"answer_start": 59, "answer": "4", "question": "How many rows and columns would a real term-document matrix have?"}, {"answer_start": 85, "answer": "one", "question": "How many rows does a term-document matrix have for each word type?"}]}, {"context": "Information retrieval (IR) is the task of finding the document d from the D information retrieval documents in some collection that best matches a query q. For IR we'll therefore also represent a query by a vector, also of length |V |, and we'll need a way to compare two vectors to find how similar they are. (Doing IR will also require efficient ways to store and manipulate these vectors by making use of the convenient fact that these vectors are sparse, i.e., mostly zeros). Later in the chapter we'll introduce some of the components of this vector comparison process: the tf-idf term weighting, and the cosine similarity metric.", "questions_and_answers": [{"answer_start": 0, "answer": "Information retrieval", "question": "What is the task of finding the document d from the D information retrieval documents in some collection that best matches a query q?"}, {"answer_start": 205, "answer": "a vector", "question": "What will we represent a query by for IR?"}, {"answer_start": 451, "answer": "sparse", "question": "What type of vectors are used for IR?"}, {"answer_start": 579, "answer": "tf-idf", "question": "What is the term weighting?"}]}, {"context": "We've seen that documents can be represented as vectors in a vector space. But vector semantics can also be used to represent the meaning of words. We do this by associating each word with a word vector-a row vector rather than a column row vector vector, hence with different dimensions, as shown in Figure 6 Figure 6 .5 The term-document matrix for four words in four Shakespeare plays. The red boxes show that each word is represented as a row vector of length four.", "questions_and_answers": [{"answer_start": 16, "answer": "documents", "question": "What can be represented as vectors in a vector space?"}, {"answer_start": 130, "answer": "meaning of words", "question": "What can vector semantics represent?"}, {"answer_start": 203, "answer": "a row vector", "question": "What is a word vector?"}, {"answer_start": 393, "answer": "red boxes", "question": "What indicates that each word is represented as a row vector of length four?"}]}, {"context": "For documents, we saw that similar documents had similar vectors, because similar documents tend to have similar words. This same principle applies to words: similar words have similar vectors because they tend to occur in similar documents. The term-document matrix thus lets us represent the meaning of a word by the documents it tends to occur in.", "questions_and_answers": [{"answer_start": 74, "answer": "similar documents tend to have similar words", "question": "Why do similar documents have similar vectors?"}, {"answer_start": 27, "answer": "similar", "question": "What words have similar vectors because they tend to occur in similar documents?"}, {"answer_start": 246, "answer": "term-document matrix", "question": "What lets us represent the meaning of a word by the documents it tends to occur in?"}]}, {"context": "An alternative to using the term-document matrix to represent words as vectors of document counts, is to use the term-term matrix, also called the word-word matrix or the term-context matrix, in which the columns are labeled by words rather word-word matrix than documents. This matrix is thus of dimensionality |V |\u00d7|V | and each cell records the number of times the row (target) word and the column (context) word co-occur in some context in some training corpus. The context could be the document, in which case the cell represents the number of times the two words appear in the same document. It is most common, however, to use smaller contexts, generally a window around the word, for example of 4 words to the left and 4 words to the right, in which case the cell represents the number of times (in some training corpus) the column word occurs in such a \u00b14 word window around the row word. For example here is one example each of some words in their windows:", "questions_and_answers": [{"answer_start": 147, "answer": "word-word matrix or the term-context matrix", "question": "What is another name for the term-term matrix?"}, {"answer_start": 373, "answer": "target", "question": "Each cell records the number of times the row (word) and the column (context) word co-occur in some context in some training corp"}, {"answer_start": 487, "answer": "the document", "question": "The context could be what?"}, {"answer_start": 661, "answer": "a window around the word", "question": "What is a smaller context?"}, {"answer_start": 917, "answer": "one example", "question": "How many words are in their windows in a training corpus?"}]}, {"context": "is traditionally followed by cherry pie, a traditional dessert often mixed, such as strawberry rhubarb pie. Apple pie computer peripherals and personal digital assistants. These devices usually a computer. This includes information available on the internet If we then take every occurrence of each word (say strawberry) and count the context words around it, we get a word-word co-occurrence matrix. Figure 6 .6 shows a simplified subset of the word-word co-occurrence matrix for these four words computed from the Wikipedia corpus (Davies, 2015 Figure 6 .6 Co-occurrence vectors for four words in the Wikipedia corpus, showing six of the dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in red. Note that a real vector would have vastly more dimensions and thus be much sparser. Figure 6 .6 that the two words cherry and strawberry are more similar to each other (both pie and sugar tend to occur in their window) than they are to other words like digital; conversely, digital and information are more similar to each other than, say, to strawberry. Note that |V |, the length of the vector, is generally the size of the vocabulary, often between 10,000 and 50,000 words (using the most frequent words in the training corpus; keeping words after about the most frequent 50,000 or so is generally not helpful). Since most of these numbers are zero these are sparse vector representations; there are efficient algorithms for storing and computing with sparse matrices. Now that we have some intuitions, let's move on to examine the details of computing word similarity. Afterwards we'll discuss methods for weighting cells.", "questions_and_answers": [{"answer_start": 84, "answer": "strawberry rhubarb pie", "question": "What is a traditional dessert often mixed with cherry pie?"}, {"answer_start": 108, "answer": "Apple pie", "question": "What is another name for computer peripherals and personal digital assistants?"}, {"answer_start": 118, "answer": "computer", "question": "What are Apple pie computer peripherals and personal digital assistants usually called?"}, {"answer_start": 369, "answer": "word-word co-occurrence matrix", "question": "What do we get if we take every occurrence of each word and count the context words around it?"}, {"answer_start": 516, "answer": "Wikipedia", "question": "Where is the word-word co-occurrence matrix computed from?"}, {"answer_start": 729, "answer": "red", "question": "What color is the vector for digital outlined in?"}, {"answer_start": 744, "answer": "a real vector", "question": "What would have vastly more dimensions and thus be much sparser?"}, {"answer_start": 849, "answer": "cherry and strawberry", "question": "What words are more similar to each other?"}, {"answer_start": 1178, "answer": "between 10,000 and 50,000", "question": "What is the typical range of words in a dictionary?"}, {"answer_start": 1396, "answer": "sparse vector representations", "question": "What are most of the numbers in the word-word co-occurrence matrix?"}, {"answer_start": 1590, "answer": "word similarity", "question": "What do we examine the details of computing?"}, {"answer_start": 1632, "answer": "methods for weighting cells", "question": "What will we discuss after we examine the details of computing word similarity?"}]}, {"context": "To measure similarity between two target words v and w, we need a metric that takes two vectors (of the same dimensionality, either both with words as dimensions, hence of length |V |, or both with documents as dimensions as documents, of length |D|) and gives a measure of their similarity. By far the most common similarity metric is the cosine of the angle between the vectors.", "questions_and_answers": [{"answer_start": 66, "answer": "metric", "question": "What do we need to measure similarity between two target words v and w?"}, {"answer_start": 336, "answer": "the cosine of the angle between the vectors", "question": "What is the most common similarity metric?"}]}, {"context": "The cosine-like most measures for vector similarity used in NLP-is based on the dot product operator from linear algebra, also called the inner product:", "questions_and_answers": [{"answer_start": 134, "answer": "the inner product", "question": "What is another name for the dot product operator?"}, {"answer_start": 106, "answer": "linear algebra", "question": "The cosine-like most measures for vector similarity are based on the dot product operator from what?"}, {"answer_start": 134, "answer": "the inner product", "question": "What is another name for the dot product operator?"}, {"answer_start": 134, "answer": "the inner product", "question": "What is another name for the dot product operator?"}, {"answer_start": 134, "answer": "the inner product", "question": "What is another name for the dot product operator?"}, {"answer_start": 134, "answer": "the inner product", "question": "What is another name for the dot product operator?"}]}, {"context": "As we will see, most metrics for similarity between vectors are based on the dot product. The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions. Alternatively, vectors that have zeros in different dimensions-orthogonal vectors-will have a dot product of 0, representing their strong dissimilarity.", "questions_and_answers": [{"answer_start": 77, "answer": "dot product", "question": "Most metrics for similarity between vectors are based on what?"}, {"answer_start": 77, "answer": "dot product", "question": "What acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions?"}, {"answer_start": 297, "answer": "orthogonal vectors", "question": "What are vectors that have zeros in different dimensions called?"}]}, {"context": "This raw dot product, however, has a problem as a similarity metric: it favors long vectors. The vector length is defined as", "questions_and_answers": [{"answer_start": 79, "answer": "long vectors", "question": "What type of vectors does the raw dot favor?"}, {"answer_start": 93, "answer": "The vector length", "question": "What is defined as?"}]}, {"context": "The dot product is higher if a vector is longer, with higher values in each dimension. More frequent words have longer vectors, since they tend to co-occur with more words and have higher co-occurrence values with each of them. The raw dot product thus will be higher for frequent words. But this is a problem; we'd like a similarity metric that tells us how similar two words are regardless of their frequency.", "questions_and_answers": [{"answer_start": 26, "answer": "if a vector is longer", "question": "When is the dot product higher?"}, {"answer_start": 87, "answer": "More frequent words", "question": "What type of words have longer vectors?"}, {"answer_start": 228, "answer": "The raw dot product", "question": "What will be higher for frequent words?"}, {"answer_start": 323, "answer": "similarity", "question": "What metric would we like that tells us how similar two words are regardless of their frequency?"}]}, {"context": "We modify the dot product to normalize for the vector length by dividing the dot product by the lengths of each of the two vectors. This normalized dot product turns out to be the same as the cosine of the angle between the two vectors, following from the definition of the dot product between two vectors a and b:", "questions_and_answers": [{"answer_start": 29, "answer": "normalize", "question": "What is the dot product modified to do for the vector length?"}, {"answer_start": 188, "answer": "the cosine of the angle between the two vectors", "question": "What is the normalized dot product the same as?"}]}, {"context": "The cosine similarity metric between two vectors v and w thus can be computed as:", "questions_and_answers": [{"answer_start": 4, "answer": "cosine", "question": "What is the similarity metric between two vectors v and w?"}]}, {"context": "For some applications we pre-normalize each vector, by dividing it by its length, creating a unit vector of length 1. Thus we could compute a unit vector from a by unit vector dividing it by |a|. For unit vectors, the dot product is the same as the cosine.", "questions_and_answers": [{"answer_start": 52, "answer": "by dividing it by its length", "question": "How do we pre-normalize each vector?"}, {"answer_start": 191, "answer": "|a|", "question": "What is the length of a unit vector divided by?"}, {"answer_start": 249, "answer": "cosine", "question": "For unit vectors, the dot product is the same as what?"}]}, {"context": "The cosine value ranges from 1 for vectors pointing in the same direction, through 0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since raw frequency values are non-negative, the cosine for these vectors ranges from 0-1.", "questions_and_answers": [{"answer_start": 29, "answer": "1", "question": "What is the cosine value for vectors pointing in the same direction?"}, {"answer_start": 89, "answer": "orthogonal", "question": "What type of vectors has a cosine value of 0?"}, {"answer_start": 250, "answer": "0-1", "question": "What is the cosine range for vectors pointing in opposite directions?"}]}, {"context": "Figure 6 .8 A (rough) graphical demonstration of cosine similarity, showing vectors for three words (cherry, digital, and information) in the two dimensional space defined by counts of the words computer and pie nearby. The figure doesn't show the cosine, but it highlights the angles; note that the angle between digital and information is smaller than the angle between cherry and information. When two vectors are more similar, the cosine is larger but the angle is smaller; the cosine has its maximum (1) when the angle between two vectors is smallest (0 [ \u2022 ] ); the cosine of all other angles is less than 1.", "questions_and_answers": [{"answer_start": 195, "answer": "computer and pie", "question": "What words are in the two dimensional space defined by counts of?"}, {"answer_start": 296, "answer": "the angle between digital and information", "question": "What is smaller than the angle between cherry and information?"}, {"answer_start": 509, "answer": "when the angle between two vectors is smallest", "question": "When does the cosine have its maximum?"}]}, {"context": "The co-occurrence matrices above represent each cell by frequencies, either of words with documents ( Figure [ 6.5 ] ), or words with other words (Figure [ 6.6 ] ). But raw frequency is not the best measure of association between words. Raw frequency is very skewed and not very discriminative. If we want to know what kinds of contexts are shared by cherry and strawberry but not by digital and information, we're not going to get good discrimination from words like the, it, or they, which occur frequently with all sorts of words and aren't informative about any particular word. We saw this also in Figure 6 .3 for the Shakespeare corpus; the dimension for the word good is not very discriminative between plays; good is simply a frequent word and has roughly equivalent high frequencies in each of the plays.", "questions_and_answers": [{"answer_start": 53, "answer": "by frequencies", "question": "How do the co-occurrence matrices above represent each cell?"}, {"answer_start": 169, "answer": "raw frequency", "question": "What is not the best measure of association between words?"}, {"answer_start": 254, "answer": "very skewed and not very discriminative", "question": "Is raw frequency discriminative or skewed?"}, {"answer_start": 351, "answer": "cherry and strawberry", "question": "What kinds of contexts are shared by digital and information?"}, {"answer_start": 432, "answer": "good", "question": "What word is not discriminative between plays?"}]}, {"context": "It's a bit of a paradox. Words that occur nearby frequently (maybe pie nearby cherry) are more important than words that only appear once or twice. Yet words that are too frequent-ubiquitous, like the or good-are unimportant. How can we balance these two conflicting constraints?", "questions_and_answers": [{"answer_start": 16, "answer": "paradox", "question": "What kind of paradox is it?"}, {"answer_start": 25, "answer": "Words that occur nearby frequently", "question": "What is more important than words that only appear once or twice?"}, {"answer_start": 213, "answer": "unimportant", "question": "Words that are too frequent-ubiquitous, like the or good, are what?"}, {"answer_start": 251, "answer": "two conflicting constraints", "question": "How can we balance words that are too frequent-ubiquitous?"}]}, {"context": "There are two common solutions to this problem: in this section we'll describe the tf-idf weighting, usually used when the dimensions are documents. In the next we introduce the PPMI algorithm (usually used when the dimensions are words).", "questions_and_answers": [{"answer_start": 138, "answer": "documents", "question": "The tf-idf weighting is usually used when the dimensions are what?"}, {"answer_start": 178, "answer": "PPMI algorithm", "question": "What algorithm is usually used when the dimensions are words?"}]}, {"context": "The tf-idf weighting (the '-' here is a hyphen, not a minus sign) is the product of two terms, each term capturing one of these two intuitions:", "questions_and_answers": [{"answer_start": 4, "answer": "tf-idf", "question": "What is the weighting of two terms?"}, {"answer_start": 54, "answer": "minus sign", "question": "The tf-idf weighting is not a what?"}]}, {"context": "The first is the term frequency (Luhn, 1957) : the frequency of the word t in the term frequency document d. We can just use the raw count as the term frequency:", "questions_and_answers": [{"answer_start": 125, "answer": "the raw count", "question": "What can we use as the term frequency?"}, {"answer_start": 47, "answer": "the frequency of the word t in the term frequency document d", "question": "What is the term frequency?"}]}, {"context": "More commonly we squash the raw frequency a bit, by using the log 10 of the frequency instead. The intuition is that a word appearing 100 times in a document doesn't make that word 100 times more likely to be relevant to the meaning of the document. Because we can't take the log of 0, we normally add 1 to the count:", "questions_and_answers": [{"answer_start": 62, "answer": "log 10", "question": "What frequency do we use instead of the raw frequency?"}, {"answer_start": 134, "answer": "100", "question": "How many times does a word appear in a document?"}, {"answer_start": 66, "answer": "1", "question": "When we can't take the log of 0, we add how many times to the count?"}]}, {"context": "If we use log weighting, terms which occur 0 times in a document would have tf = log 10 (1) = 0, 10 times in a document tf = log 10 (11) = [ 1.04 ], 100 times tf = log 10 (101) = [ 2.004 ], 1000 times tf = [ 3.00044 ], and so on.", "questions_and_answers": [{"answer_start": 120, "answer": "tf = log 10 (11)", "question": "How many times in a document would terms that occur 0 times in a document have tf = log 10 (11) = [ 1.04"}, {"answer_start": 159, "answer": "tf = log 10 (101)", "question": "How many times in a document would a term occur 0 times in a document?"}]}, {"context": "The second factor in tf-idf is used to give a higher weight to words that occur only in a few documents. Terms that are limited to a few documents are useful for discriminating those documents from the rest of the collection; terms that occur frequently across the entire collection aren't as helpful. The document frequency document frequency df t of a term t is the number of documents it occurs in. Document frequency is not the same as the collection frequency of a term, which is the total number of times the word appears in the whole collection in any document. Consider in the collection of Shakespeare's 37 plays the two words Romeo and action. The words have identical collection frequencies (they both occur 113 times in all the plays) but very different document frequencies, since Romeo only occurs in a single play. If our goal is to find documents about the romantic tribulations of Romeo, the word Romeo should be highly weighted, but not action:", "questions_and_answers": [{"answer_start": 21, "answer": "tf-idf", "question": "What is used to give a higher weight to words that occur only in a few documents?"}, {"answer_start": 105, "answer": "Terms that are limited to a few documents", "question": "What is useful for discriminating documents from the rest of the collection?"}, {"answer_start": 306, "answer": "document frequency document frequency df t", "question": "What is the number of documents a term occurs in?"}, {"answer_start": 489, "answer": "total number of times the word appears in the whole collection in any document", "question": "What is the collection frequency of a term?"}, {"answer_start": 636, "answer": "Romeo and action", "question": "What words do Shakespeare's 37 plays contain?"}, {"answer_start": 719, "answer": "113", "question": "How many times do Romeo and action appear in all of Shakespeare's 37 plays?"}, {"answer_start": 646, "answer": "action", "question": "What word should Romeo be highly weighted, but not?"}]}, {"context": "We emphasize discriminative words like Romeo via the inverse document frequency or idf term weight (Sparck Jones, 1972) . The idf is defined using the fracidf tion N/df t , where N is the total number of documents in the collection, and df t is the number of documents in which term t occurs. The fewer documents in which a term occurs, the higher this weight. The lowest weight of 1 is assigned to terms that occur in all the documents. It's usually clear what counts as a document: in Shakespeare we would use a play; when processing a collection of encyclopedia articles like Wikipedia, the document is a Wikipedia page; in processing newspaper articles, the document is a single article. Occasionally your corpus might not have appropriate document divisions and you might need to break up the corpus into documents yourself for the purposes of computing idf.", "questions_and_answers": [{"answer_start": 53, "answer": "inverse document frequency or idf term weight", "question": "How do we emphasize discriminative words like Romeo?"}, {"answer_start": 164, "answer": "N", "question": "What is the total number of documents in the collection?"}, {"answer_start": 293, "answer": "The fewer documents in which a term occurs", "question": "What is the higher the idf term weight?"}, {"answer_start": 114, "answer": "1", "question": "What is the lowest weight assigned to terms that occur in all the documents?"}, {"answer_start": 579, "answer": "Wikipedia", "question": "When processing a collection of encyclopedia articles, the document is a Wikipedia page; in processing newspaper articles, the document is a single"}, {"answer_start": 785, "answer": "break up the corpus into documents", "question": "What might you need to do if your corpus doesn't have appropriate document divisions?"}]}, {"context": "Because of the large number of documents in many collections, this measure too is usually squashed with a log function. The resulting definition for inverse document frequency (idf) is thus", "questions_and_answers": [{"answer_start": 106, "answer": "log function", "question": "What is inverse document frequency usually squashed with?"}, {"answer_start": 149, "answer": "inverse document frequency", "question": "What does idf stand for?"}]}, {"context": "Here are some idf values for some words in the Shakespeare corpus, ranging from extremely informative words which occur in only one play like Romeo, to those that occur in a few like salad or Falstaff, to those which are very common like fool or so common as to be completely non-discriminative since they occur in all 37 plays like good or sweet. 3", "questions_and_answers": [{"answer_start": 315, "answer": "all 37", "question": "How many plays do the words \"good or sweet\" appear in?"}, {"answer_start": 319, "answer": "3", "question": "How many plays have idf values for words in the Shakespeare corpus?"}]}, {"context": "The tf-idf weighting is the way for weighting co-occurrence matrices in information retrieval, but also plays a role in many other aspects of natural language processing. It's also a great baseline, the simple thing to try first. We'll look at other weightings like PPMI (Positive Pointwise Mutual Information) in Section [ 6.6 ].", "questions_and_answers": [{"answer_start": 4, "answer": "tf-idf", "question": "What is the way for weighting co-occurrence matrices in information retrieval?"}, {"answer_start": 189, "answer": "baseline", "question": "What is the tf-idf weighting a great thing to try first?"}, {"answer_start": 272, "answer": "Positive Pointwise Mutual Information", "question": "What does PPMI stand for?"}]}, {"context": "An alternative weighting function to tf-idf, PPMI (positive pointwise mutual information), is used for term-term-matrices, when the vector dimensions correspond to words rather than documents. PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.", "questions_and_answers": [{"answer_start": 51, "answer": "positive pointwise mutual information", "question": "What is PPMI?"}, {"answer_start": 292, "answer": "how much more the two words co-occur in our corpus", "question": "What is the best way to weigh the association between words?"}]}, {"context": "Pointwise mutual information (Fano, 1961) 4 is one of the most important con-pointwise mutual information cepts in NLP. It is a measure of how often two events x and y occur, compared with what we would expect if they were independent:", "questions_and_answers": [{"answer_start": 0, "answer": "Pointwise mutual information", "question": "What is one of the most important con-pointwise mutual information cepts in NLP?"}, {"answer_start": 36, "answer": "1961", "question": "In what year was Pointwise mutual information first introduced?"}, {"answer_start": 139, "answer": "how often two events x and y occur", "question": "Pointwise mutual information is a measure of what?"}]}, {"context": "The pointwise mutual information between a target word w and a context word c (Church and Hanks 1989, Church and Hanks 1990) is then defined as:", "questions_and_answers": [{"answer_start": 79, "answer": "Church and Hanks 1989", "question": "What is the pointwise mutual information between a target word w and a context word c?"}]}, {"context": "The numerator tells us how often we observed the two words together (assuming we compute probability by using the MLE). The denominator tells us how often we would expect the two words to co-occur assuming they each occurred independently; recall that the probability of two independent events both occurring is just the product of the probabilities of the two events. Thus, the ratio gives us an estimate of how much more the two words co-occur than we expect by chance. PMI is a useful tool whenever we need to find words that are strongly associated.", "questions_and_answers": [{"answer_start": 0, "answer": "The numerator", "question": "What tells us how often we observed the two words together?"}, {"answer_start": 252, "answer": "the probability of two independent events both occurring", "question": "What is just the product of the probabilities of the two events?"}, {"answer_start": 375, "answer": "the ratio", "question": "What gives us an estimate of how much more the two words co-occur than we expect by chance?"}, {"answer_start": 472, "answer": "PMI", "question": "What is a useful tool when we need to find words that are strongly associated?"}]}, {"context": "More formally, let's assume we have a co-occurrence matrix F with W rows (words) and C columns (contexts), where f i j gives the number of times word w i occurs in 4 PMI is based on the mutual information between two random variables X and Y , defined as:", "questions_and_answers": [{"answer_start": 113, "answer": "f i j", "question": "What gives the number of times word w i occurs in 4 PMI?"}, {"answer_start": 113, "answer": "f i j", "question": "What gives the number of times word w i occurs in 4 PMI?"}]}, {"context": "In a confusion of terminology, Fano used the phrase mutual information to refer to what we now call pointwise mutual information and the phrase expectation of the mutual information for what we now call mutual information 5 Positive PMI also cleanly solves the problem of what to do with zero counts, using 0 to replace the \u2212\u221e from log(0).", "questions_and_answers": [{"answer_start": 52, "answer": "mutual information", "question": "What phrase did Fano use to refer to pointwise mutual information?"}]}, {"context": "context c j . This can be turned into a PPMI matrix where ppmi i j gives the PPMI value of word w i with context c j as follows:", "questions_and_answers": [{"answer_start": 0, "answer": "context c j", "question": "What can be turned into a PPMI matrix where ppmi i j gives the PPMI value of word w "}, {"answer_start": 40, "answer": "PPMI matrix", "question": "What can context c j be turned into?"}]}, {"context": "Thus for example we could compute PPMI(w=information, c=data), assuming we pretended that Figure 6 .11 Replacing the counts in Figure 6 .6 with joint probabilities, showing the marginals around the outside.", "questions_and_answers": [{"answer_start": 177, "answer": "marginals around the outside", "question": "What would the joint probabilities show in Figure 6.11?"}, {"answer_start": 144, "answer": "joint probabilities", "question": "What would we replace the counts in Figure 6.11 with?"}]}, {"context": "Another possible solution is Laplace smoothing: Before computing PMI, a small constant k (values of [ 0.1 ]-3 are common) is added to each of the counts, shrinking (discounting) all the non-zero values. The larger the k, the more the non-zero counts are discounted.", "questions_and_answers": [{"answer_start": 70, "answer": "a small constant k", "question": "What is added to each count before computing PMI?"}, {"answer_start": 221, "answer": "the more the non-zero counts are discounted", "question": "The larger the k, what happens to the non-zero counts?"}]}, {"context": "In summary, the vector semantics model we've described so far represents a target word as a vector with dimensions corresponding either to the documents in a large collection (the term-document matrix) or to the counts of words in some neighboring window (the term-term matrix). The values in each dimension are counts, weighted by tf-idf (for term-document matrices) or PPMI (for term-term matrices), and the vectors are sparse (since most values are zero).", "questions_and_answers": [{"answer_start": 180, "answer": "term-document matrix", "question": "The vector semantics model represents a target word as a vector with dimensions corresponding to what?"}, {"answer_start": 260, "answer": "term-term matrix", "question": "What is the vector semantics model used to represent a target word as a vector with dimensions corresponding either to the documents in a large collection"}, {"answer_start": 332, "answer": "tf-idf", "question": "What is the weighted value for term-document matrices?"}]}, {"context": "The model computes the similarity between two words x and y by taking the cosine of their tf-idf or PPMI vectors; high cosine, high similarity. This entire model is sometimes referred to as the tf-idf model or the PPMI model, after the weighting function.", "questions_and_answers": [{"answer_start": 74, "answer": "cosine", "question": "The model computes the similarity between two words x and y by taking what of their tf-idf or PPMI"}, {"answer_start": 194, "answer": "tf-idf model or the PPMI model", "question": "What is the model that computes the similarity between two words x and y called?"}]}, {"context": "The tf-idf model of meaning is often used for document functions like deciding if two documents are similar. We represent a document by taking the vectors of all the words in the document, and computing the centroid of all those vectors.", "questions_and_answers": [{"answer_start": 70, "answer": "deciding if two documents are similar", "question": "What is the tf-idf model used for?"}, {"answer_start": 193, "answer": "computing the centroid", "question": "What does the tf-idf model use to represent a document?"}]}, {"context": "The centroid is the multidimensional version of the mean; the centroid of a set of vectors is a single vector that has the minimum sum of squared distances to each of the vectors in the set. Given k word vectors w 1 , w 2 , ..., w k , the centroid document vector d is:", "questions_and_answers": [{"answer_start": 119, "answer": "the minimum sum of squared distances", "question": "What does the centroid of a set of vectors have to each of the vectors in the set?"}, {"answer_start": 58, "answer": "the centroid", "question": "What is a single vector that has the minimum sum of squared distances to each of the vectors in a set?"}, {"answer_start": 197, "answer": "k", "question": "What are the word vectors w 1, w 2,..., w k?"}]}, {"context": "In the previous sections we saw how to represent a word as a sparse, long vector with dimensions corresponding to words in the vocabulary or documents in a collection. We now introduce a more powerful word representation: embeddings, short dense vectors. Unlike the vectors we've seen so far, embeddings are short, with number of dimensions d ranging from 50-1000, rather than the much larger vocabulary size |V | or number of documents D we've seen. These d dimensions don't have a clear interpretation. And the vectors are dense: instead of vector entries being sparse, mostly-zero counts or functions of counts, the values will be real-valued numbers that can be negative.", "questions_and_answers": [{"answer_start": 61, "answer": "sparse, long vector", "question": "How was a word represented in previous sections?"}, {"answer_start": 222, "answer": "embeddings", "question": "What are short dense vectors called?"}, {"answer_start": 222, "answer": "embeddings", "question": "What are short dense vectors?"}, {"answer_start": 457, "answer": "d dimensions", "question": "What do embeddings not have a clear interpretation of?"}, {"answer_start": 634, "answer": "real-valued numbers", "question": "Instead of sparse, mostly-zero counts or functions of counts, what are the values of embeddings?"}]}, {"context": "It turns out that dense vectors work better in every NLP task than sparse vectors. While we don't completely understand all the reasons for this, we have some intuitions. Representing words as 300-dimensional dense vectors requires our classifiers to learn far fewer weights than if we represented words as 50,000-dimensional vectors, and the smaller parameter space possibly helps with generalization and avoiding overfitting. Dense vectors may also do a better job of capturing synonymy. For example, in a sparse vector representation, dimensions for synonyms like car and automobile dimension are distinct and unrelated; sparse vectors may thus fail to capture the similarity between a word with car as a neighbor and a word with automobile as a neighbor.", "questions_and_answers": [{"answer_start": 18, "answer": "dense vectors", "question": "What works better in every NLP task than sparse vectors?"}, {"answer_start": 159, "answer": "intuitions", "question": "What do we have about dense vectors?"}, {"answer_start": 193, "answer": "300", "question": "How many dimensional dense vectors do classifiers need to learn?"}, {"answer_start": 480, "answer": "synonymy", "question": "Dense vectors may do a better job of capturing what?"}, {"answer_start": 600, "answer": "distinct and unrelated", "question": "What are dimensions for synonyms like car and automobile dimension in a sparse vector representation?"}]}, {"context": "In this section we introduce one method for computing embeddings: skip-gram vocabulary. In Chapter 11 we'll introduce methods for learning dynamic contextual embeddings like the popular family of BERT representations, in which the vector for each word is different in different contexts.", "questions_and_answers": [{"answer_start": 66, "answer": "skip-gram vocabulary", "question": "What is one method for computing embeddings?"}, {"answer_start": 227, "answer": "the vector for each word is different in different contexts", "question": "How are BERT representations different in different contexts?"}]}, {"context": "The intuition of word2vec is that instead of counting how often each word w occurs near, say, apricot, we'll instead train a classifier on a binary prediction task: \"Is word w likely to show up near apricot?\" We don't actually care about this prediction task; instead we'll take the learned classifier weights as the word embeddings.", "questions_and_answers": [{"answer_start": 94, "answer": "apricot", "question": "Where does word2vec train a classifier on a binary prediction task?"}, {"answer_start": 94, "answer": "apricot", "question": "Where does word2vec train a classifier on a binary prediction task?"}, {"answer_start": 322, "answer": "embeddings", "question": "What do we use the classifier weights as instead of counting how often each word w appears near apricot?"}]}, {"context": "The revolutionary intuition here is that we can just use running text as implicitly supervised training data for such a classifier; a word c that occurs near the target word apricot acts as gold 'correct answer' to the question \"Is word c likely to show up near apricot?\" This method, often called self-supervision, avoids the need for self-supervision any sort of hand-labeled supervision signal. This idea was first proposed in the task of neural language modeling, when Bengio et al. (2003) and Collobert et al. 2011showed that a neural language model (a neural network that learned to predict the next word from prior words) could just use the next word in running text as its supervision signal, and could be used to learn an embedding representation for each word as part of doing this prediction task.", "questions_and_answers": [{"answer_start": 190, "answer": "gold", "question": "What is the correct answer to the question \"Is word c likely to show up near apricot?\""}, {"answer_start": 298, "answer": "self-supervision", "question": "What is the method that eliminates the need for hand-labeled supervision?"}, {"answer_start": 442, "answer": "neural language modeling", "question": "What task first proposed the idea of self-supervision?"}, {"answer_start": 498, "answer": "Collobert", "question": "Who et al. 2011 showed that a neural language model could use the next word in running text as its supervision signal?"}, {"answer_start": 731, "answer": "embedding representation", "question": "What could a neural language model learn for each word?"}]}, {"context": "We'll see how to do neural networks in the next chapter, but word2vec is a much simpler model than the neural network language model, in two ways. First, word2vec simplifies the task (making it binary classification instead of word prediction). Second, word2vec simplifies the architecture (training a logistic regression classifier instead of a multi-layer neural network with hidden layers that demand more sophisticated training algorithms). The intuition of skip-gram is:", "questions_and_answers": [{"answer_start": 61, "answer": "word2vec", "question": "What is a much simpler model than the neural network language model?"}, {"answer_start": 227, "answer": "word prediction", "question": "Word2vec makes binary classification instead of what?"}, {"answer_start": 302, "answer": "logistic regression", "question": "What type of classifier does word2vec train instead of a multi-layer neural network with hidden layers?"}, {"answer_start": 462, "answer": "skip-gram", "question": "What is the intuition of word2vec?"}]}, {"context": "Let's start by thinking about the classification task, and then turn to how to train. Imagine a sentence like the following, with a target word apricot, and assume we're using a window of \u00b12 context words:", "questions_and_answers": [{"answer_start": 72, "answer": "how to train", "question": "What do we then turn to?"}, {"answer_start": 144, "answer": "apricot", "question": "What is the target word for a sentence like the following?"}]}, {"context": "Our goal is to train a classifier such that, given a tuple (w, c) of a target word w paired with a candidate context word c (for example (apricot, jam), or perhaps (apricot, aardvark)) it will return the probability that c is a real context word (true for jam, false for aardvark):", "questions_and_answers": [{"answer_start": 226, "answer": "a real context word", "question": "What is the probability that c is?"}, {"answer_start": 226, "answer": "a real context word", "question": "What is the probability that c is?"}]}, {"context": "The probability that word c is not a real context word for w is just 1 minus Eq. [ 6.24 ]:", "questions_and_answers": [{"answer_start": 69, "answer": "1", "question": "What is the probability that word c is not a real context word for w?"}, {"answer_start": 83, "answer": "6.24", "question": "What is the probability that word c is not a real context word for w?"}]}, {"context": "We model the probability that word c is a real context word for target word w as:", "questions_and_answers": [{"answer_start": 30, "answer": "w", "question": "What is a real context word for target word w?"}]}, {"context": "The sigmoid function returns a number between 0 and 1, but to make it a probability we'll also need the total probability of the two possible events (c is a context word, and c isn't a context word) to sum to 1. We thus estimate the probability that word c is not a real context word for w as:", "questions_and_answers": [{"answer_start": 150, "answer": "c is a context word", "question": "What does the sigmoid function say?"}, {"answer_start": 175, "answer": "c isn't a context word", "question": "What is the difference between c and w?"}, {"answer_start": 41, "answer": "w", "question": "What is not a real context word for w?"}]}, {"context": "Equation [ 6.28 ] gives us the probability for one word, but there are many context words in the window. Skip-gram makes the simplifying assumption that all context words are independent, allowing us to just multiply their probabilities:", "questions_and_answers": [{"answer_start": 11, "answer": "6.28", "question": "What equation gives us the probability for one word, but there are many context words in the window?"}, {"answer_start": 105, "answer": "Skip-gram", "question": "What makes the assumption that all context words are independent?"}]}, {"context": "The learning algorithm for skip-gram embeddings takes as input a corpus of text, and a chosen vocabulary size N. It begins by assigning a random embedding vector for each of the N vocabulary words, and then proceeds to iteratively shift the embedding of each word w to be more like the embeddings of words that occur nearby in texts, and less like the embeddings of words that don't occur nearby. Let's start by considering a single piece of training data:", "questions_and_answers": [{"answer_start": 219, "answer": "iteratively shift the embedding of each word w", "question": "What does the learning algorithm do after assigning a random embedding vector for each of the N vocabulary words?"}, {"answer_start": 424, "answer": "a single piece of training data", "question": "What does the learning algorithm consider first?"}]}, {"context": "This example has a target word w (apricot), and 4 context words in the L = \u00b12 window, resulting in 4 positive training instances (on the left below): For training a binary classifier we also need negative examples. In fact skipgram with negative sampling (SGNS) uses more negative examples than positive examples (with the ratio between them set by a parameter k). So for each of these (w, c pos ) training instances we'll create k negative samples, each consisting of the target w plus a 'noise word' c neg . A noise word is a random word from the lexicon, constrained not to be the target word w. The right above shows the setting where k = 2, so we'll have 2 negative examples in the negative training set \u2212 for each positive example w, c pos .", "questions_and_answers": [{"answer_start": 34, "answer": "apricot", "question": "What is the target word w?"}, {"answer_start": 256, "answer": "SGNS", "question": "What is another name for skipgram with negative sampling?"}, {"answer_start": 224, "answer": "k", "question": "How many negative samples will we create for each of the training instances?"}, {"answer_start": 528, "answer": "random word from the lexicon", "question": "What is a noise word?"}]}, {"context": "Setting \u03b1 = .75 gives better performance because it gives rare noise words slightly higher probability: for rare words, P \u03b1 (w) > P(w). To illustrate this intuition, it might help to work out the probabilities for an example with two events, P(a) = .99", "questions_and_answers": [{"answer_start": 12, "answer": ".75", "question": "Setting  = what gives rare noise words slightly higher probability?"}, {"answer_start": 230, "answer": "two", "question": "How many events does P(a) =.99 represent?"}]}, {"context": "and P(b) = .01: If we consider one word/context pair (w, c pos ) with its k noise words c neg 1 ...c neg k , we can express these two goals as the following loss function L to be minimized (hence the \u2212); here the first term expresses that we want the classifier to assign the real context word c pos a high probability of being a neighbor, and the second term expresses that we want to assign each of the noise words c neg i a high probability of being a non-neighbor, all multiplied because we assume independence:", "questions_and_answers": [{"answer_start": 492, "answer": "we assume independence", "question": "Why do we want to assign each of the noise words c neg i a high probability of being a non-neighbor?"}]}, {"context": "That is, we want to maximize the dot product of the word with the actual context words, and minimize the dot products of the word with the k negative sampled nonneighbor words.", "questions_and_answers": [{"answer_start": 139, "answer": "k negative", "question": "What type of nonneighbor words do we want to minimize the dot products of the word with?"}]}, {"context": "To get the gradient, we need to take the derivative of Eq. [ 6.34 ] with respect to the different embeddings. It turns out the derivatives are the following (we leave the proof as an exercise at the end of the chapter):", "questions_and_answers": [{"answer_start": 98, "answer": "embeddings", "question": "To get the gradient, we need to take the derivative of Eq. [ 6.34 ] with respect to what?"}, {"answer_start": 192, "answer": "at the end of the chapter", "question": "Where do we leave the proof as an exercise?"}]}, {"context": "The update equations going from time step t to t + 1 in stochastic gradient descent Figure 6 .14 Intuition of one step of gradient descent. The skip-gram model tries to shift embeddings so the target embeddings (here for apricot) are closer to (have a higher dot product with) context embeddings for nearby words (here jam) and further from (lower dot product with) context embeddings for noise words that don't occur nearby (here Tolstoy and matrix).", "questions_and_answers": [{"answer_start": 56, "answer": "stochastic gradient descent", "question": "What is the name of the process in which the update equations go from time step t to t + 1?"}, {"answer_start": 221, "answer": "apricot", "question": "The skip-gram model tries to shift embeddings so the target embeddings are closer to (have a higher dot product"}]}, {"context": "Recall that the skip-gram model learns two separate embeddings for each word i: the target embedding w i and the context embedding c i , stored in two matrices, the target embedding context embedding target matrix W and the context matrix C. It's common to just add them together, representing word i with the vector w i + c i . Alternatively we can throw away the C matrix and just represent each word i by the vector w i .", "questions_and_answers": [{"answer_start": 39, "answer": "two separate embeddings", "question": "How many embeddings does the skip-gram model learn for each word i?"}, {"answer_start": 306, "answer": "the vector w i", "question": "What does the skip-gram model use to represent each word i?"}]}, {"context": "As with the simple count-based methods like tf-idf, the context window size L affects the performance of skip-gram embeddings, and experiments often tune the parameter L on a devset.", "questions_and_answers": [{"answer_start": 56, "answer": "context window size L", "question": "What affects the performance of skip-gram embeddings?"}]}, {"context": "There are many kinds of static embeddings. An extension of word2vec, fasttext fasttext (Bojanowski et al., 2017) , addresses a problem with word2vec as we have presented it so far: it has no good way to deal with unknown words -words that appear in a test corpus but were unseen in the training corpus. A related problem is word sparsity, such as in languages with rich morphology, where some of the many forms for each noun and verb may only occur rarely. Fasttext deals with these problems by using subword models, representing each word as itself plus a bag of constituent n-grams, with special boundary symbols < and > added to each word. For example, [ 6.9 ] [ \u2022 ] VISUALIZING EMBEDDINGS 119 with n = 3 the word where would be represented by the sequence <where> plus the character n-grams: <wh, whe, her, ere, re>", "questions_and_answers": [{"answer_start": 24, "answer": "static embeddings", "question": "What are there many kinds of?"}, {"answer_start": 324, "answer": "word sparsity", "question": "What is a problem with word2vec?"}, {"answer_start": 492, "answer": "by using subword models", "question": "How does Fasttext deal with word sparsity?"}, {"answer_start": 702, "answer": "n = 3", "question": "What is the word where represented by the sequence where> plus the character n-grams?"}]}, {"context": "Then a skipgram embedding is learned for each constituent n-gram, and the word where is represented by the sum of all of the embeddings of its constituent n-grams. Unknown words can then be presented only by the sum of the constituent n-grams. A fasttext open-source library, including pretrained embeddings for 157 languages, is available at https://fasttext.cc.", "questions_and_answers": [{"answer_start": 5, "answer": "a skipgram embedding", "question": "What is learned for each constituent n-gram?"}, {"answer_start": 164, "answer": "Unknown", "question": "What words can be presented only by the sum of the constituent n-grams?"}, {"answer_start": 246, "answer": "fasttext", "question": "What open-source library is available at https://fasttext.cc?"}]}, {"context": "Another very widely used static embedding model is GloVe (Pennington et al., 2014), short for Global Vectors, because the model is based on capturing global corpus statistics. GloVe is based on ratios of probabilities from the word-word cooccurrence matrix, combining the intuitions of count-based models like PPMI while also capturing the linear structures used by methods like word2vec.", "questions_and_answers": [{"answer_start": 94, "answer": "Global Vectors", "question": "What is GloVe short for?"}, {"answer_start": 94, "answer": "Global Vectors", "question": "What is GloVe short for?"}, {"answer_start": 194, "answer": "ratios of probabilities", "question": "What is GloVe based on?"}]}, {"context": "It turns out that dense embeddings like word2vec actually have an elegant mathematical relationships with sparse embeddings like PPMI, in which word2vec can be seen as implicitly optimizing a shifted version of a PPMI matrix (Levy and Goldberg, 2014c).", "questions_and_answers": [{"answer_start": 129, "answer": "PPMI", "question": "Word2vec has an elegant mathematical relationship with sparse embeddings like what?"}, {"answer_start": 129, "answer": "PPMI", "question": "Word2vec has an elegant mathematical relationship with sparse embeddings like what?"}, {"answer_start": 129, "answer": "PPMI", "question": "Word2vec has an elegant mathematical relationship with sparse embeddings like what?"}]}, {"context": "\"I see well in many dimensions as long as the dimensions are around two.\"", "questions_and_answers": [{"answer_start": 68, "answer": "two", "question": "\"I see well in many dimensions as long as the dimensions are around what?"}]}, {"context": "The late economist Martin Shubik Visualizing embeddings is an important goal in helping understand, apply, and improve these models of word meaning. But how can we visualize a (for example) 100-dimensional vector?", "questions_and_answers": [{"answer_start": 19, "answer": "Martin Shubik", "question": "Who was the late economist?"}, {"answer_start": 190, "answer": "100", "question": "How many dimensional vectors can we visualize?"}]}, {"context": "The simplest way to visualize the meaning of a word w embedded in a space is to list the most similar words to w by sorting the vectors for all words in the vocabulary by their cosine with the vector for w. For example the 7 closest words to frog using the GloVe embeddings are: frogs, toad, litoria, leptodactylidae, rana, lizard, and eleutherodactylus (Pennington et al., 2014).", "questions_and_answers": [{"answer_start": 113, "answer": "by sorting the vectors for all words in the vocabulary by their cosine with the vector for w", "question": "How do you visualize the meaning of a word w embedded in a space?"}]}, {"context": "Yet another visualization method is to use a clustering algorithm to show a hierarchical representation of which words are similar to others in the embedding space. The uncaptioned figure on the left uses hierarchical clustering of some embedding vectors for nouns as a visualization method (Rohde et al., 2006) .", "questions_and_answers": [{"answer_start": 45, "answer": "clustering algorithm", "question": "What is used to show a hierarchical representation of which words are similar to others in the embedding space?"}, {"answer_start": 292, "answer": "Rohde et al.", "question": "Who used hierarchical clustering of some embedding vectors for nouns as a visualization method?"}]}, {"context": "Probably the most common visualization method, however, is to project the 100 dimensions of a word down into 2 dimensions. Figure 6 .1 showed one such visualization, as does Figure 6 .16, using a projection method called t-SNE (van der Maaten and Hinton, 2008).", "questions_and_answers": [{"answer_start": 109, "answer": "2", "question": "How many dimensions of a word is the most common visualization method?"}, {"answer_start": 221, "answer": "t-SNE", "question": "What is the projection method used in Figure 6.16?"}]}, {"context": "In this section we briefly summarize some of the semantic properties of embeddings that have been studied.", "questions_and_answers": [{"answer_start": 49, "answer": "semantic properties", "question": "What are some of the properties of embeddings that have been studied?"}]}, {"context": "Different types of similarity or association: One parameter of vector semantic models that is relevant to both sparse tf-idf vectors and dense word2vec vectors is the size of the context window used to collect counts. This is generally between 1 and 10 words on each side of the target word (for a total context of 2-20 words).", "questions_and_answers": [{"answer_start": 163, "answer": "the size of the context window", "question": "What is one parameter of vector semantic models that is relevant to sparse tf-idf vectors and dense word2vec vector"}, {"answer_start": 236, "answer": "between 1 and 10", "question": "What is the size of the context window used to collect counts?"}]}, {"context": "The choice depends on the goals of the representation. Shorter context windows tend to lead to representations that are a bit more syntactic, since the information is coming from immediately nearby words. When the vectors are computed from short context windows, the most similar words to a target word w tend to be semantically similar words with the same parts of speech. When vectors are computed from long context windows, the highest cosine words to a target word w tend to be words that are topically related but not similar.", "questions_and_answers": [{"answer_start": 26, "answer": "goals of the representation", "question": "The choice depends on what?"}, {"answer_start": 55, "answer": "Shorter context windows", "question": "What tends to lead to representations that are a bit more syntactic?"}, {"answer_start": 316, "answer": "semantically similar", "question": "When the vectors are computed from short context windows, the most similar words to a target word w tend to be what?"}, {"answer_start": 497, "answer": "topically related but not similar", "question": "When vectors are computed from long context windows, the highest cosine words to a target word w tend to be words that are what"}]}, {"context": "For example Levy and Goldberg (2014a) showed that using skip-gram with a window of \u00b12, the most similar words to the word Hogwarts (from the Harry Potter series) were names of other fictional schools: Sunnydale (from Buffy the Vampire Slayer) or Evernight (from a vampire series). With a window of \u00b15, the most similar words to Hogwarts were other words topically related to the Harry Potter series: Dumbledore, Malfoy, and half-blood.", "questions_and_answers": [{"answer_start": 201, "answer": "Sunnydale", "question": "What is the name of the school from Buffy the Vampire Slayer?"}, {"answer_start": 400, "answer": "Dumbledore, Malfoy, and half-blood", "question": "What were the most similar words to Hogwarts with a window of 5?"}]}, {"context": "It's also often useful to distinguish two kinds of similarity or association between words (Sch\u00fctze and Pedersen, 1993). Two words have first-order co-occurrence for solving simple analogy problems of the form a is to b as a* is to what?. In such problems, a system given a problem like apple:tree::grape:?, i.e., apple is to tree as grape is to , and must fill in the word vine. In the parallelogram model, illustrated in Figure 6 .15, the vector from the word apple to the word tree (= # \u00bb tree \u2212 # \u00bb apple) is added to the vector for grape ( # \u00bb grape); the nearest word to that point is returned. tree apple grape vine Figure 6 .15 The parallelogram model for analogy problems (Rumelhart and Abrahamson, 1973) : the location of # \u00bb vine can be found by subtracting # \u00bb apple from # \u00bb tree and adding # \u00bb grape.", "questions_and_answers": [{"answer_start": 51, "answer": "similarity or association", "question": "What two kinds of words are often useful to distinguish between words?"}, {"answer_start": 210, "answer": "a is to b", "question": "What is the form of a simple analogy problem?"}, {"answer_start": 287, "answer": "apple", "question": "What is a system given a problem like?"}, {"answer_start": 437, "answer": "the vector", "question": "What is added to the vector for grape in the parallelogram model?"}, {"answer_start": 708, "answer": "1973", "question": "When was the parallelogram model for analogy problems created?"}]}, {"context": "There are some caveats. For example, the closest value returned by the parallelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact b* but one of the 3 input words or their morphological variants (i.e., cherry:red :: potato:x returns potato or potatoes instead of brown), so these must be explicitly excluded. Furthermore while embedding spaces perform well if the task involves frequent words, small distances, and certain relations (like relating countries with their capitals or verbs/nouns with their inflected forms), the parallelogram method with embeddings doesn't work as well for other relations (Linzen 2016 , Gladkova et al. 2016 , Schluter 2018 , Ethayarajh et al. 2019a ), and indeed Peterson et al. (2020) argue that the parallelogram method is in general too simple to model the human cognitive process of forming analogies of this kind.", "questions_and_answers": [{"answer_start": 15, "answer": "caveats", "question": "What are there some caveats to the parallelogram method?"}, {"answer_start": 156, "answer": "b*", "question": "What is the closest value returned by the parallelogram algorithm in word2vec or GloVe embedding spaces?"}, {"answer_start": 551, "answer": "parallelogram method", "question": "What method with embeddings doesn't work as well for other relations?"}, {"answer_start": 667, "answer": "Schluter 2018", "question": "What year did Ethayarajh et al. 2019a argue that the parallelogram method with embeddings doesn't work well"}, {"answer_start": 721, "answer": "Peterson et al.", "question": "Who argue that the parallelogram method is in general too simple to model the human cognitive process of forming analogies of this kind?"}, {"answer_start": 794, "answer": "too simple", "question": "What does Peterson et al. argue the parallelogram method is in general to model the human cognitive process of forming analogies of this kind"}]}, {"context": "Embeddings can also be a useful tool for studying how meaning changes over time, by computing multiple embedding spaces, each from texts written in a particular time period. For example Figure 6 .17 shows a visualization of changes in meaning in English words over the last two centuries, computed by building separate embed-ding spaces for each decade from historical corpora like Google n-grams (Lin et al., 2012b) and the Corpus of Historical American English (Davies, 2012).", "questions_and_answers": [{"answer_start": 0, "answer": "Embeddings", "question": "What can be a useful tool for studying how meaning changes over time?"}, {"answer_start": 382, "answer": "Google n-grams", "question": "What is an example of a historical corpora?"}]}, {"context": "Figure 6 .17: Two-dimensional visualization of semantic change in English using SGNS vectors (see Section [ 5.8 ] for the visualization algorithm). A, The word gay shifted from meaning \"cheerful\" or \"frolicsome\" to referring to homosexuality. A, In the early 20th century broadcast referred to \"casting out seeds\"; with the rise of television and radio its meaning shifted to \"transmitting signals\". C, Awful underwent a process of pejoration, as it shifted from meaning \"full of awe\" to meaning \"terrible or appalling\" [212] . that adverbials (e.g., actually) have a general tendency to undergo subjectification where they shift from objective statements about the world (e.g., \"Sorry, the car is actually broken\") to subjective statements (e.g., \"I can't believe he actually did that\", indicating surprise/disbelief). .17 A t-SNE visualization of the semantic change of 3 words in English using word2vec vectors. The modern sense of each word, and the grey context words, are computed from the most recent (modern) time-point embedding space. Earlier points are computed from earlier historical embedding spaces. The visualizations show the changes in the word gay from meanings related to \"cheerful\" or \"frolicsome\" to referring to homosexuality, the development of the modern \"transmission\" sense of broadcast from its original sense of sowing seeds, and the pejoration of the word awful as it shifted from meaning \"full of awe\" to meaning \"terrible or appalling\" (Hamilton et al., 2016b).", "questions_and_answers": [{"answer_start": 80, "answer": "SGNS vectors", "question": "Two-dimensional visualization of semantic change in English using what?"}, {"answer_start": 199, "answer": "\"frolicsome\"", "question": "What word shifted from being \"cheerful\" to referring to homosexuality?"}, {"answer_start": 272, "answer": "broadcast referred to \"casting out seeds\"", "question": "What did broadcasts refer to in the early 20th century?"}, {"answer_start": 471, "answer": "\"full of awe\"", "question": "Awful shifted from meaning what to meaning \"terrible or appalling\"?"}, {"answer_start": 719, "answer": "subjective statements", "question": "What do adverbials shift from objective statements about the world to?"}, {"answer_start": 897, "answer": "word2vec", "question": "What vector is used to visualize the semantic change of 3 words in English?"}, {"answer_start": 996, "answer": "most recent (modern) time-point embedding space", "question": "The modern sense of each word, and the grey context words, are computed from what?"}, {"answer_start": 1078, "answer": "earlier historical embedding spaces", "question": "What are earlier points computed from?"}, {"answer_start": 1386, "answer": "awful", "question": "What word shifted from \"full of awe\" to \"terrible or appalling\"?"}]}, {"context": "In addition to their ability to learn word meaning from text, embeddings, alas, also reproduce the implicit biases and stereotypes that were latent in the text. As the prior section just showed, embeddings can roughly model relational similarity: 'queen' as the closest word to 'king' -'man' + 'woman' implies the analogy man:woman::king:queen. But these same embedding analogies also exhibit gender stereotypes. For example Bolukbasi et al. (2016) find that the closest occupation to 'man' -'computer programmer' + 'woman' in word2vec embeddings trained on news text is 'homemaker', and that the embeddings similarly suggest the analogy 'father' is to 'doctor' as 'mother' is to 'nurse'. This could result in what Crawford (2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-allocational harm cates resources (jobs or credit) unfairly to different groups. For example algorithms that use embeddings as part of a search for hiring potential programmers or doctors might thus incorrectly downweight documents with women's names. It turns out that embeddings don't just reflect the statistics of their input, but also amplify bias; gendered terms become more gendered in embedding space than they bias amplification were in the input text statistics (Zhao et al. 2017 , Ethayarajh et al. 2019b , Jia et al. 2020 , and biases are more exaggerated than in actual labor employment statistics (Garg et al., 2018) .", "questions_and_answers": [{"answer_start": 62, "answer": "embeddings", "question": "What reproduces implicit biases and stereotypes that were latent in the text?"}, {"answer_start": 247, "answer": "'queen", "question": "What is the closest word to 'king'?"}, {"answer_start": 393, "answer": "gender stereotypes", "question": "What do embedding analogies also exhibit?"}, {"answer_start": 425, "answer": "Bolukbasi et al.", "question": "Who found that the closest occupation to'man' -'computer programmer' + 'woman' in word2vec embedding"}, {"answer_start": 572, "answer": "homemaker", "question": "What is the closest occupation to'man' -'computer programmer' + 'woman' in embeddings trained on news text"}, {"answer_start": 715, "answer": "Crawford (2017) and Blodgett et al.", "question": "Who called an allocational harm?"}, {"answer_start": 766, "answer": "allocational harm", "question": "What do Crawford (2017) and Blodgett et al. call when a system allo-allocational harm cates resources unfair"}, {"answer_start": 984, "answer": "doctors", "question": "Embeddings can be used to downweight documents with women's names."}, {"answer_start": 1158, "answer": "gendered terms", "question": "What become more gendered in embedding space than they bias amplification were in the input text statistics?"}, {"answer_start": 1296, "answer": "Ethayarajh", "question": "Who et al. 2019b found that gendered terms become more gendered in embedding space than in actual labor employment statistics?"}, {"answer_start": 1322, "answer": "Jia", "question": "Who et al. 2020 found that gendered terms become more gendered in embedding space than in actual labor employment statistics?"}, {"answer_start": 108, "answer": "biases", "question": "What are more exaggerated in embeddings than in actual labor employment statistics?"}]}, {"context": "Embeddings also encode the implicit associations that are a property of human reasoning. The Implicit Association Test (Greenwald et al., 1998) measures people's associations between concepts (like 'flowers' or 'insects') and attributes (like 'pleasantness' and 'unpleasantness') by measuring differences in the latency with which they label words in the various categories. 7 Using such methods, people", "questions_and_answers": [{"answer_start": 0, "answer": "Embeddings", "question": "What encodes the implicit associations that are a property of human reasoning?"}, {"answer_start": 89, "answer": "The Implicit Association Test", "question": "What test measures people's associations between concepts and attributes?"}, {"answer_start": 153, "answer": "people", "question": "Who uses the Implicit Association Test?"}]}, {"context": "The most important evaluation metric for vector models is extrinsic evaluation on tasks, i.e., using vectors in an NLP task and seeing whether this improves performance over some other model.", "questions_and_answers": [{"answer_start": 58, "answer": "extrinsic evaluation", "question": "What is the most important evaluation metric for vector models?"}]}, {"context": "Nonetheless it is useful to have intrinsic evaluations. The most common metric is to test their performance on similarity, computing the correlation between an algorithm's word similarity scores and word similarity ratings assigned by humans. WordSim-353 (Finkelstein et al., 2002 ) is a commonly used set of ratings from 0 (love, laughter, pleasure) and a red button for 'insects' (flea, spider, mosquito) and 'unpleasant words' (abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for 'flowers' and 'unpleasant words' and a green button for 'insects' and 'pleasant words'.", "questions_and_answers": [{"answer_start": 33, "answer": "intrinsic evaluations", "question": "What is useful to have?"}, {"answer_start": 111, "answer": "similarity", "question": "What is the most common metric to test an algorithm's performance on?"}, {"answer_start": 243, "answer": "WordSim-353", "question": "What is a commonly used set of ratings from 0 (love, laughter, pleasure) and a red button for 'insect"}]}, {"context": "to 10 for 353 noun pairs; for example (plane, car) had an average score of [ 5.77 ]. SimLex-999 (Hill et al., 2015 ) is a more difficult dataset that quantifies similarity (cup, mug) rather than relatedness (cup, coffee), and including both concrete and abstract adjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each consisting of a target word with 4 additional word choices; the task is to choose which is the correct synonym, as in the example: Levied is closest in meaning to: imposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these datasets present words without context.", "questions_and_answers": [{"answer_start": 77, "answer": "5.77", "question": "What was the average score for plane, car?"}, {"answer_start": 85, "answer": "SimLex-999", "question": "What is a more difficult dataset that quantifies similarity (cup, mug) rather than relatedness (cup, coffee)?"}, {"answer_start": 475, "answer": "Levied", "question": "Which word is closest in meaning to imposed, believed, requested, correlated?"}, {"answer_start": 622, "answer": "context", "question": "All of the datasets present words without what?"}]}, {"context": "Another task used for evaluation is the analogy task, discussed on page 120, where the system has to solve problems of the form a is to b as a* is to b*, given a, b, and a* and having to find b* (Turney and Littman, 2005) . A number of sets of tuples have been created for this task, (Mikolov et al. 2013a , Mikolov et al. 2013c , Gladkova et al. 2016 , covering morphology (city:cities::child:children), lexicographic relations (leg:table::spout::teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland), some drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jurgens et al., 2012) .", "questions_and_answers": [{"answer_start": 40, "answer": "analogy", "question": "What task is discussed on page 120?"}, {"answer_start": 244, "answer": "tuples", "question": "What have been created for the analogy task?"}, {"answer_start": 285, "answer": "Mikolov", "question": "Who created a number of sets of tuples for the analogy task?"}, {"answer_start": 331, "answer": "Gladkova", "question": "Who created a set of tuples for the analogy task?"}, {"answer_start": 569, "answer": "79", "question": "How many different relations did the SemEval-2012 Task 2 dataset contain?"}]}, {"context": "All embedding algorithms suffer from inherent variability. For example because of randomness in the initialization and the random negative sampling, algorithms like word2vec may produce different results even from the same dataset, and individual documents in a collection may strongly impact the resulting embeddings (Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When embeddings are used to study word associations in particular corpora, therefore, it is best practice to train multiple embeddings with bootstrap sampling over documents and average the results (Antoniak and Mimno, 2018).", "questions_and_answers": [{"answer_start": 37, "answer": "inherent variability", "question": "All embedding algorithms suffer from what?"}, {"answer_start": 82, "answer": "randomness in the initialization and the random negative sampling", "question": "What causes word2vec algorithms to produce different results even from the same dataset?"}, {"answer_start": 331, "answer": "2016", "question": "When was Tian et al. published?"}, {"answer_start": 527, "answer": "bootstrap sampling", "question": "What is the best practice when embeddings are used to study word associations in particular corpora?"}]}, {"context": "[ \u2022 ] In vector semantics, a word is modeled as a vector-a point in high-dimensional space, also called an embedding. In this chapter we focus on static embeddings, in each each word is mapped to a fixed embedding.", "questions_and_answers": [{"answer_start": 107, "answer": "embedding", "question": "In vector semantics, a point in high-dimensional space is also called what?"}, {"answer_start": 9, "answer": "vector semantics", "question": "What is a word modeled as a vector-a point in high-dimensional space?"}, {"answer_start": 146, "answer": "static embeddings", "question": "What do we focus on in this chapter?"}]}, {"context": "[ \u2022 ] Vector semantic models fall into two classes: sparse and dense. In sparse models each dimension corresponds to a word in the vocabulary V and cells are functions of co-occurrence counts. The term-document matrix has a row for each word (term) in the vocabulary and a column for each document. The word-context or term-term matrix has a row for each (target) word in the vocabulary and a column for each context term in the vocabulary. Two sparse weightings are common: the tf-idf weighting which weights each cell by its term frequency and inverse document frequency, and PPMI (pointwise positive mutual information) most common for for word-context matrices.", "questions_and_answers": [{"answer_start": 52, "answer": "sparse and dense", "question": "What are the two classes of vector semantic models?"}, {"answer_start": 171, "answer": "co-occurrence counts", "question": "Cells in sparse models are functions of what?"}, {"answer_start": 197, "answer": "term", "question": "What matrix has a row for each word in the vocabulary and a column for each document?"}, {"answer_start": 356, "answer": "target", "question": "The word-context matrix has a row for each word in the vocabulary and a column for each context term in the vocabulary."}, {"answer_start": 578, "answer": "PPMI", "question": "What is the most common weighting for word-context matrices?"}]}, {"context": "[ \u2022 ] Dense vector models have dimensionality 50-1000. Word2vec algorithms like skip-gram are a popular way to compute dense embeddings. Skip-gram trains a logistic regression classifier to compute the probability that two words are 'likely to occur nearby in text'. This probability is computed from the dot product between the embeddings for the two words. [ \u2022 ] Skip-gram uses stochastic gradient descent to train the classifier, by learning embeddings that have a high dot product with embeddings of words that occur nearby and a low dot product with noise words. [ \u2022 ] Other important embedding algorithms include GloVe, a method based on ratios of word co-occurrence probabilities. [ \u2022 ] Whether using sparse or dense vectors, word and document similarities are computed by some function of the dot product between vectors. The cosine of two vectors-a normalized dot product-is the most popular such metric.", "questions_and_answers": [{"answer_start": 6, "answer": "Dense vector models", "question": "What models have dimensionality 50-1000?"}, {"answer_start": 55, "answer": "Word2vec algorithms", "question": "What is a popular way to compute dense embeddings?"}, {"answer_start": 137, "answer": "Skip-gram", "question": "What trains a logistic regression classifier to compute the probability that two words are 'likely to occur nearby in text'?"}, {"answer_start": 301, "answer": "the dot product between the embeddings for the two words", "question": "What is the probability that two words are likely to occur nearby in text computed from?"}, {"answer_start": 380, "answer": "stochastic gradient descent", "question": "What does Skip-gram use to train the classifier?"}, {"answer_start": 619, "answer": "GloVe", "question": "What is a method based on ratios of word co-occurrence probabilities?"}, {"answer_start": 708, "answer": "sparse or dense", "question": "Word and document similarities are computed by some function of the dot product between what vectors?"}, {"answer_start": 858, "answer": "normalized dot product", "question": "What is the most popular metric for word and document similarities?"}]}, {"context": "The idea that the meaning of a word might be modeled as a point in a multidimensional semantic space came from psychologists like Charles E. Osgood, who had been studying how people responded to the meaning of words by assigning values along scales like happy[ /sad or hard/ ]soft. Osgood et al. (1957) proposed that the meaning of a word in general could be modeled as a point in a multidimensional Euclidean space, and that the similarity of meaning between two words could be modeled as the distance between these points in the space.", "questions_and_answers": [{"answer_start": 130, "answer": "Charles E. Osgood", "question": "Who proposed that the meaning of a word could be modeled as a point in a multidimensional semantic space?"}, {"answer_start": 282, "answer": "Osgood et al.", "question": "Who proposed that the meaning of a word in general could be modeled as a point in a multidimensional Euclidean space?"}, {"answer_start": 297, "answer": "1957", "question": "When did Osgood and colleagues propose that the meaning of a word in general could be modeled as a point in a multidimensional Eu"}]}, {"context": "A final intellectual source in the 1950s and early 1960s was the field then called mechanical indexing, now known as information retrieval. In what became known mechanical indexing as the vector space model for information retrieval (Salton 1971 , Sparck Jones 1986 , researchers demonstrated new ways to define the meaning of words in terms of vectors (Switzer, 1965) , and refined methods for word similarity based on measures of statistical association between words like mutual information (Giuliano, 1965) and idf (Sparck Jones, 1972) , and showed that the meaning of documents could be represented in the same vector spaces used for words. Some of the philosophical underpinning of the distributional way of thinking came from the late writings of the philosopher Wittgenstein, who was skeptical of the possibility of building a completely formal theory of meaning definitions for each word, suggesting instead that \"the meaning of a word is its use in the language\" (Wittgenstein, 1953, PI 43) . That is, instead of using some logical language to define each word, or drawing on denotations or truth values, Wittgenstein's idea is that we should define a word by how it is used by people in speaking and understanding in their day-to-day interactions, thus prefiguring the movement toward embodied and experiential models in linguistics and NLP (Glenberg and Robertson 2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).", "questions_and_answers": [{"answer_start": 117, "answer": "information retrieval", "question": "What is mechanical indexing now known as?"}, {"answer_start": 184, "answer": "the vector space model for information retrieval", "question": "What was mechanical indexing known as?"}, {"answer_start": 770, "answer": "Wittgenstein", "question": "Who was skeptical of the possibility of building a completely formal theory of meaning definitions for each word?"}, {"answer_start": 1296, "answer": "embodied and experiential models", "question": "What did Wittgenstein's idea prefigure the movement toward in linguistics and NLP?"}, {"answer_start": 1416, "answer": "2020", "question": "In what year did Bisk and Koller publish their work on embodied and experiential models in linguistics and NLP?"}]}, {"context": "More distantly related is the idea of defining words by a vector of discrete features, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992, Wierzbicka 1996) . By the middle of the 20th century, beginning with the work of Hjelmslev (Hjelmslev, 1969) (originally 1943) and fleshed out in early models of generative grammar (Katz and Fodor, 1963) , the idea arose of representing meaning with semantic features, symbols that represent some sort of primitive meaning.", "questions_and_answers": [{"answer_start": 127, "answer": "Descartes and Leibniz", "question": "The idea of defining words by a vector of discrete features has roots as far back as who?"}, {"answer_start": 248, "answer": "Hjelmslev", "question": "Who started the idea of defining words by a vector of discrete features?"}, {"answer_start": 365, "answer": "1963", "question": "When was the idea of defining words by a vector of discrete features first developed?"}]}, {"context": "For example words like hen, rooster, or chick, have something in common (they all describe chickens) and something different (their age and sex), representable as:", "questions_and_answers": [{"answer_start": 23, "answer": "hen, rooster, or chick", "question": "What are some words that describe chickens?"}]}, {"context": "The dimensions used by vector models of meaning to define words, however, are only abstractly related to this idea of a small fixed number of hand-built dimensions. Nonetheless, there has been some attempt to show that certain dimensions of embedding models do contribute some specific compositional aspect of meaning like these early semantic features.", "questions_and_answers": [{"answer_start": 142, "answer": "hand-built dimensions", "question": "The dimensions used by vector models of meaning to define words are only abstractly related to this idea of a small fixed number of what?"}, {"answer_start": 241, "answer": "embedding models", "question": "What type of models have some attempt to show that contribute some specific compositional aspect of meaning like these early semantic features?"}]}, {"context": "The use of dense vectors to model word meaning, and indeed the term embedding, grew out of the latent semantic indexing (LSI) model (Deerwester et al., 1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990) . In LSA singular value decomposition-SVDis applied to a term-document matrix (each SVD cell weighted by log frequency and normalized by entropy), and then the first 300 dimensions are used as the LSA embedding. Singular Value Decomposition (SVD) is a method for finding the most important dimensions of a data set, those dimensions along which the data varies the most. LSA was then quickly widely applied: as a cognitive model Landauer and Dumais (1997), and for tasks like spell checking (Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Jurafsky 1998, Bellegarda 2000) morphology induction (Schone and Jurafsky 2000, Schone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky, 2001a), and essay grading (Rehder et al., 1998) . Related models were simultaneously developed and applied to word sense disambiguation by Sch\u00fctze (1992b). LSA also led to the earliest use of embeddings to represent words in a probabilistic classifier, in the logistic regression document router of Sch\u00fctze et al. (1995) . The idea of SVD on the term-term matrix (rather than the term-document matrix) as a model of meaning for NLP was proposed soon after LSA by Sch\u00fctze (1992b). Sch\u00fctze applied the low-rank (97-dimensional) embeddings produced by SVD to the task of word sense disambiguation, analyzed the resulting semantic space, and also suggested possible techniques like dropping high-order dimensions. See Sch\u00fctze (1997a).", "questions_and_answers": [{"answer_start": 173, "answer": "latent semantic analysis", "question": "What does LSA stand for?"}, {"answer_start": 391, "answer": "300", "question": "How many dimensions are used as the LSA embedding?"}, {"answer_start": 437, "answer": "Singular Value Decomposition", "question": "What is a method for finding the most important dimensions of a data set?"}, {"answer_start": 742, "answer": "language modeling", "question": "What was Bellegarda 1997, Coccaro and Jurafsky 1998, Bellegarda 2000?"}, {"answer_start": 1088, "answer": "Sch\u00fctze", "question": "Who developed and applied related models to word sense disambiguation?"}, {"answer_start": 1176, "answer": "probabilistic", "question": "What type of classifier did LSA lead to the first use of embeddings?"}, {"answer_start": 1264, "answer": "1995", "question": "When did Sch\u00fctze et al. first use embeddings to represent words in a probabilistic classifier?"}, {"answer_start": 1295, "answer": "term-term matrix", "question": "What did Sch\u00fctze propose as a model of meaning for NLP?"}, {"answer_start": 1449, "answer": "low-rank", "question": "What is the term for 97-dimensional embeddings produced by SVD?"}, {"answer_start": 1672, "answer": "1997a", "question": "In what year did Sch\u00fctze propose dropping high-order dimensions?"}]}, {"context": "A number of alternative matrix models followed on from the early SVD work, including Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent Dirichlet Allocation (LDA) (Blei et al., 2003) , and Non-negative Matrix Factorization (NMF) (Lee and Seung, 1999).", "questions_and_answers": [{"answer_start": 208, "answer": "Non-negative Matrix Factorization", "question": "What is NMF?"}, {"answer_start": 85, "answer": "Probabilistic Latent Semantic Indexing", "question": "What is PLSI?"}]}, {"context": "Neural networks are a fundamental computational tool for language processing, and a very old one. They are called neural because their origins lie in the McCulloch-Pitts neuron (McCulloch and Pitts, 1943 ), a simplified model of the human neuron as a kind of computing element that could be described in terms of propositional logic. But the modern use in language processing no longer draws on these early biological inspirations.", "questions_and_answers": [{"answer_start": 0, "answer": "Neural networks", "question": "What is a fundamental computational tool for language processing?"}, {"answer_start": 154, "answer": "McCulloch-Pitts neuron", "question": "What is the origin of neural networks?"}, {"answer_start": 407, "answer": "biological inspirations", "question": "What does the modern use of neural networks no longer draw on?"}]}, {"context": "Instead, a modern neural network is a network of small computing units, each of which takes a vector of input values and produces a single output value. In this chapter we introduce the neural net applied to classification. The architecture we introduce is called a feedforward network because the computation proceeds iterfeedforward atively from one layer of units to the next. The use of modern neural nets is often called deep learning, because modern networks are often deep (have many layers).", "questions_and_answers": [{"answer_start": 36, "answer": "a network of small computing units", "question": "What is a modern neural network?"}, {"answer_start": 208, "answer": "classification", "question": "What is the neural net applied to?"}, {"answer_start": 266, "answer": "feedforward network", "question": "What is the architecture we introduce called?"}, {"answer_start": 426, "answer": "deep learning", "question": "What is the use of modern neural nets called?"}]}, {"context": "Neural networks share much of the same mathematics as logistic regression. But neural networks are a more powerful classifier than logistic regression, and indeed a minimal neural network (technically one with a single 'hidden layer') can be shown to learn any function.", "questions_and_answers": [{"answer_start": 54, "answer": "logistic regression", "question": "Neural networks share much of the same mathematics as what?"}, {"answer_start": 163, "answer": "a minimal neural network", "question": "What can be shown to learn any function?"}]}, {"context": "Neural net classifiers are different from logistic regression in another way. With logistic regression, we applied the regression classifier to many different tasks by developing many rich kinds of feature templates based on domain knowledge. When working with neural networks, it is more common to avoid most uses of rich handderived features, instead building neural networks that take raw words as inputs and learn to induce features as part of the process of learning to classify. We saw examples of this kind of representation learning for embeddings in Chapter 6. Nets that are very deep are particularly good at representation learning. For that reason deep neural nets are the right tool for large scale problems that offer sufficient data to learn features automatically.", "questions_and_answers": [{"answer_start": 0, "answer": "Neural net classifiers", "question": "What is different from logistic regression in another way?"}, {"answer_start": 225, "answer": "domain knowledge", "question": "What are feature templates based on?"}, {"answer_start": 388, "answer": "raw words", "question": "What do neural networks take as inputs?"}, {"answer_start": 545, "answer": "embeddings", "question": "What did we see examples of representation learning for in Chapter 6?"}, {"answer_start": 584, "answer": "very deep", "question": "What kind of neural nets are particularly good at representation learning?"}, {"answer_start": 660, "answer": "deep neural nets", "question": "What is the right tool for large scale problems that offer sufficient data to learn features automatically?"}]}, {"context": "In this chapter we'll introduce feedforward networks as classifiers, and also apply them to the simple task of language modeling: assigning probabilities to word sequences and predicting upcoming words. In subsequent chapters we'll introduce many other aspects of neural models, such as recurrent neural networks and the Transformer (Chapter 9), contextual embeddings like BERT (Chapter 11), and encoder-decoder models and attention (Chapter 10).", "questions_and_answers": [{"answer_start": 56, "answer": "classifiers", "question": "What are feedforward networks?"}, {"answer_start": 287, "answer": "recurrent neural networks", "question": "What is the Transformer?"}]}, {"context": "The building block of a neural network is a single computational unit. A unit takes a set of real valued numbers as input, performs some computation on them, and produces an output.", "questions_and_answers": [{"answer_start": 42, "answer": "a single computational unit", "question": "What is the building block of a neural network?"}, {"answer_start": 174, "answer": "output", "question": "What is produced by a unit that takes a set of real valued numbers as input?"}]}, {"context": "Often it's more convenient to express this weighted sum using vector notation; recall from linear algebra that a vector is, at heart, just a list or array of numbers. Thus vector we'll talk about z in terms of a weight vector w, a scalar bias b, and an input vector x, and we'll replace the sum with the convenient dot product:", "questions_and_answers": [{"answer_start": 139, "answer": "a list or array of numbers", "question": "A vector is, at heart, just what?"}, {"answer_start": 315, "answer": "dot product", "question": "What will we replace the sum of a vector with?"}]}, {"context": "We'll discuss three popular non-linear functions f () below (the sigmoid, the tanh, and the rectified linear ReLU) but it's pedagogically convenient to start with the sigmoid function since we saw it in Chapter 5:", "questions_and_answers": [{"answer_start": 78, "answer": "tanh", "question": "The sigmoid, the rectified linear ReLU and what other non-linear function are discussed below?"}, {"answer_start": 167, "answer": "sigmoid function", "question": "What is the first non-linear function discussed in Chapter 5?"}]}, {"context": "z a Figure 7 .2 A neural unit, taking 3 inputs x 1 , x 2 , and x 3 (and a bias b that we represent as a weight for an input clamped at +1) and producing an output y. We include some convenient intermediate variables: the output of the summation, z, and the output of the sigmoid, a. In this case the output of the unit y is the same as a, but in deeper networks we'll reserve y to mean the final output of the entire network, leaving a as the activation of an individual node.", "questions_and_answers": [{"answer_start": 135, "answer": "+1", "question": "What is the input clamped at?"}, {"answer_start": 217, "answer": "the output of the summation, z, and the output of the sigmoid", "question": "What are the two intermediate variables in a neural unit?"}, {"answer_start": 386, "answer": "the final output of the entire network", "question": "What does y mean in deeper networks?"}]}, {"context": "Let's walk through an example just to get an intuition. Let's suppose we have a unit with the following weight vector and bias:", "questions_and_answers": [{"answer_start": 19, "answer": "an example", "question": "Let's walk through what to get an intuition?"}, {"answer_start": 78, "answer": "a unit", "question": "What do we suppose we have with the following weight vector and bias?"}]}, {"context": "In practice, the sigmoid is not commonly used as an activation function. A function that is very similar but almost always better is the tanh function shown in Figure 7.3a; tanh tanh is a variant of the sigmoid that ranges from -1 to +1:", "questions_and_answers": [{"answer_start": 52, "answer": "activation function", "question": "In practice, the sigmoid is not commonly used as what?"}, {"answer_start": 234, "answer": "+1", "question": "What is the range of tanh tanh?"}, {"answer_start": 228, "answer": "-1", "question": "What is the range of the tanh tanh variant of the sigmoid?"}, {"answer_start": 234, "answer": "+1", "question": "What is the range of tanh tanh?"}, {"answer_start": 234, "answer": "+1", "question": "What is the range of tanh tanh?"}, {"answer_start": 228, "answer": "-1", "question": "What is the range of the tanh tanh variant of the sigmoid?"}]}, {"context": "These activation functions have different properties that make them useful for different language applications or network architectures. For example, the tanh function has the nice properties of being smoothly differentiable and mapping outlier values toward the mean. The rectifier function, on the other hand has nice properties that result from it being very close to linear. In the sigmoid or tanh functions, very high values of z result in values of y that are saturated, i.e., extremely close to 1, saturated and have derivatives very close to 0. Zero derivatives cause problems for learning, because as we'll see in Section [ 7.6 ], we'll train networks by propagating an error signal backwards, multiplying gradients (partial derivatives) from each layer of the network; gradients that are almost 0 cause the error signal to get smaller and smaller until it is too small to be used for training, a problem called the vanishing gradient vanishing gradient problem. Rectifiers don't have this problem, since the derivative of ReLU for high values of z is 1 rather than very close to 0.", "questions_and_answers": [{"answer_start": 32, "answer": "different properties", "question": "What makes activation functions useful for different language applications or network architectures?"}, {"answer_start": 154, "answer": "tanh function", "question": "What activation function has the nice properties of being smoothly differentiable and mapping outlier values toward the mean?"}, {"answer_start": 273, "answer": "rectifier function", "question": "What activation function has nice properties that result from being very close to linear?"}, {"answer_start": 413, "answer": "very high values of z", "question": "What results in values of y that are saturated?"}, {"answer_start": 553, "answer": "Zero derivatives", "question": "What causes problems for learning?"}, {"answer_start": 972, "answer": "Rectifiers", "question": "What doesn't have the vanishing gradient vanishing gradient problem?"}]}, {"context": "Early in the history of neural networks it was realized that the power of neural networks, as with the real neurons that inspired them, comes from combining these units into larger networks. One of the most clever demonstrations of the need for multi-layer networks was the proof by Minsky and Papert (1969) that a single neural unit cannot compute some very simple functions of its input. Consider the task of computing elementary logical functions of two inputs, like AND, OR, and XOR. As a reminder, here are the truth tables for those functions:", "questions_and_answers": [{"answer_start": 147, "answer": "combining these units into larger networks", "question": "What did the power of neural networks come from?"}, {"answer_start": 302, "answer": "1969", "question": "When was the proof by Minsky and Papert that a single neural unit cannot compute some very simple functions of its input?"}, {"answer_start": 470, "answer": "AND, OR, and XOR", "question": "What are the basic logical functions of two inputs?"}, {"answer_start": 516, "answer": "truth tables", "question": "What are the functions of AND, OR, and XOR?"}]}, {"context": "This example was first shown for the perceptron, which is a very simple neural perceptron unit that has a binary output and does not have a non-linear activation function. The output y of a perceptron is 0 or 1, and is computed as follows (using the same weight w, input x, and bias b as in Eq. [ 7.2 ]):", "questions_and_answers": [{"answer_start": 106, "answer": "binary", "question": "What type of output does the perceptron have?"}, {"answer_start": 204, "answer": "0 or 1", "question": "What is the output y of a perceptron?"}, {"answer_start": 297, "answer": "7.2", "question": "What is the value of the perceptron in Eq. 7.2?"}]}, {"context": "The intuition behind this important result relies on understanding that a perceptron is a linear classifier. For a two-dimensional input x 1 and x 2 , the perception equation, w 1 x 1 + w 2 x 2 + b = 0 is the equation of a line. (We can see this by putting it in the standard linear format:", "questions_and_answers": [{"answer_start": 74, "answer": "perceptron", "question": "What is a linear classifier?"}, {"answer_start": 176, "answer": "w 1 x 1 + w 2 x 2 + b", "question": "What is the perception equation of a line?"}, {"answer_start": 267, "answer": "standard linear format", "question": "How can we see the perception equation?"}]}, {"context": "Let's walk through what happens with the input x = [0, 0]. If we multiply each input value by the appropriate weight, sum, and then add the bias b, we get the vector [0, -1], and we then apply the rectified linear transformation to give the output of the h layer as [0, 0]. Now we once again multiply by the weights, sum, and add the bias (0 in this case) resulting in the value 0. The reader should work through the computation of the remaining 3 possible input pairs to see that the resulting y values are 1 for the inputs [0, 1] ? Figure 7 .5 The functions AND, OR, and XOR, represented with input x 1 on the x-axis and input x 2 on the y axis. Filled circles represent perceptron outputs of 1, and white circles perceptron outputs of 0. There is no way to draw a line that correctly separates the two categories for XOR. Figure styled after Russell and Norvig (2002) .", "questions_and_answers": [{"answer_start": 41, "answer": "input x = [0, 0]", "question": "What is the output of the h layer?"}, {"answer_start": 91, "answer": "b", "question": "What is the appropriate weight, sum, and then add the bias b?"}, {"answer_start": 132, "answer": "add the bias", "question": "What happens when we multiply by the weights, sum, and then add the bias b?"}, {"answer_start": 495, "answer": "y values", "question": "The reader should work through the computation of the remaining 3 possible input pairs to see what are 1 for the inputs [0, 1]?"}, {"answer_start": 560, "answer": "AND, OR, and XOR", "question": "What functions are represented with input x 1 on the x-axis and input x 2 on the y axis?"}, {"answer_start": 673, "answer": "perceptron outputs of 1, and white circles", "question": "What do Filled circles represent?"}, {"answer_start": 573, "answer": "XOR", "question": "There is no way to draw a line that correctly separates the two categories for what?"}, {"answer_start": 845, "answer": "Russell and Norvig", "question": "Who did the figure styled after?"}]}, {"context": ".6 XOR solution after Goodfellow et al. (2016). There are three ReLU units, in two layers; we've called them h 1 , h 2 (h for \"hidden layer\") and y 1 . As before, the numbers on the arrows represent the weights w for each unit, and we represent the bias b as a weight on a unit clamped to +1, with the bias weights/units in gray.", "questions_and_answers": [{"answer_start": 0, "answer": ".6", "question": "What is the XOR solution after Goodfellow et al. (2016)?"}, {"answer_start": 41, "answer": "2016", "question": "In what year did Goodfellow et al. publish a.6 XOR solution?"}, {"answer_start": 109, "answer": "h 1", "question": "What are the three ReLU units in two layers called?"}, {"answer_start": 115, "answer": "h 2", "question": "What are the layers of ReLU units called?"}, {"answer_start": 324, "answer": "gray", "question": "The bias weights/units are in what color?"}]}, {"context": "It's also instructive to look at the intermediate results, the outputs of the two hidden nodes h 1 and h 2 . We showed in the previous paragraph that the h vector for the inputs x = [0, 0] was [0, 0]. Figure 7.7b shows the values of the h layer for all 4 inputs. Notice that hidden representations of the two input points x = [0, 1] and x = [1, 0] (the two cases with XOR output = 1) are merged to the single point h = [1, 0]. The merger makes it easy to linearly separate the positive and negative cases of XOR. In other words, we can view the hidden layer of the network as forming a representation for the input.", "questions_and_answers": [{"answer_start": 59, "answer": "the outputs of the two hidden nodes", "question": "What are the intermediate results of h 1 and h 2?"}, {"answer_start": 178, "answer": "x", "question": "What is the h vector for the inputs?"}, {"answer_start": 201, "answer": "Figure 7.7b", "question": "What shows the values of the h layer for all 4 inputs?"}, {"answer_start": 337, "answer": "x = [1, 0]", "question": "The hidden representations of the two input points x = [0, 1] and what are merged to the single point h = [1,"}, {"answer_start": 427, "answer": "The merger", "question": "What makes it easy to separate the positive and negative cases of XOR?"}, {"answer_start": 576, "answer": "forming a representation for the input", "question": "What can we view the hidden layer of the network as?"}]}, {"context": "Note that the solution to the XOR problem requires a network of units with nonlinear activation functions. A network made up of simple linear (perceptron) units cannot solve the XOR problem. This is because a network formed by many layers of purely linear units can always be reduced (i.e., shown to be computationally identical to) a single layer of linear units with appropriate weights, and we've already shown (visually, in Figure 7 .5) that a single unit cannot solve the XOR problem. We'll return to this question on page 137.", "questions_and_answers": [{"answer_start": 51, "answer": "a network of units with nonlinear activation functions", "question": "What does the solution to the XOR problem require?"}, {"answer_start": 128, "answer": "simple linear (perceptron) units", "question": "What cannot solve the XOR problem?"}, {"answer_start": 333, "answer": "a single layer of linear units with appropriate weights", "question": "A network formed by many layers of purely linear units can always be reduced (i.e., shown to be computationally identical to) what?"}, {"answer_start": 523, "answer": "page 137", "question": "On what page will we return to the XOR problem?"}]}, {"context": "Let's now walk through a slightly more formal presentation of the simplest kind of neural network, the feedforward network. A feedforward network is a multilayer feedforward network network in which the units are connected with no cycles; the outputs from units in each layer are passed to units in the next higher layer, and no outputs are passed back to lower layers. (In Chapter 9 we'll introduce networks with cycles, called recurrent neural networks.) For historical reasons multilayer networks, especially feedforward networks, are sometimes called multi-layer perceptrons (or MLPs); this is a technical misnomer, multi-layer perceptrons MLP since the units in modern multilayer networks aren't perceptrons (perceptrons are purely linear, but modern networks are made up of units with non-linearities like sigmoids), but at some point the name stuck. Simple feedforward networks have three kinds of nodes: input units, hidden units, and output units. Figure [ 7.8 ] shows a picture.", "questions_and_answers": [{"answer_start": 99, "answer": "the feedforward network", "question": "What is the simplest kind of neural network?"}, {"answer_start": 326, "answer": "no outputs are passed back to lower layers", "question": "What happens in a feedforward network?"}, {"answer_start": 429, "answer": "recurrent neural networks", "question": "What are networks with cycles called?"}, {"answer_start": 555, "answer": "multi-layer perceptrons", "question": "What are feedforward networks sometimes called?"}, {"answer_start": 912, "answer": "input units, hidden units, and output units", "question": "What are the three types of nodes in a feedforward network?"}, {"answer_start": 957, "answer": "Figure [ 7.8 ]", "question": "What shows a picture of a simple feedforward network?"}]}, {"context": "The input layer x is a vector of simple scalar values just as we saw in Figure 7 .2. The core of the neural network is the hidden layer h formed of hidden units h i , hidden layer each of which is a neural unit as described in Section [ 7.1 ], taking a weighted sum of its inputs and then applying a non-linearity. In the standard architecture, each layer is fully-connected, meaning that each unit in each layer takes as input the outputs fully-connected from all the units in the previous layer, and there is a link between every pair of units from two adjacent layers. Thus each hidden unit sums over all the input units.", "questions_and_answers": [{"answer_start": 21, "answer": "a vector of simple scalar values", "question": "What is the input layer x?"}, {"answer_start": 123, "answer": "hidden layer h", "question": "What is the core of the neural network?"}, {"answer_start": 359, "answer": "fully-connected", "question": "In the standard architecture, each layer is what?"}, {"answer_start": 604, "answer": "all the input units", "question": "Each hidden unit sums over what?"}]}, {"context": "Recall that a single hidden unit has as parameters a weight vector and a bias. We represent the parameters for the entire hidden layer by combining the weight vector and bias for each unit i into a single weight matrix W and a single bias vector b for the whole layer (see Figure [ 7.8 ]) . Each element W ji of the weight matrix W represents the weight of the connection from the ith input unit x i to the jth hidden unit h j . Figure 7 .8 A simple 2-layer feedforward network, with one hidden layer, one output layer, and one input layer (the input layer is usually not counted when enumerating layers).", "questions_and_answers": [{"answer_start": 51, "answer": "a weight vector and a bias", "question": "What are the parameters of a single hidden unit?"}, {"answer_start": 138, "answer": "combining the weight vector and bias for each unit i into a single weight matrix W and a single bias vector b", "question": "How do we represent the parameters for the entire hidden layer?"}, {"answer_start": 343, "answer": "the weight of the connection", "question": "What does each element of the weight matrix W represent?"}, {"answer_start": 528, "answer": "input layer", "question": "A simple 2-layer feedforward network, with one hidden layer, one output layer, and one what?"}]}, {"context": "The output of the hidden layer, the vector h, is thus the following; (for this example we'll use the sigmoid function \u03c3 as our activation function):", "questions_and_answers": [{"answer_start": 32, "answer": "the vector h", "question": "What is the output of the hidden layer?"}]}, {"context": "Notice that we're applying the \u03c3 function here to a vector, while in Eq. [ 7.3 ] it was applied to a scalar. We're thus allowing \u03c3 ([ \u2022 ]), and indeed any activation function g([ \u2022 ]), to apply to a vector element-wise, so", "questions_and_answers": [{"answer_start": 50, "answer": "a vector", "question": "What is the  function applied to?"}, {"answer_start": 101, "answer": "scalar", "question": "In Eq. [ 7.3 ] what was the  function applied to?"}, {"answer_start": 151, "answer": "any activation function g([ \u2022 ]", "question": "What is allowed to apply to a vector element-wise?"}]}, {"context": "As we saw in Section [ 7.2 ], the resulting value h (for hidden but also for hypothesis) forms a representation of the input. The role of the output layer is to take this new representation h and compute a final output. This output could be a realvalued number, but in many cases the goal of the network is to make some sort of classification decision, and so we will focus on the case of classification.", "questions_and_answers": [{"answer_start": 31, "answer": "h", "question": "What form a representation of the input?"}, {"answer_start": 196, "answer": "compute a final output", "question": "What is the role of the output layer?"}, {"answer_start": 328, "answer": "classification", "question": "The goal of the network is to make some sort of what decision?"}]}, {"context": "If we are doing a binary task like sentiment classification, we might have a single output node, and its scalar value y is the probability of positive versus negative sentiment. If we are doing multinomial classification, such as assigning a part-ofspeech tag, we might have one output node for each potential part-of-speech, whose output value is the probability of that part-of-speech, and the values of all the output nodes must sum to one. The output layer is thus a vector y that gives a probability distribution across the output nodes.", "questions_and_answers": [{"answer_start": 23, "answer": "y", "question": "What is the probability of positive versus negative sentiment?"}, {"answer_start": 194, "answer": "multinomial", "question": "What type of classification is assigning a part-of-speech tag?"}, {"answer_start": 471, "answer": "vector y", "question": "What is the output layer?"}]}, {"context": "However, z can't be the output of the classifier, since it's a vector of real-valued numbers, while what we need for classification is a vector of probabilities. There is a convenient function for normalizing a vector of real values, by which we mean normalizing converting it to a vector that encodes a probability distribution (all the numbers lie between 0 and 1 and sum to 1): the softmax function that we saw on page 91 of softmax Chapter 5. For a vector z of dimensionality d, the softmax is defined as:", "questions_and_answers": [{"answer_start": 9, "answer": "z", "question": "What can't be the output of the classifier?"}, {"answer_start": 302, "answer": "a probability distribution", "question": "What does normalizing a vector encode?"}, {"answer_start": 385, "answer": "softmax", "question": "What is defined as for a vector z of dimensionality d?"}]}, {"context": "The softmax function will normalize it to a probability distribution: You may recall that softmax was exactly what is used to create a probability distribution from a vector of real-valued numbers (computed from summing weights times features) in the multinomial version of logistic regression in Chapter 5. That means we can think of a neural network classifier with one hidden layer as building a vector h which is a hidden layer representation of the input, and then running standard logistic regression on the features that the network develops in h. By contrast, in Chapter 5 the features were mainly designed by hand via feature templates. So a neural network is like logistic regression, but (a) with many layers, since a deep neural network is like layer after layer of logistic regression classifiers, and (b) rather than forming the features by feature templates, the prior layers of the network induce the feature representations themselves.", "questions_and_answers": [{"answer_start": 0, "answer": "The softmax function", "question": "What will normalize it to a probability distribution?"}, {"answer_start": 627, "answer": "feature templates", "question": "What were the features designed by hand in Chapter 5?"}, {"answer_start": 917, "answer": "feature representations", "question": "What do the prior layers of a neural network induce?"}]}, {"context": "Here are the final equations for a feedforward network with a single hidden layer, which takes an input vector x, outputs a probability distribution y, and is parameterized by weight matrices W and U and a bias vector b:", "questions_and_answers": [{"answer_start": 204, "answer": "a bias vector b", "question": "What is parameterized by a feedforward network with a single hidden layer?"}, {"answer_start": 98, "answer": "input vector x", "question": "What does a feedforward network take?"}]}, {"context": "We'll call this network a 2-layer network (we traditionally don't count the input layer when numbering layers, but do count the output layer). So by this terminology logistic regression is a 1-layer network.", "questions_and_answers": [{"answer_start": 26, "answer": "2-layer network", "question": "What is logistic regression a network called?"}, {"answer_start": 166, "answer": "logistic regression", "question": "What is a 1-layer network?"}]}, {"context": "Let's now set up some notation to make it easier to talk about deeper networks of depth more than 2. We'll use superscripts in square brackets to mean layer numbers, starting at 0 for the input layer. So W [1] will mean the weight matrix for the (first) hidden layer, and b [1] will mean the bias vector for the (first) hidden layer. n j will mean the number of units at layer j. We'll use g([ \u2022 ]) to stand for the activation function, which will tend to be ReLU or tanh for intermediate layers and softmax for output layers. We'll use a [i] to mean the output from layer i, and z [i] to mean the combination of weights and biases W [i] a [i\u22121] + b [i] . The 0th layer is for inputs, so the inputs x we'll refer to more generally as a [0] .", "questions_and_answers": [{"answer_start": 63, "answer": "deeper networks of depth", "question": "Let's set up some notation to make it easier to talk about what?"}, {"answer_start": 178, "answer": "0", "question": "What is the starting point for the input layer?"}, {"answer_start": 288, "answer": "the bias vector", "question": "What does b mean for the (first) hidden layer?"}, {"answer_start": 334, "answer": "n j", "question": "What will mean the number of units at layer j?"}, {"answer_start": 390, "answer": "g([ \u2022 ])", "question": "What will we use to stand for the activation function?"}, {"answer_start": 580, "answer": "z", "question": "What is the combination of weights and biases W [i] a [i1] + b [i]?"}, {"answer_start": 677, "answer": "inputs", "question": "The 0th layer is for what?"}]}, {"context": "Note that with this notation, the equations for the computation done at each layer are the same. The algorithm for computing the forward step in an n-layer feedforward network, given the input vector a [0] is thus simply:", "questions_and_answers": [{"answer_start": 30, "answer": "the equations for the computation done at each layer", "question": "What is the same with this notation?"}, {"answer_start": 148, "answer": "n-layer feedforward network", "question": "What is the algorithm for computing the forward step in?"}]}, {"context": "a [i] = g [i] (z [i] ) y = a [n] The activation functions g([ \u2022 ]) are generally different at the final layer. Thus g [2] might be softmax for multinomial classification or sigmoid for binary classification, while ReLU or tanh might be the activation function g([ \u2022 ]) at the internal layers.", "questions_and_answers": [{"answer_start": 8, "answer": "g", "question": "What does a [i] =?"}, {"answer_start": 173, "answer": "sigmoid", "question": "What is the activation function g([ \u2022 ]) for binary classification?"}, {"answer_start": 214, "answer": "ReLU or tanh", "question": "What might be the activation function g([ \u2022 ]) at the internal layers?"}]}, {"context": "More on the need for non-linear activation functions We mentioned in Section [ 7.2 ] that one of the reasons we use non-linear activation functions for each layer in a neural network is that if we did not, the resulting network is exactly equivalent to a single-layer network. Now that we have the notation for multilayer networks, we can see that intuition is more detail. Imagine the first two layers of such a network of purely linear layers:", "questions_and_answers": [{"answer_start": 191, "answer": "if we did not", "question": "Why do we use non-linear activation functions for each layer in a neural network?"}, {"answer_start": 348, "answer": "intuition", "question": "What is more detail in multilayer networks now that we have the notation for multilayer networks?"}, {"answer_start": 386, "answer": "first two layers", "question": "What are the first two layers of a network of purely linear layers?"}]}, {"context": "This generalizes to any number of layers. So without non-linear activation functions, a multilayer network is just a notational variant of a single layer network with a different set of weights, and we lose all the representational power of multilayer networks as we discussed in Section [ 7.2 ].", "questions_and_answers": [{"answer_start": 20, "answer": "any number of layers", "question": "This generalizes to what?"}, {"answer_start": 53, "answer": "non-linear activation functions", "question": "Without what is a multilayer network just a notational variant of a single layer network with a different set of weights?"}]}, {"context": "Replacing the bias unit In describing networks, we will often use a slightly simplified notation that represents exactly the same function without referring to an explicit bias node b. Instead, we add a dummy node a 0 to each layer whose value will always be 1. Thus layer 0, the input layer, will have a dummy node a we'll use:", "questions_and_answers": [{"answer_start": 66, "answer": "a slightly simplified notation", "question": "What type of notation is often used in describing networks?"}, {"answer_start": 201, "answer": "a dummy node a 0", "question": "What do we add to each layer whose value will always be 1?"}, {"answer_start": 201, "answer": "a dummy node a", "question": "What does layer 0, the input layer, have?"}]}, {"context": "Let's see how to apply feedforward networks to NLP tasks! In this section we'll look at classification tasks like sentiment analysis; in the next section we'll introduce neural language modeling.", "questions_and_answers": [{"answer_start": 23, "answer": "feedforward networks", "question": "What do we apply to NLP tasks?"}, {"answer_start": 114, "answer": "sentiment analysis", "question": "What is a classification task that we'll look at in this section?"}]}, {"context": "Let's begin with a simple two-layer sentiment classifier. You might imagine taking our logistic regression classifier of Chapter 5, which corresponds to a 1-layer network, and just adding a hidden layer. The input element x i could be scalar features like those in Figure [ 5.2 ], e .g., x 1 = count(words \u2208 doc), x 2 = count(positive lexicon words \u2208 doc), x 3 = 1 if \"no\" \u2208 doc, and so on. And the output layer y could have two nodes (one each for positive and negative), or 3 nodes (positive, negative, neutral), in which case y 1 would be the estimated probability of positive sentiment, y 2 the probability of negative and y 3 the probability of neutral. The resulting equations would be just what we saw above for a two-layer network (as sketched in Figure [ 7.10 ] ):", "questions_and_answers": [{"answer_start": 26, "answer": "two-layer sentiment classifier", "question": "What is the first step in creating a simple network?"}, {"answer_start": 188, "answer": "a hidden layer", "question": "What would you add to our logistic regression classifier?"}, {"answer_start": 288, "answer": "x 1", "question": "What is the input element x i?"}, {"answer_start": 529, "answer": "y 1", "question": "What would be the estimated probability of positive sentiment?"}, {"answer_start": 755, "answer": "Figure [ 7.10 ]", "question": "Where are the equations for a two-layer network shown?"}]}, {"context": "As we mentioned earlier, adding this hidden layer to our logistic regression regression classifier allows the network to represent the non-linear interactions between features. This alone might give us a better sentiment classifier.", "questions_and_answers": [{"answer_start": 57, "answer": "logistic regression regression classifier", "question": "What classifier does adding a hidden layer to allow the network to represent the non-linear interactions between features?"}, {"answer_start": 211, "answer": "sentiment classifier", "question": "What classifier could the hidden layer of the regression classifier give us?"}]}, {"context": "Most neural NLP applications do something different, however. Instead of using hand-built human-engineered features as the input to our classifier, we draw on deep learning's ability to learn features from the data by representing words as word2vec or GloVe embeddings (Chapter 6). For a text with n input words/tokens w 1 , ..., w n , the input vector will be the concatenated embeddings of the n words: [e w 1 ; ...; e w n ]. If we use the semicolon ';' to mean concatenation of vectors, the equation for our sentiment classifier will be (as sketched in Figure [ 7.11 ] The idea of using word2vec or GloVe embeddings as our input representationand more generally the idea of relying on another algorithm to have already learned an embedding representation for our input words -is called pretraining. Using pretraining pretrained embedding representations, whether simple static word embeddings like word2vec or the more powerful contextual embeddings we'll introduce in Chapter 11, is one of the central ideas of deep learning. (It's also, possible, however, to train the word embeddings as part of an NLP task; we'll talk about how to do this Section [ 7.7 ] in the context of the neural language modeling task.)", "questions_and_answers": [{"answer_start": 5, "answer": "neural NLP applications", "question": "What do most NLP applications do something different?"}, {"answer_start": 215, "answer": "by representing words as word2vec or GloVe embeddings", "question": "How do neural NLP applications learn features from data?"}, {"answer_start": 336, "answer": "the input vector", "question": "What will be the concatenated embeddings of the n words?"}, {"answer_start": 442, "answer": "semicolon", "question": "What is used to mean concatenation of vectors?"}, {"answer_start": 789, "answer": "pretraining", "question": "What is one of the central ideas of deep learning?"}, {"answer_start": 1184, "answer": "neural language modeling task", "question": "What type of task is it possible to train word embeddings as part of?"}]}, {"context": "As our second application of feedforward networks, let's consider language modeling: predicting upcoming words from prior word context. Neural language modeling is an important NLP task in itself, and it plays a role in many important algorithms for tasks like machine translation, summarization, speech recognition, grammar correction, and dialogue. We'll describe simple feedforward neural language models, first introduced by Bengio et al. (2003) more powerful architectures like the recurrent nets or transformer networks to be introduced in Chapter 9, the feedforward language model introduces many of the important concepts of neural language modeling. Neural language models have many advantages over the n-gram language models of Chapter 3. Compared to n-gram models, neural language models can handle much longer histories, can generalize better over contexts of similar words, and are more accurate at word-prediction. On the other hand, neural net language models are much more complex, slower to train, and less interpretable than n-gram models, so for many (especially smaller) tasks an n-gram language model is still the right tool.", "questions_and_answers": [{"answer_start": 66, "answer": "language modeling", "question": "What is the second application of feedforward networks?"}, {"answer_start": 136, "answer": "Neural language modeling", "question": "What is an important NLP task in itself?"}, {"answer_start": 429, "answer": "Bengio et al.", "question": "Who first introduced simple feedforward neural language models?"}, {"answer_start": 546, "answer": "Chapter 9", "question": "In what chapter are recurrent nets and transformer networks introduced?"}, {"answer_start": 659, "answer": "Neural language models", "question": "What have many advantages over the n-gram language models of Chapter 3?"}, {"answer_start": 815, "answer": "longer histories", "question": "What can neural language models handle better than n-gram models?"}, {"answer_start": 712, "answer": "n-gram", "question": "Neural net language models are much more complex, slower to train, and less interpretable than what model?"}]}, {"context": "A feedforward neural LM is a feedforward network that takes as input at time t a representation of some number of previous words (w t\u22121 , w t\u22122 , etc.) and outputs a probability distribution over possible next words. Thus-like the n-gram LM-the feedforward neural LM approximates the probability of a word given the entire prior context P(w t |w 1:t\u22121 ) by approximating based on the N previous words:", "questions_and_answers": [{"answer_start": 27, "answer": "a feedforward network", "question": "What is a feedforward neural LM?"}, {"answer_start": 156, "answer": "outputs a probability distribution over possible next words", "question": "What does a feedforward neural LM do?"}, {"answer_start": 280, "answer": "the probability of a word", "question": "What does the feedforward neural LM approximate?"}]}, {"context": "In the following examples we'll use a 4-gram example, so we'll show a net to estimate the probability P(w t = i|w t\u22123 , w t\u22122 , w t\u22121 ).", "questions_and_answers": [{"answer_start": 38, "answer": "4-gram", "question": "In the following examples, we'll use what example?"}]}, {"context": "Neural language models represent words in this prior context by their embeddings, rather than just by their word identity as used in n-gram language models. Using embeddings allows neural language models to generalize better to unseen data. For example, suppose we've seen this sentence in training:", "questions_and_answers": [{"answer_start": 70, "answer": "embeddings", "question": "Neural language models represent words in this prior context by what?"}, {"answer_start": 70, "answer": "embeddings", "question": "What allows neural language models to generalize better to unseen data?"}, {"answer_start": 290, "answer": "training", "question": "What type of training is a neural language model used for?"}]}, {"context": "forward inference Forward inference is the task, given an input, of running a forward pass on the network to produce a probability distribution over possible outputs, in this case next words.", "questions_and_answers": [{"answer_start": 0, "answer": "forward inference", "question": "What is the task of running a forward pass on the network to produce a probability distribution over possible outputs?"}]}, {"context": "We first represent each of the N previous words as a one-hot vector of length |V |, i.e., with one dimension for each word in the vocabulary. A one-hot vector is one-hot vector a vector that has one element equal to 1-in the dimension corresponding to that word's index in the vocabulary-while all the other elements are set to zero. Thus in a one-hot representation for the word \"toothpaste\", supposing it is V 5 , i.e., index 5 in the vocabulary, x 5 = 1, and x i = 0 \u2200i = 5, as shown here:", "questions_and_answers": [{"answer_start": 53, "answer": "one-hot", "question": "What is the first vector of each of the N previous words?"}, {"answer_start": 53, "answer": "one-hot vector", "question": "What is one-hot vector a vector that has one element equal to 1-in the dimension corresponding to that word's index in the vocabulary?"}, {"answer_start": 381, "answer": "toothpaste", "question": "What word is represented as a one-hot vector if it is V 5?"}]}, {"context": "The 3 resulting embedding vectors are concatenated to produce e, the embedding layer. This is followed by a hidden layer and an output layer whose softmax produces a probability distribution over words. For example y 42 , the value of output node 42, is the probability of the next word w t being V 42 , the vocabulary word with index 42 (which is the word 'fish' in our example).", "questions_and_answers": [{"answer_start": 2, "answer": "e", "question": "How many embedding vectors are concatenated to produce e?"}, {"answer_start": 106, "answer": "a hidden layer and an output layer", "question": "What are followed by the embedding layer?"}, {"answer_start": 287, "answer": "w t", "question": "What is the probability of the next word being V 42?"}]}, {"context": "multiplied by the embedding matrix E, to give the first part of the first hidden layer, the embedding layer. Since each column of the input matrix E is an embedding layer embedding for a word, and the input is a one-hot column vector x i for word V i , the embedding layer for input w will be Ex i = e i , the embedding for word i. We now concatenate the three embeddings for the three context words to produce the embedding layer e.", "questions_and_answers": [{"answer_start": 92, "answer": "embedding layer", "question": "What is the first part of the first hidden layer?"}, {"answer_start": 185, "answer": "a word", "question": "Each column of the input matrix E is an embedding layer embedding for what?"}, {"answer_start": 155, "answer": "embedding layer e", "question": "What is the first part of the first hidden layer?"}]}, {"context": "We multiply by W (and add b) and pass through the ReLU (or other) activation function to get the hidden layer h. 3. Multiply by U: h is now multiplied by U 4. Apply softmax: After the softmax, each node i in the output layer estimates the probability P(w t = i|w t\u22121 , w t\u22122 , w t\u22123 )", "questions_and_answers": [{"answer_start": 3, "answer": "multiply by W", "question": "How do we get the hidden layer h?"}, {"answer_start": 116, "answer": "Multiply by U", "question": "How is h multiplied by U?"}, {"answer_start": 165, "answer": "softmax", "question": "What does each node i in the output layer estimate the probability P(w t = i|w t1, "}]}, {"context": "In summary, the equations for a neural language model with a window size of 3, Note that we formed the embedding layer e by concatenating the 3 embeddings for the three context vectors; we'll often use semicolons to mean concatenation of vectors.", "questions_and_answers": [{"answer_start": 202, "answer": "semicolons", "question": "What do we often use to mean concatenation of vectors?"}, {"answer_start": 103, "answer": "embedding layer e", "question": "What did we form by concatenating the 3 embeddings for the three context vectors?"}]}, {"context": "In the next section we'll introduce a general algorithm for training neural networks, and then return to how to specifically train the neural language model in Section [ 7.7 ].", "questions_and_answers": [{"answer_start": 160, "answer": "Section [ 7.7 ].", "question": "In what section will we return to how to specifically train the neural language model?"}]}, {"context": "In general, we do all this by drawing on the methods we introduced in Chapter 5 for logistic regression, so the reader should be comfortable with that chapter before proceeding.", "questions_and_answers": [{"answer_start": 70, "answer": "Chapter 5", "question": "In what chapter are the methods for logistic regression introduced?"}]}, {"context": "First, we'll need a loss function that models the distance between the system output and the gold output, and it's common to use the loss function used for logistic regression, the cross-entropy loss.", "questions_and_answers": [{"answer_start": 129, "answer": "the loss function used for logistic regression", "question": "What is the cross-entropy loss?"}, {"answer_start": 177, "answer": "the cross-entropy loss", "question": "What is the loss function used for logistic regression called?"}, {"answer_start": 129, "answer": "the loss function", "question": "What is used for logistic regression?"}]}, {"context": "Second, to find the parameters that minimize this loss function, we'll use the gradient descent optimization algorithm introduced in Chapter 5.", "questions_and_answers": [{"answer_start": 79, "answer": "gradient descent optimization algorithm", "question": "What algorithm is used to find the parameters that minimize this loss function?"}]}, {"context": "Third, gradient descent requires knowing the gradient of the loss function, the vector that contains the partial derivative of the loss function with respect to each of the parameters. In logistic regression, for each observation we could directly compute the derivative of the loss function with respect to an individual w or b. But for neural networks, with millions of parameters in many layers, it's much harder to see how to compute the partial derivative of some weight in layer 1 when the loss is attached to some much later layer. How do we partial out the loss over all those intermediate layers? The answer is the algorithm called error backpropagation or backward differentiation.", "questions_and_answers": [{"answer_start": 7, "answer": "gradient descent", "question": "What requires knowing the gradient of the loss function?"}, {"answer_start": 188, "answer": "logistic regression", "question": "In what type of regression could we directly compute the derivative of the loss function with respect to an individual w or b?"}, {"answer_start": 360, "answer": "millions", "question": "How many parameters are in neural networks?"}, {"answer_start": 549, "answer": "partial out the loss", "question": "How do we compute the partial derivative of some weight in layer 1?"}, {"answer_start": 641, "answer": "error backpropagation or backward differentiation", "question": "What is the algorithm used to partial out the loss over all the intermediate layers?"}]}, {"context": "The cross-entropy loss that is used in neural networks is the same one we saw for cross-entropy loss logistic regression. In fact, if the neural network is being used as a binary classifier, with the sigmoid at the final layer, the loss function is exactly the same as we saw with logistic regression in Eq. [ 5.11 ]:", "questions_and_answers": [{"answer_start": 4, "answer": "cross-entropy loss", "question": "What is used in neural networks?"}, {"answer_start": 200, "answer": "sigmoid", "question": "What is at the final layer of a binary classifier?"}, {"answer_start": 172, "answer": "binary classifier", "question": "What is the neural network being used as?"}, {"answer_start": 310, "answer": "5.11", "question": "What is the sigmoid at the final layer of a binary classifier?"}]}, {"context": "What about if the neural network is being used as a multinomial classifier? Let y be a vector over the C classes representing the true output probability distribution. The cross-entropy loss here is", "questions_and_answers": [{"answer_start": 52, "answer": "multinomial classifier", "question": "What is the neural network being used as?"}, {"answer_start": 85, "answer": "a vector", "question": "What is y in a multinomial classifier?"}, {"answer_start": 172, "answer": "cross-entropy loss", "question": "What is the loss in the neural network used as a multinomial classifier?"}]}, {"context": "Hence the cross-entropy loss is simply the log of the output probability corresponding to the correct class, and we therefore also call this the negative log likelihood loss:", "questions_and_answers": [{"answer_start": 145, "answer": "negative log likelihood loss", "question": "What is the cross-entropy loss also called?"}, {"answer_start": 39, "answer": "the log of the output probability corresponding to the correct class", "question": "What is the cross-entropy loss?"}]}, {"context": "negative log likelihood loss L CE (\u0177, y) = \u2212 log\u0177 i , (where i is the correct class) ([ 7.26 ]) Plugging in the softmax formula from Eq. [ 7.9 ], and with K the number of classes:", "questions_and_answers": [{"answer_start": 0, "answer": "negative log likelihood loss", "question": "What is L CE (, y) =  log i?"}, {"answer_start": 139, "answer": "7.9", "question": "What is the softmax formula from Eq."}]}, {"context": "How do we compute the gradient of this loss function? Computing the gradient requires the partial derivative of the loss function with respect to each parameter. For a network with one weight layer and sigmoid output (which is what logistic regression is), we could simply use the derivative of the loss that we used for logistic regression in Eq. [ 7.28 ] (and derived in Section [ 5.8 ]):", "questions_and_answers": [{"answer_start": 10, "answer": "compute the gradient", "question": "How do we compute the loss function?"}, {"answer_start": 90, "answer": "partial derivative", "question": "What is required to compute the gradient of a loss function?"}, {"answer_start": 232, "answer": "logistic regression", "question": "What is a network with one weight layer and sigmoid output?"}, {"answer_start": 373, "answer": "Section [ 5.8 ]", "question": "Where is the derivative of the loss that we used for logistic regression derived?"}]}, {"context": "Or for a network with one hidden layer and softmax output, we could use the derivative of the softmax loss from Eq. [ 5.37 ]:", "questions_and_answers": [{"answer_start": 43, "answer": "softmax", "question": "What is the output of a network with one hidden layer?"}, {"answer_start": 118, "answer": "5.37", "question": "What is the derivative of the softmax loss from Eq."}]}, {"context": "A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.", "questions_and_answers": [{"answer_start": 2, "answer": "computation graph", "question": "What is a representation of the process of computing a mathematical expression?"}, {"answer_start": 2, "answer": "computation", "question": "A graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations?"}]}, {"context": "Consider computing the function L(a, b, c) = c(a + 2b). If we make each of the component addition and multiplication operations explicit, and add names (d and e) for the intermediate outputs, the resulting series of computations is:", "questions_and_answers": [{"answer_start": 32, "answer": "L(a, b, c) = c(a + 2b)", "question": "What is the function L(a, b, c) = c(a + 2b)?"}, {"answer_start": 142, "answer": "add names (d and e) for the intermediate outputs", "question": "What do we do with the component addition and multiplication operations?"}]}, {"context": "The importance of the computation graph comes from the backward pass, which is used to compute the derivatives that we'll need for the weight update. In this example our goal is to compute the derivative of the output function L with respect to each of the input variables, i.e., \u2202 L \u2202 a , \u2202 L \u2202 b , and \u2202 L \u2202 c . The derivative \u2202 L \u2202 a , tells us how much a small change in a affects L.", "questions_and_answers": [{"answer_start": 51, "answer": "the backward pass", "question": "What is used to compute the derivatives that we'll need for the weight update?"}, {"answer_start": 181, "answer": "compute the derivative of the output function L", "question": "What is the goal of the backward pass?"}, {"answer_start": 348, "answer": "how much a small change in a affects L", "question": "What does the derivative  L  a tell us?"}]}, {"context": "Backwards differentiation makes use of the chain rule in calculus, so let's rechain rule mind ourselves of that. Suppose we are computing the derivative of a composite function f (x) = u(v(x)). The derivative of f (x) is the derivative of u(x) with respect to v(x) times the derivative of v(x) with respect to x:", "questions_and_answers": [{"answer_start": 0, "answer": "Backwards", "question": "What differentiation makes use of the chain rule in calculus?"}, {"answer_start": 185, "answer": "u(v(x)", "question": "What is the derivative of a composite function f (x) equal to?"}, {"answer_start": 187, "answer": "v(x)", "question": "The derivative of f (x) is the derivative of u(x) with respect to what?"}]}, {"context": "The chain rule extends to more than two functions. If computing the derivative of a composite function f (x) = u(v(w(x))), the derivative of f (x) is:", "questions_and_answers": [{"answer_start": 26, "answer": "more than two functions", "question": "The chain rule extends to what?"}, {"answer_start": 111, "answer": "u(v(w(x))", "question": "What is the derivative of f (x) if computing the derivative of a composite function f (x) =?"}]}, {"context": "The intuition of backward differentiation is to pass gradients back from the final node to all the nodes in the graph. Figure 7 .17 shows part of the backward computation at one node e. Each node takes an upstream gradient that is passed in from its parent node to the right, and for each of its inputs computes a local gradient (the gradient of its output with respect to its input), and uses the chain rule to multiply these two to compute a downstream gradient to be passed on to the next earlier node. Figure 7 .15 Each node (like e here) takes an upstream gradient, multiplies it by the local gradient (the gradient of its output with respect to its input), and uses the chain rule to compute a downstream gradient to be passed on to a prior node. A node may have multiple local gradients if it has multiple inputs.", "questions_and_answers": [{"answer_start": 45, "answer": "to pass gradients back from the final node to all the nodes in the graph", "question": "What is the intuition of backward differentiation?"}, {"answer_start": 330, "answer": "the gradient of its output with respect to its input", "question": "What is a local gradient?"}, {"answer_start": 330, "answer": "the gradient of its output with respect to its input", "question": "What is the local gradient?"}, {"answer_start": 769, "answer": "multiple", "question": "A node may have how many local gradients if it has multiple inputs?"}]}, {"context": "Let's now compute the 3 derivatives we need. Since in the computation graph L = ce, we can directly compute the derivative \u2202 L \u2202 c :", "questions_and_answers": [{"answer_start": 22, "answer": "3", "question": "How many derivatives do we need?"}, {"answer_start": 76, "answer": "L = ce", "question": "What is the name of the graph where we can directly compute the derivative  L  c?"}]}, {"context": "For the other two, we'll need to use the chain rule:", "questions_and_answers": [{"answer_start": 37, "answer": "the chain rule", "question": "What do we need to use for the other two?"}]}, {"context": "In the backward pass, we compute each of these partials along each edge of the graph from right to left, using the chain rule just as we did above. Thus we begin by computing the downstream gradients from node L, which are \u2202 L \u2202 e and \u2202 L \u2202 c . For node e, we then multiply this upstream gradient \u2202 L \u2202 e by the local gradient (the gradient of the output with respect to the input), \u2202 e \u2202 d to get the output we send back to node d:", "questions_and_answers": [{"answer_start": 111, "answer": "the chain rule", "question": "What is used to compute the partials along each edge of the graph from right to left?"}, {"answer_start": 162, "answer": "by computing the downstream gradients from node L", "question": "How do we begin the backward pass?"}, {"answer_start": 312, "answer": "local gradient", "question": "What is the gradient of the output with respect to the input?"}]}, {"context": "Of course computation graphs for real neural networks are much more complex. Figure 7 .17 shows a sample computation graph for a 2-layer neural network with n 0 = 2, n 1 = 2, and n 2 = 1, assuming binary classification and hence using a sigmoid output unit for simplicity. The function that the computation graph is computing is:", "questions_and_answers": [{"answer_start": 10, "answer": "computation graphs", "question": "What is much more complex for real neural networks?"}, {"answer_start": 237, "answer": "sigmoid output unit", "question": "What is used for simplicity in a computation graph for a 2-layer neural network?"}, {"answer_start": 157, "answer": "n 0 = 2, n 1 = 2, and n 2 = 1", "question": "What is a typical computation graph for a 2-layer neural network?"}, {"answer_start": 277, "answer": "function", "question": "What is the computation graph computing?"}]}, {"context": "For the backward pass we'll also need to compute the loss L. The loss function for binary sigmoid output from Eq. [ 7.23 ] is", "questions_and_answers": [{"answer_start": 65, "answer": "loss function", "question": "What is the loss function for binary sigmoid output from Eq. [ 7.23 ]?"}, {"answer_start": 116, "answer": "7.23", "question": "What is the loss function for binary sigmoid output from Eq."}]}, {"context": "Our output\u0177 = a [2] , so we can rephrase this as L CE (a [2] , y) = \u2212 y log a [2] Figure 7 .17 Sample computation graph for a simple 2-layer neural net (= 1 hidden layer) with two input dimensions and 2 hidden dimensions.", "questions_and_answers": [{"answer_start": 49, "answer": "L CE", "question": "What is our output = a [2]?"}]}, {"context": "The weights that need updating (those for which we need to know the partial derivative of the loss function) are shown in teal. In order to do the backward pass, we'll need to know the derivatives of all the functions in the graph. We already saw in Section [ 5.8 ] the derivative of the sigmoid \u03c3 :", "questions_and_answers": [{"answer_start": 122, "answer": "teal", "question": "The weights that need updating are shown in what color?"}, {"answer_start": 181, "answer": "the derivatives of all the functions in the graph", "question": "In order to do the backward pass, we'll need to know what?"}, {"answer_start": 266, "answer": "the derivative of the sigmoid", "question": "What did we already see in Section [ 5.8 ]?"}]}, {"context": "We'll also need the derivatives of each of the other activation functions. The derivative of tanh is:", "questions_and_answers": [{"answer_start": 53, "answer": "activation functions", "question": "What are the derivatives of tanh?"}, {"answer_start": 93, "answer": "tanh", "question": "What is the derivative of?"}]}, {"context": "We'll give the start of the computation, computing the derivative of the loss function L with respect to z, or \u2202 L \u2202 z (and leaving the rest of the computation as an exercise for the reader). By the chain rule:", "questions_and_answers": [{"answer_start": 51, "answer": "the derivative of the loss function L with respect to z", "question": "What is computed at the start of the computation?"}, {"answer_start": 199, "answer": "chain rule", "question": "What rule is used to compute the derivative of the loss function L with respect to z?"}]}, {"context": "Next, by the derivative of the sigmoid: 2] (1 \u2212 a [2] ) Finally, we can use the chain rule:", "questions_and_answers": [{"answer_start": 9, "answer": "the derivative of the sigmoid", "question": "What is the chain rule?"}, {"answer_start": 76, "answer": "the chain rule", "question": "What rule can we use?"}]}, {"context": "Continuing the backward computation of the gradients (next by passing the gradients over b [2] 1 and the two product nodes, and so on, back to all the orange nodes), is left as an exercise for the reader.", "questions_and_answers": [{"answer_start": 193, "answer": "the reader", "question": "Who does the backward computation of the gradients serve as an exercise for?"}]}, {"context": "Optimization in neural networks is a non-convex optimization problem, more complex than for logistic regression, and for that and other reasons there are many best practices for successful learning.", "questions_and_answers": [{"answer_start": 92, "answer": "logistic regression", "question": "Optimization in neural networks is more complex than what?"}, {"answer_start": 0, "answer": "Optimization in neural networks", "question": "What is a non-convex optimization problem?"}]}, {"context": "For logistic regression we can initialize gradient descent with all the weights and biases having the value 0. In neural networks, by contrast, we need to initialize the weights with small random numbers. It's also helpful to normalize the input values to have 0 mean and unit variance.", "questions_and_answers": [{"answer_start": 4, "answer": "logistic regression", "question": "For what type of regression can we initialize gradient descent with all the weights and biases having the value 0."}, {"answer_start": 155, "answer": "initialize the weights with small random numbers", "question": "What do neural networks need to do?"}, {"answer_start": 226, "answer": "normalize the input values", "question": "What is helpful to have 0 mean and unit variance?"}]}, {"context": "Finally, most modern neural networks are built using computation graph formalisms that make it easy and natural to do gradient computation and parallelization onto vector-based GPUs (Graphic Processing Units). PyTorch (Paszke et al., 2017) and TensorFlow (Abadi et al., 2015) are two of the most popular. The interested reader should consult a neural network textbook for further details; some suggestions are at the end of the chapter.", "questions_and_answers": [{"answer_start": 65, "answer": "graph formalisms", "question": "What makes it easy and natural to do gradient computation and parallelization onto vector-based GPUs?"}, {"answer_start": 210, "answer": "PyTorch", "question": "What is one of the most popular neural networks?"}, {"answer_start": 342, "answer": "a neural network textbook", "question": "What should the interested reader consult for further details?"}]}, {"context": "For language modeling, the classes are the words in the vocabulary, so\u0177 i here means the probability that the model assigns to the correct next word w t :", "questions_and_answers": [{"answer_start": 85, "answer": "the probability that the model assigns to the correct next word", "question": "What does the class mean?"}, {"answer_start": 23, "answer": "the classes", "question": "What are the words in the vocabulary?"}]}, {"context": "The parameter update for stochastic gradient descent for this loss from step s to s + 1 is then:", "questions_and_answers": [{"answer_start": 4, "answer": "parameter update for stochastic gradient descent", "question": "What is the update for this loss from step s to s + 1?"}]}, {"context": "Training the parameters to minimize loss will result both in an algorithm for language modeling (a word predictor) but also a new set of embeddings E that can be used as word representations for other tasks.", "questions_and_answers": [{"answer_start": 137, "answer": "embeddings", "question": "What is a new set of E that can be used as word representations for other tasks?"}, {"answer_start": 99, "answer": "word predictor", "question": "What is an algorithm for language modeling called?"}]}, {"context": "[ \u2022 ] Neural networks are built out of neural units, originally inspired by human neurons but now simply an abstract computational device. [ \u2022 ] Each neural unit multiplies input values by a weight vector, adds a bias, and then applies a non-linear activation function like sigmoid, tanh, or rectified linear unit. [ \u2022 ] In a fully-connected, feedforward network, each unit in layer i is connected to each unit in layer i + 1, and there are no cycles. [ \u2022 ] The power of neural networks comes from the ability of early layers to learn representations that can be utilized by later layers in the network. [ \u2022 ] Neural networks are trained by optimization algorithms like gradient descent. [ \u2022 ] Error backpropagation, backward differentiation on a computation graph, is used to compute the gradients of the loss function for a network. [ \u2022 ] Neural language models use a neural network as a probabilistic classifier, to compute the probability of the next word given the previous n words. [ \u2022 ] Neural language models can use pretrained embeddings, or can learn embeddings from scratch in the process of language modeling.", "questions_and_answers": [{"answer_start": 39, "answer": "neural units", "question": "What are neural networks built out of?"}, {"answer_start": 274, "answer": "sigmoid, tanh, or rectified linear unit", "question": "What are some non-linear activation functions?"}, {"answer_start": 441, "answer": "no cycles", "question": "How many cycles are there in a fully connected, feedforward network?"}, {"answer_start": 513, "answer": "early layers", "question": "The power of neural networks comes from the ability of which layers to learn representations that can be utilized by later layers in the network?"}, {"answer_start": 670, "answer": "gradient descent", "question": "What optimization algorithm is used to train neural networks?"}, {"answer_start": 694, "answer": "Error backpropagation", "question": "What is used to compute the gradients of the loss function for a network?"}, {"answer_start": 890, "answer": "probabilistic", "question": "Neural language models use a neural network as a classifier to compute the probability of the next word given the previous n words?"}, {"answer_start": 1036, "answer": "embeddings", "question": "What can neural language models learn from scratch in the process of language modeling?"}]}, {"context": "The origins of neural networks lie in the 1940s McCulloch-Pitts neuron (McCulloch and Pitts, 1943 ), a simplified model of the human neuron as a kind of computing element that could be described in terms of propositional logic. By the late 1950s and early 1960s, a number of labs (including Frank Rosenblatt at Cornell and Bernard Widrow at Stanford) developed research into neural networks; this phase saw the development of the perceptron (Rosenblatt, 1958) , and the transformation of the threshold into a bias, a notation we still use (Widrow and Hoff, 1960) . The field of neural networks declined after it was shown that a single perceptron unit was unable to model functions as simple as XOR (Minsky and Papert, 1969) . While some small amount of work continued during the next two decades, a major revival for the field didn't come until the 1980s, when practical tools for building deeper networks like error backpropagation became widespread (Rumelhart et al., 1986) . During the 1980s a wide variety of neural network and related architectures were developed, particularly for applications in psychology and cognitive science (Rumelhart and McClelland 1986b , McClelland and Elman 1986 , Rumelhart and McClelland 1986a , Elman 1990 , for which the term connectionist or paralconnectionist lel distributed processing was often used (Feldman and Ballard 1982, Smolensky 1988) . Many of the principles and techniques developed in this period are foundational to modern work, including the ideas of distributed representations (Hinton, 1986) , recurrent networks (Elman, 1990) , and the use of tensors for compositionality (Smolensky, 1990) .", "questions_and_answers": [{"answer_start": 42, "answer": "1940s", "question": "In what decade did the McCulloch-Pitts neuron originate?"}, {"answer_start": 341, "answer": "Stanford", "question": "Where did Bernard Widrow work?"}, {"answer_start": 719, "answer": "1969", "question": "When was it shown that a single perceptron unit was unable to model functions as simple as XOR?"}, {"answer_start": 850, "answer": "1980s", "question": "When did a major revival for the field of neural networks come?"}, {"answer_start": 1104, "answer": "psychology and cognitive science", "question": "Applications of neural networks and related architectures were developed during the 1980s, particularly for applications in what?"}, {"answer_start": 1601, "answer": "tensors", "question": "What did Smolensky use for compositionality?"}]}, {"context": "By the 1990s larger neural networks began to be applied to many practical language processing tasks as well, like handwriting recognition (LeCun et al. 1989) and speech recognition (Morgan and Bourlard 1990) . By the early 2000s, improvements in computer hardware and advances in optimization and training techniques made it possible to train even larger and deeper networks, leading to the modern term deep learning (Hinton et al. 2006 , Bengio et al. 2007 . We cover more related history in Chapter 9 and Chapter 26.", "questions_and_answers": [{"answer_start": 114, "answer": "handwriting recognition", "question": "What is an example of a language processing task LeCun and Bourlard performed in 1989?"}, {"answer_start": 152, "answer": "1989", "question": "When did LeCun and colleagues publish their work on handwriting recognition?"}, {"answer_start": 403, "answer": "deep learning", "question": "What is the modern term for what?"}, {"answer_start": 432, "answer": "2006", "question": "In what year did Hinton et al. create the term deep learning?"}, {"answer_start": 453, "answer": "2007", "question": "In what year did Bengio and Hinton come up with the term deep learning?"}, {"answer_start": 493, "answer": "Chapter 9 and Chapter 26", "question": "Where do we cover more related history?"}]}, {"context": "There are a number of excellent books on the subject. Goldberg (2017) has superb coverage of neural networks for natural language processing. For neural networks in general see Goodfellow et al. (2016) and Nielsen (2015).", "questions_and_answers": [{"answer_start": 22, "answer": "excellent books", "question": "What is there a number of on neural networks?"}, {"answer_start": 54, "answer": "Goldberg", "question": "Who wrote a book on neural networks for natural language processing?"}, {"answer_start": 177, "answer": "Goodfellow et al.", "question": "Who published a book on neural networks in 2016?"}, {"answer_start": 206, "answer": "Nielsen", "question": "Who published a book on neural networks in 2015?"}]}, {"context": "Dionysius Thrax of Alexandria (c. 100 B.C. ), or perhaps someone else (it was a long time ago), wrote a grammatical sketch of Greek (a \u201ctechn \u0304e\u201d) that summarized the linguistic knowledge of his day. This work is the source of an astonishing proportion of modern linguistic vocabulary, including the words syntax, diphthong, clitic, and analogy. Also included are a description of eight parts of speech: noun, verb,parts of speech pronoun, preposition, adverb, conjunction, participle, and article. Although earlier scholars (including Aristotle as well as the Stoics) had their own lists of parts of speech, it was Thrax\u2019s set of eight that became the basis for descriptions of European languages for the next 2000 years. (All the way to the Schoolhouse Rock educational television shows of our childhood, which had songs about 8 parts of speech, like the late great Bob Dorough\u2019s Conjunction Junction.) The durability of parts of speech through two millennia speaks to their centrality in models of human language.", "questions_and_answers": [{"answer_start": 0, "answer": "Dionysius Thrax", "question": "Who wrote a grammatical sketch of Greek?"}, {"answer_start": 104, "answer": "grammatical sketch of Greek", "question": "What did Dionysius Thrax write?"}, {"answer_start": 306, "answer": "syntax, diphthong, clitic, and analogy", "question": "What words are included in Thrax's grammatical sketch?"}, {"answer_start": 381, "answer": "eight", "question": "How many parts of speech did Thrax describe?"}, {"answer_start": 536, "answer": "Aristotle", "question": "Who wrote a grammatical sketch of Greek?"}, {"answer_start": 868, "answer": "Bob Dorough", "question": "Who wrote Conjunction Junction?"}, {"answer_start": 947, "answer": "two millennia", "question": "The durability of parts of speech through how many millennia speaks to their centrality in models of human language?"}]}, {"context": "Proper names are another important and anciently studied linguistic category. While parts of speech are generally assigned to individual words or morphemes, a proper name is often an entire multiword phrase, like the name \"Marie Curie\", the location \"New York City\", or the organization \"Stanford University\". We'll use the term named entity for, roughly speaking, anything that can be referred to with a named entity proper name: a person, a location, an organization, although as we'll see the term is commonly extended to include things that aren't entities per se.", "questions_and_answers": [{"answer_start": 0, "answer": "Proper names", "question": "What is another important and anciently studied linguistic category?"}, {"answer_start": 180, "answer": "an entire multiword phrase", "question": "What is a proper name?"}, {"answer_start": 329, "answer": "named entity", "question": "What term is used to describe anything that can be referred to with a proper name?"}]}, {"context": "Parts of speech (also known as POS) and named entities are useful clues to POS sentence structure and meaning. Knowing whether a word is a noun or a verb tells us about likely neighboring words (nouns in English are preceded by determiners and adjectives, verbs by nouns) and syntactic structure (verbs have dependency links to nouns), making part-of-speech tagging a key aspect of parsing. Knowing if a named entity like Washington is a name of a person, a place, or a university is important to many natural language processing tasks like question answering, stance detection, or information extraction. In this chapter we'll introduce the task of part-of-speech tagging, taking a sequence of words and assigning each word a part of speech like NOUN or VERB, and the task of named entity recognition (NER), assigning words or phrases tags like PERSON, LOCATION, or ORGANIZATION.", "questions_and_answers": [{"answer_start": 31, "answer": "POS", "question": "Parts of speech are also known as what?"}, {"answer_start": 169, "answer": "likely neighboring words", "question": "What does knowing whether a word is a noun or a verb tell us about?"}, {"answer_start": 582, "answer": "information extraction", "question": "What is an important part of natural language processing?"}, {"answer_start": 777, "answer": "named entity recognition", "question": "What is NER?"}]}, {"context": "Such tasks in which we assign, to each word x i in an input word sequence, a label y i , so that the output sequence Y has the same length as the input sequence X are called sequence labeling tasks. We'll introduce classic sequence labeling algo-sequence labeling rithms, one generative-the Hidden Markov Model (HMM)-and one discriminativethe Conditional Random Field (CRF). In following chapters we'll introduce modern sequence labelers based on RNNs and Transformers.", "questions_and_answers": [{"answer_start": 174, "answer": "sequence labeling tasks", "question": "What are tasks in which we assign a label y i so that the output sequence Y has the same length as the input sequence X"}, {"answer_start": 343, "answer": "Conditional Random Field", "question": "What is the CRF?"}, {"answer_start": 447, "answer": "RNNs and Transformers", "question": "What are modern sequence labelers based on?"}]}, {"context": "Until now we have been using part-of-speech terms like noun and verb rather freely. In this section we give more complete definitions. While word classes do have semantic tendencies-adjectives, for example, often describe properties and nouns people-parts of speech are defined instead based on their grammatical relationship with neighboring words or the morphological properties about their affixes.", "questions_and_answers": [{"answer_start": 55, "answer": "noun and verb", "question": "What are two examples of part-of-speech terms?"}, {"answer_start": 122, "answer": "definitions", "question": "What do we give in this section?"}, {"answer_start": 301, "answer": "grammatical", "question": "Parts of speech are defined based on what relationship with neighboring words?"}, {"answer_start": 182, "answer": "adjectives", "question": "What class of words often describe properties and nouns people?"}]}, {"context": "Open Class Nouns are words for people, places, or things, but include others as well. Actually, I ran home extremely quickly yesterday", "questions_and_answers": [{"answer_start": 0, "answer": "Open Class Nouns", "question": "What are words for people, places, or things?"}, {"answer_start": 107, "answer": "extremely quickly", "question": "How did I get home yesterday?"}]}, {"context": "Adverbs generally modify something (often verbs, hence the name \"adverb\", but also other adverbs and entire verb phrases). Directional adverbs or locative adlocative verbs (home, here, downhill) specify the direction or location of some action; degree degree adverbs (extremely, very, somewhat) specify the extent of some action, process, or property; manner adverbs (slowly, slinkily, delicately) describe the manner of some manner action or process; and temporal adverbs describe the time that some action or event temporal took place (yesterday, Monday).", "questions_and_answers": [{"answer_start": 0, "answer": "Adverbs", "question": "What generally modify something?"}, {"answer_start": 245, "answer": "degree degree", "question": "What adverbs specify the extent of some action, process, or property?"}]}, {"context": "Interjections (oh, hey, alas, uh, um) , are a smaller open class, that also includes interjection greetings (hello, goodbye), and question responses (yes, no, uh-huh) .", "questions_and_answers": [{"answer_start": 85, "answer": "interjection greetings", "question": "What do interjections include?"}, {"answer_start": 130, "answer": "question responses", "question": "Interjections include what type of responses?"}]}, {"context": "A particle resembles a preposition or an adverb and is used in combination with particle a verb. Particles often have extended meanings that aren't quite the same as the prepositions they resemble, as in the particle over in she turned the paper over. A verb and a particle acting as a single unit is called a phrasal verb. The meaning phrasal verb of phrasal verbs is often non-compositional-not predictable from the individual meanings of the verb and the particle. Thus, turn down means 'reject', rule out 'eliminate', and go on 'continue'. Determiners like this and that (this chapter, that page) can mark the start of an determiner English noun phrase. Articles like a, an, and the, are a type of determiner that mark article discourse properties of the noun and are quite frequent; the is the most common word in written English, with a and an right behind.", "questions_and_answers": [{"answer_start": 80, "answer": "particle a verb", "question": "A particle resembles a preposition or an adverb and is used in combination with what?"}, {"answer_start": 118, "answer": "extended meanings", "question": "Particles often have what meanings that aren't quite the same as the prepositions they resemble?"}, {"answer_start": 310, "answer": "phrasal verb", "question": "A verb and a particle acting as a single unit is called what?"}, {"answer_start": 375, "answer": "non-compositional", "question": "What is the meaning phrasal verb of phrasal verbs?"}, {"answer_start": 533, "answer": "continue", "question": "What does 'go on' mean?"}, {"answer_start": 561, "answer": "this and that", "question": "What determiners mark the start of an English noun phrase?"}, {"answer_start": 658, "answer": "Articles", "question": "What is a type of determiner that mark article discourse properties of the noun?"}]}, {"context": "Conjunctions join two phrases, clauses, or sentences. Coordinating conjuncconjunction tions like and, or, and but join two elements of equal status. Subordinating conjunctions are used when one of the elements has some embedded status. For example, the subordinating conjunction that in \"I thought that you might like some milk\" links the main clause I thought with the subordinate clause you might like some milk. This clause is called subordinate because this entire clause is the \"content\" of the main verb thought. Subordinating conjunctions like that which link a verb to its argument in this way are also called complementizers.", "questions_and_answers": [{"answer_start": 0, "answer": "Conjunctions", "question": "What joins two phrases, clauses, or sentences?"}, {"answer_start": 54, "answer": "Coordinating conjuncconjunction tions", "question": "What joins two elements of equal status?"}, {"answer_start": 185, "answer": "when one of the elements has some embedded status", "question": "When are subordinating conjunctions used?"}, {"answer_start": 288, "answer": "I thought that you might like some milk", "question": "What is the subordinating conjunction that links the main clause I thought with the subordinate clause you might like some milk?"}, {"answer_start": 484, "answer": "content", "question": "What is the main verb thought in a subordinate clause?"}, {"answer_start": 618, "answer": "complementizers", "question": "What are subordinating conjunctions that link a verb to its argument called?"}]}, {"context": "Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text. The input is a sequence x 1 , x 2 , ..., x n of (tokenized) words and a tagset, and the output is a sequence y 1 , y 2 , ..., y n of tags, each output y i corresponding exactly to one input x i , as shown in the intuition in Figure [ 8.3 ] . Tagging is a disambiguation task; words are ambiguous -have more than one ambiguous possible part-of-speech-and the goal is to find the correct tag for the situation. For example, book can be a verb (book that flight) or a noun (hand me that book). That can be a determiner (Does that flight serve dinner) or a complementizer (I We'll introduce algorithms for the task in the next few sections, but first let's explore the task. Exactly how hard is it? Figure [ 8.4 ] shows that most word types (85-86%) are unambiguous (Janet is always NNP, hesitantly is always RB). But the ambiguous words, though accounting for only 14-15% of the vocabulary, are very common, and 55-67% of word tokens in running text are ambiguous. Particularly ambiguous common words include that, back, down, put and set; here are some examples of the 6 different parts of speech for the word back: earnings growth took a back[ /JJ seat a small building in the back/ ]NN a clear majority of senators back[ /VBP the bill Dave began to back/ ]VB toward the door enable the country to buy back[ /RP debt I was twenty-one back/ ]RB then Nonetheless, many words are easy to disambiguate, because their different tags aren't equally likely. For example, a can be a determiner or the letter a, but the determiner sense is much more likely.", "questions_and_answers": [{"answer_start": 41, "answer": "assigning a part-of-speech to each word in a text", "question": "What is part-of-speech tagging?"}, {"answer_start": 334, "answer": "Tagging", "question": "What is a disambiguation task?"}, {"answer_start": 563, "answer": "hand me that book", "question": "What is a noun for a book?"}, {"answer_start": 645, "answer": "complementizer", "question": "What is a part-of-speech tagging?"}, {"answer_start": 763, "answer": "Exactly how hard is it", "question": "How hard is part-of-speech tagging?"}, {"answer_start": 830, "answer": "85-86%", "question": "What percentage of word types are unambiguous?"}, {"answer_start": 1001, "answer": "55-67%", "question": "What percentage of word tokens in running text are ambiguous?"}, {"answer_start": 1098, "answer": "that, back, down, put and set", "question": "What are some ambiguous common words?"}, {"answer_start": 597, "answer": "determiner", "question": "What can a be a part-of-speech tagging?"}]}, {"context": "This idea suggests a useful baseline: given an ambiguous word, choose the tag which is most frequent in the training corpus. This is a key concept:", "questions_and_answers": [{"answer_start": 74, "answer": "tag", "question": "What is the most frequent in the training corpus?"}, {"answer_start": 135, "answer": "key concept", "question": "What is the idea of choosing the tag that is most frequent in the training corpus?"}]}, {"context": "Most Frequent Class Baseline: Always compare a classifier against a baseline at least as good as the most frequent class baseline (assigning each token to the class it occurred in most often in the training set).", "questions_and_answers": [{"answer_start": 101, "answer": "most frequent class baseline", "question": "A classifier should always compare a classifier against a baseline at least as good as what?"}]}, {"context": "The most-frequent-tag baseline has an accuracy of about 92% 1 . The baseline thus differs from the state-of-the-art and human ceiling (97%) by only 5%.", "questions_and_answers": [{"answer_start": 56, "answer": "92%", "question": "What is the accuracy of the most-frequent-tag baseline?"}, {"answer_start": 135, "answer": "97%", "question": "What is the human ceiling?"}]}, {"context": "Part of speech tagging can tell us that words like Janet, Stanford University, and Colorado are all proper nouns; being a proper noun is a grammatical property of these words. But viewed from a semantic perspective, these proper nouns refer to different kinds of entities: Janet is a person, Stanford University is an organization,.. and Colorado is a location.", "questions_and_answers": [{"answer_start": 139, "answer": "grammatical", "question": "What type of property does being a proper noun have?"}, {"answer_start": 282, "answer": "a person", "question": "What is Janet?"}]}, {"context": "Palo Alto is raising the fees for parking. Named entity tagging is a useful first step in lots of natural language processing tasks. In sentiment analysis we might want to know a consumer's sentiment toward a particular entity. Entities are a useful first stage in question answering, or for linking text to information in structured knowledge sources like Wikipedia. And named entity tagging is also central to tasks involving building semantic representations, like extracting events and the relationship between participants.", "questions_and_answers": [{"answer_start": 34, "answer": "parking", "question": "What is Palo Alto raising the fees for?"}, {"answer_start": 43, "answer": "Named entity tagging", "question": "What is a useful first step in lots of natural language processing tasks?"}, {"answer_start": 136, "answer": "sentiment analysis", "question": "What kind of analysis might we want to know a consumer's sentiment toward a particular entity?"}, {"answer_start": 357, "answer": "Wikipedia", "question": "Entities are useful for linking text to information in structured knowledge sources like what?"}, {"answer_start": 372, "answer": "named entity tagging", "question": "What is central to tasks involving building semantic representations?"}]}, {"context": "Unlike part-of-speech tagging, where there is no segmentation problem since each word gets one tag, the task of named entity recognition is to find and label spans of text, and is difficult partly because of the ambiguity of segmentation; we", "questions_and_answers": [{"answer_start": 212, "answer": "ambiguity of segmentation", "question": "Why is the task of named entity recognition difficult?"}, {"answer_start": 140, "answer": "to find and label spans of text", "question": "What is the task of named entity recognition?"}]}, {"context": "In this section we introduce our first sequence labeling algorithm, the Hidden Markov Model, and show how to apply it to part-of-speech tagging. Recall that a sequence labeler is a model whose job is to assign a label to each unit in a sequence, thus mapping a sequence of observations to a sequence of labels of the same length. The HMM is a classic model that introduces many of the key concepts of sequence modeling that we will see again in more modern models.", "questions_and_answers": [{"answer_start": 72, "answer": "Hidden Markov Model", "question": "What is the name of the first sequence labeling algorithm?"}, {"answer_start": 121, "answer": "part-of-speech tagging", "question": "What is the Hidden Markov Model used for?"}, {"answer_start": 203, "answer": "assign a label to each unit in a sequence", "question": "What is the job of a sequence labeler?"}, {"answer_start": 334, "answer": "HMM", "question": "What is a classic model that introduces many of the key concepts of sequence modeling that we will see again in more modern models?"}]}, {"context": "An HMM is a probabilistic sequence model: given a sequence of units (words, letters, morphemes, sentences, whatever), it computes a probability distribution over possible sequences of labels and chooses the best label sequence.", "questions_and_answers": [{"answer_start": 3, "answer": "HMM", "question": "What is a probabilistic sequence model?"}]}, {"context": "Markov assumption when predicting the future, the past doesn't matter, only the present.", "questions_and_answers": [{"answer_start": 0, "answer": "Markov", "question": "What assumption is used when predicting the future?"}]}, {"context": "an initial probability distribution over states. \u03c0 i is the probability that the Markov chain will start in state i. Some states j may have \u03c0 j = 0, meaning that they cannot be initial states. Also, n i=1 \u03c0 i = 1 Before you go on, use the sample probabilities in Figure 8.8a (with \u03c0 = [[ 0.1 ], [ 0.7 ], [ 0.2 ]] ) to compute the probability of each of the following sequences:", "questions_and_answers": [{"answer_start": 3, "answer": "initial probability distribution over states", "question": "What is the probability that the Markov chain will start in state i?"}, {"answer_start": 81, "answer": "Markov chain", "question": "i is the probability that what chain will start in state i?"}, {"answer_start": 162, "answer": "they cannot be initial states", "question": "Some states j may have  j = 0, meaning what?"}, {"answer_start": 263, "answer": "Figure 8.8a", "question": "In what figure are the sample probabilities of each of the following sequences shown?"}]}, {"context": "A Markov chain is useful when we need to compute a probability for a sequence of observable events. In many cases, however, the events we are interested in are hidden: we don't observe them directly. For example we don't normally observe hidden part-of-speech tags in a text. Rather, we see words, and must infer the tags from the word sequence. We call the tags hidden because they are not observed.", "questions_and_answers": [{"answer_start": 2, "answer": "Markov chain", "question": "What is useful when we need to compute a probability for a sequence of observable events?"}, {"answer_start": 160, "answer": "hidden", "question": "In many cases, the events we are interested in are what?"}, {"answer_start": 245, "answer": "part-of-speech tags", "question": "What do we not normally observe hidden in a text?"}, {"answer_start": 291, "answer": "words", "question": "What do we see hidden part-of-speech tags in a text?"}, {"answer_start": 378, "answer": "they are not observed", "question": "Why do we call hidden tags?"}]}, {"context": "A hidden Markov model (HMM) allows us to talk about both observed events hidden Markov model (like words that we see in the input) and hidden events (like part-of-speech tags) that we think of as causal factors in our probabilistic model. An HMM is specified by the following components:", "questions_and_answers": [{"answer_start": 2, "answer": "hidden Markov model", "question": "What does HMM stand for?"}, {"answer_start": 155, "answer": "part-of-speech tags", "question": "What are hidden events in a hidden Markov model?"}, {"answer_start": 2, "answer": "hidden Markov model", "question": "What does HMM stand for?"}, {"answer_start": 276, "answer": "components", "question": "What is an HMM specified by?"}]}, {"context": "a sequence of observation likelihoods, also called emission probabilities, each expressing the probability of an observation o t being generated from a state q i", "questions_and_answers": [{"answer_start": 51, "answer": "emission probabilities", "question": "What are observation likelihoods also called?"}, {"answer_start": 51, "answer": "emission probabilities", "question": "What are observation likelihoods also called?"}]}, {"context": "an initial probability distribution over states. \u03c0 i is the probability that the Markov chain will start in state i. Some states j may have \u03c0 j = 0, meaning that they cannot be initial states. Also, n i=1 \u03c0 i = 1 A first-order hidden Markov model instantiates two simplifying assumptions. First, as with a first-order Markov chain, the probability of a particular state depends only on the previous state:", "questions_and_answers": [{"answer_start": 3, "answer": "initial probability distribution over states", "question": "What is the probability that the Markov chain will start in state i?"}, {"answer_start": 3, "answer": "i", "question": "What is the probability that the Markov chain will start in state i?"}, {"answer_start": 162, "answer": "they cannot be initial states", "question": "Some states j may have  j = 0, meaning what?"}, {"answer_start": 213, "answer": "A first-order hidden Markov model", "question": "What instantiates two simplifying assumptions?"}, {"answer_start": 386, "answer": "the previous state", "question": "What does the probability of a particular state depend on?"}]}, {"context": "Second, the probability of an output observation o i depends only on the state that produced the observation q i and not on any other states or any other observations:", "questions_and_answers": [{"answer_start": 69, "answer": "the state that produced the observation q i", "question": "The probability of an output observation o i depends only on what?"}, {"answer_start": 8, "answer": "the probability of an output observation o i", "question": "What depends only on the state that produced the observation q i?"}]}, {"context": "Let's start by looking at the pieces of an HMM tagger, and then we'll see how to use it to tag. An HMM has two components, the A and B probabilities.", "questions_and_answers": [{"answer_start": 47, "answer": "tag", "question": "What is an HMM's ger?"}, {"answer_start": 47, "answer": "tag", "question": "What is an HMM's ger?"}, {"answer_start": 127, "answer": "A and B probabilities", "question": "What are the two components of an HMM?"}]}, {"context": "In the WSJ corpus, for example, MD occurs 13124 times of which it is followed by VB 10471, for an MLE estimate of", "questions_and_answers": [{"answer_start": 32, "answer": "MD", "question": "What occurs 13124 times in the WSJ corpus?"}, {"answer_start": 81, "answer": "VB 10471", "question": "MD is followed by what in the WSJ corpus?"}, {"answer_start": 32, "answer": "MD", "question": "What occurs 13124 times in the WSJ corpus?"}, {"answer_start": 42, "answer": "13124", "question": "How many times does MD occur in the WSJ corpus?"}]}, {"context": "Let's walk through an example, seeing how these probabilities are estimated and used in a sample tagging task, before we return to the algorithm for decoding.", "questions_and_answers": [{"answer_start": 97, "answer": "tagging", "question": "What is a sample task that uses probabilities?"}]}, {"context": "In HMM tagging, the probabilities are estimated by counting on a tagged training corpus. For this example we'll use the tagged WSJ corpus.", "questions_and_answers": [{"answer_start": 51, "answer": "counting on a tagged training corpus", "question": "How are the probabilities estimated in HMM tagging?"}, {"answer_start": 127, "answer": "WSJ", "question": "What corpus is used in this example?"}]}, {"context": "The B emission probabilities, P(w i |t i ), represent the probability, given a tag (say MD), that it will be associated with a given word (say will). The MLE of the emission probability is", "questions_and_answers": [{"answer_start": 4, "answer": "B emission probabilities", "question": "What represent the probability, given a tag (say MD), that it will be associated with a given word (say will)?"}, {"answer_start": 88, "answer": "MD", "question": "What is another name for a tag?"}, {"answer_start": 154, "answer": "MLE", "question": "What is the name of the emission probability?"}]}, {"context": "Of the 13124 occurrences of MD in the WSJ corpus, it is associated with will 4046 times:", "questions_and_answers": [{"answer_start": 77, "answer": "4046", "question": "How many times is MD associated with the WSJ corpus?"}, {"answer_start": 7, "answer": "13124", "question": "How many occurrences of MD in the WSJ corpus are associated with will 4046 times?"}]}, {"context": "We saw this kind of Bayesian modeling in Chapter 4; recall that this likelihood term is not asking \"which is the most likely tag for the word will?\" That would be the posterior P(MD|will). Instead, P(will|MD) answers the slightly counterintuitive question \"If we were going to generate a MD, how likely is it that this modal would be will?\"", "questions_and_answers": [{"answer_start": 100, "answer": "which is the most likely tag for the word will?", "question": "What is the posterior P(MD|MD)?"}, {"answer_start": 167, "answer": "posterior", "question": "What is the most likely tag for the word will?"}, {"answer_start": 198, "answer": "P(will|MD)", "question": "What answers the question \"If we were going to generate a MD, how likely is it that this modal would be will?\""}]}, {"context": "The way we'll do this in the HMM is to use Bayes' rule to instead compute:", "questions_and_answers": [{"answer_start": 43, "answer": "Bayes' rule", "question": "What is the way we'll compute in the HMM?"}, {"answer_start": 29, "answer": "HMM", "question": "What is the name of the method we'll use to do this?"}]}, {"context": "HMM taggers make two further simplifying assumptions. The first is that the probability of a word appearing depends only on its own tag and is independent of neighboring words and tags:", "questions_and_answers": [{"answer_start": 29, "answer": "simplifying assumptions", "question": "What do HMM taggers make?"}, {"answer_start": 143, "answer": "independent", "question": "The second assumption is that the probability of a word appearing depends only on its own tag and is what?"}]}, {"context": "The second assumption, the bigram assumption, is that the probability of a tag is dependent only on the previous tag, rather than the entire tag sequence;", "questions_and_answers": [{"answer_start": 23, "answer": "the bigram assumption", "question": "What is the second assumption that the probability of a tag is dependent only on the previous tag?"}, {"answer_start": 54, "answer": "the probability of a tag is dependent only on the previous tag", "question": "What is the bigram assumption?"}, {"answer_start": 130, "answer": "the entire tag sequence", "question": "The bigram assumption is that the probability of a tag is dependent only on the previous tag, rather than what?"}]}, {"context": "The two parts of Eq. [ 8.17 ] correspond neatly to the B emission probability and A transition probability that we just defined above!", "questions_and_answers": [{"answer_start": 4, "answer": "two", "question": "How many parts of Eq. [ 8.17 ] correspond neatly to the B emission probability and A transition probability that we just defined above?"}, {"answer_start": 23, "answer": "8.17", "question": "Which part of Eq. corresponds neatly to the B emission probability and A transition probability?"}]}, {"context": "As an instance of dynamic programming, Viterbi resembles the dynamic programming minimum edit distance algorithm of Chapter 2.", "questions_and_answers": [{"answer_start": 18, "answer": "dynamic programming", "question": "What is Viterbi an example of?"}, {"answer_start": 18, "answer": "dynamic programming", "question": "What is Viterbi an example of?"}]}, {"context": "function VITERBI(observations of len T,state-graph of len N) returns best-path, path-prob create a path probability matrix viterbi [N,T] for each state s from 1 to N do", "questions_and_answers": [{"answer_start": 69, "answer": "best-path", "question": "What does VITERBI return?"}, {"answer_start": 69, "answer": "best-path", "question": "What does VITERBI return?"}]}, {"context": "for each time step t from 2 to T do ; recursion step for each state s from", "questions_and_answers": [{"answer_start": 38, "answer": "recursion", "question": "What is the step for each state s from 2 to T?"}]}, {"context": "bestpath \u2190 the path starting at state bestpathpointer, that follows backpointer[] to states back in time return bestpath, bestpathprob Figure 8 .10 Viterbi algorithm for finding the optimal sequence of tags. Given an observation sequence and an HMM \u03bb = (A, B), the algorithm returns the state path through the HMM that assigns maximum likelihood to the observation sequence.", "questions_and_answers": [{"answer_start": 38, "answer": "bestpathpointer", "question": "What is the path starting at state?"}, {"answer_start": 245, "answer": "HMM", "question": "What is  = (A, B)?"}]}, {"context": "Each cell of the lattice, v t ( j), represents the probability that the HMM is in state j after seeing the first t observations and passing through the most probable state sequence q 1 , ..., q t\u22121 , given the HMM \u03bb . The value of each cell v t ( j) is computed by recursively taking the most probable path that could lead us to this cell. Formally, each cell expresses the probability", "questions_and_answers": [{"answer_start": 26, "answer": "v t", "question": "Which cell represents the probability that the HMM is in state j?"}, {"answer_start": 262, "answer": "by recursively taking the most probable path that could lead us to this cell", "question": "How is the value of each cell of the lattice computed?"}, {"answer_start": 231, "answer": "each cell", "question": "What expresses the probability that the HMM is in state j?"}]}, {"context": "We represent the most probable path by taking the maximum over all possible previous state sequences max", "questions_and_answers": [{"answer_start": 39, "answer": "taking the maximum over all possible previous state sequences", "question": "How do we represent the most probable path?"}]}, {"context": "The three factors that are multiplied in Eq. [ 8.19 ] for extending the previous paths to compute the Viterbi probability at time t are .11 A sketch of the lattice for Janet will back the bill, showing the possible tags (q i ) for each word and highlighting the path corresponding to the correct tag sequence through the hidden states. States (parts of speech) which have a zero probability of generating a particular word according to the B matrix (such as the probability that a determiner DT will be realized as Janet) are greyed out.", "questions_and_answers": [{"answer_start": 4, "answer": "three", "question": "How many factors are multiplied in Eq. [ 8.19 ] for extending the previous paths to compute the Viterbi probability at"}, {"answer_start": 221, "answer": "q i", "question": "What are the possible tags for each word?"}, {"answer_start": 344, "answer": "parts of speech", "question": "What are states?"}]}, {"context": "v t\u22121 (i) the previous Viterbi path probability from the previous time step a i j the transition probability from previous state q i to current state q j b j (o t ) the state observation likelihood of the observation symbol o t given the current state j", "questions_and_answers": [{"answer_start": 165, "answer": "the state observation likelihood of the observation symbol", "question": "What is o t given the current state j?"}, {"answer_start": 165, "answer": "the state observation likelihood of the observation symbol", "question": "What is o t given the current state j?"}]}, {"context": "While the HMM is a useful and powerful model, it turns out that HMMs need a number of augmentations to achieve high accuracy. For example, in POS tagging as in other tasks, we often run into unknown words: proper names and acronyms unknown words are created very often, and even new common nouns and verbs enter the language at a surprising rate. It would be great to have ways to add arbitrary features to help with this, perhaps based on capitalization or morphology (words starting with capital letters are likely to be proper nouns, words ending with -ed tend to be past tense (VBD or VBN), etc.) Or knowing the previous or following words might be a useful feature (if the previous word is the, the current tag is unlikely to be a verb). Although we could try to hack the HMM to find ways to incorporate some of these, in general it's hard for generative models like HMMs to add arbitrary features directly into the model in a clean way. We've already seen a model for combining arbitrary features in a principled way: log-linear models like the logistic regression model of Chapter 5! But logistic regression isn't a sequence model; it assigns a class to a single observation.", "questions_and_answers": [{"answer_start": 86, "answer": "augmentations", "question": "What do HMMs need to achieve high accuracy?"}, {"answer_start": 191, "answer": "unknown words", "question": "What do we often run into in POS tagging?"}, {"answer_start": 570, "answer": "past tense", "question": "Words ending with -ed tend to be what?"}, {"answer_start": 604, "answer": "knowing the previous or following words", "question": "What might be a useful feature for POS tagging?"}, {"answer_start": 385, "answer": "arbitrary features", "question": "What is difficult for generative models like HMMs to add directly into the model in a clean way?"}, {"answer_start": 1024, "answer": "log-linear models", "question": "What model does the logistic regression model of Chapter 5 combine arbitrary features in a principled way?"}, {"answer_start": 1142, "answer": "assigns a class to a single observation", "question": "What does logistic regression do?"}]}, {"context": "Luckily, there is a discriminative sequence model based on log-linear models: the conditional random field (CRF). We'll describe here the linear chain CRF, CRF the version of the CRF most commonly used for language processing, and the one whose conditioning closely matches the HMM.", "questions_and_answers": [{"answer_start": 82, "answer": "conditional random field", "question": "What is the CRF?"}, {"answer_start": 206, "answer": "language processing", "question": "What is the CRF most commonly used for?"}]}, {"context": "Assuming we have a sequence of input words X = x 1 ...x n and want to compute a sequence of output tags Y = y 1 ...y n . In an HMM to compute the best tag sequence that maximizes P(Y |X) we rely on Bayes' rule and the likelihood P(X|Y ):", "questions_and_answers": [{"answer_start": 104, "answer": "Y", "question": "What is the name of the sequence of output tags?"}, {"answer_start": 104, "answer": "Y", "question": "What is the name of the sequence of output tags?"}, {"answer_start": 198, "answer": "Bayes' rule", "question": "In an HMM to compute the best tag sequence that maximizes P(Y |X) we rely on what rule?"}]}, {"context": "In a CRF, by contrast, we compute the posterior p(Y |X) directly, training the CRF to discriminate among the possible tag sequences:", "questions_and_answers": [{"answer_start": 5, "answer": "CRF", "question": "What is used to compute the posterior p(Y |X) directly?"}]}, {"context": "However, the CRF does not compute a probability for each tag at each time step. Instead, at each time step the CRF computes log-linear functions over a set of relevant features, and these local features are aggregated and normalized to produce a global probability for the whole sequence. Let's introduce the CRF more formally, again using X and Y as the input and output sequences. A CRF is a log-linear model that assigns a probability to an entire output (tag) sequence Y , out of all possible sequences Y, given the entire input (word) sequence X. We can think of a CRF as like a giant version of what multinomial logistic regression does for a single token. Recall that the feature function f in regular multinomial logistic regression can be viewed as a function of a tuple: a token x and a label y (page 92). In a CRF, the function F maps an entire input sequence X and an entire output sequence Y to a feature vector. Let's assume we have K features, with a weight w k for each feature F k :", "questions_and_answers": [{"answer_start": 13, "answer": "CRF", "question": "What does not compute a probability for each tag at each time step?"}, {"answer_start": 115, "answer": "computes log-linear functions over a set of relevant features", "question": "What does the CRF do at each time step?"}, {"answer_start": 340, "answer": "X and Y", "question": "What are the input and output sequences of the CRF?"}, {"answer_start": 124, "answer": "log-linear", "question": "What type of model is a CRF?"}, {"answer_start": 606, "answer": "multinomial logistic regression", "question": "What does a CRF do for a single token?"}, {"answer_start": 772, "answer": "a tuple", "question": "The feature function f in regular multinomial logistic regression can be viewed as a function of what?"}, {"answer_start": 15, "answer": "F", "question": "What function maps an entire input sequence X and an entire output sequence Y to a feature vector?"}, {"answer_start": 947, "answer": "K features", "question": "What does the CRF assume we have?"}]}, {"context": "It's common to also describe the same equation by pulling out the denominator into a function Z(X):", "questions_and_answers": [{"answer_start": 50, "answer": "pulling out the denominator into a function Z(X)", "question": "How is it common to describe the same equation?"}]}, {"context": "We'll call these K functions F k (X,Y ) global features, since each one is a property of the entire input sequence X and output sequence Y . We compute them by decomposing into a sum of local features for each position i in Y :", "questions_and_answers": [{"answer_start": 40, "answer": "global features", "question": "What are the K functions F k (X,Y) called?"}, {"answer_start": 157, "answer": "by decomposing", "question": "How do we compute global features?"}]}, {"context": "Each of these local features f k in a linear-chain CRF is allowed to make use of the current output token y i , the previous output token y i\u22121 , the entire input string X (or any subpart of it), and the current position i. This constraint to only depend on the current and previous output tokens y i and y i\u22121 are what characterizes a linear chain CRF. As we will see, this limitation makes it possible to use versions of the linear chain CRF efficient Viterbi and Forward-Backwards algorithms from the HMM. A general CRF, by contrast, allows a feature to make use of any output token, and are thus necessary for tasks in which the decision depend on distant output tokens, like y i\u22124 . General CRFs require more complex inference, and are less commonly used for language processing.", "questions_and_answers": [{"answer_start": 204, "answer": "current position i", "question": "What is a local feature allowed to make use of in a linear chain CRF?"}, {"answer_start": 262, "answer": "current and previous output tokens", "question": "What do y i and y i1 depend on?"}, {"answer_start": 454, "answer": "Viterbi and Forward-Backwards algorithms", "question": "Which versions of the linear chain CRF can be used from the HMM?"}, {"answer_start": 569, "answer": "any output token", "question": "A general CRF allows a feature to make use of what?"}, {"answer_start": 764, "answer": "language processing", "question": "General CRFs are less commonly used for what?"}]}, {"context": "For simplicity, we'll assume all CRF features take on the value 1 or 0. Above, we explicitly use the notation 1{x} to mean \"1 if x is true, and 0 otherwise\". From now on, we'll leave off the 1 when we define features, but you can assume each feature has it there implicitly.", "questions_and_answers": [{"answer_start": 64, "answer": "1 or 0.", "question": "For simplicity, we assume all CRF features take on what value?"}, {"answer_start": 64, "answer": "1", "question": "What is the notation used to mean \"1 if x is true, and 0 otherwise?\""}, {"answer_start": 193, "answer": "when we define features", "question": "When will we leave off the 1?"}]}, {"context": "Although the idea of what features to use is done by the system designer by hand, the specific features are automatically populated by using feature templates as we feature templates briefly mentioned in Chapter 5. Here are some templates that only use information from y i\u22121 , y i , X, i):", "questions_and_answers": [{"answer_start": 141, "answer": "feature templates", "question": "What are the specific features automatically populated by?"}, {"answer_start": 284, "answer": "X", "question": "What is another name for i?"}]}, {"context": "These templates automatically populate the set of features from every instance in the training and test set. Thus for our example Janet[ /NNP will/ ]MD back[ /VB the/ ]DT bill/NN, when x i is the word back, the following features would be generated and have the value 1 (we've assigned them arbitrary feature numbers):", "questions_and_answers": [{"answer_start": 6, "answer": "templates", "question": "What automatically populate the set of features from every instance in the training and test set?"}, {"answer_start": 185, "answer": "x i", "question": "What is the word back?"}]}, {"context": "f 3743 : y i = VB and x i = back f 156 : y i = VB and y i\u22121 = MD f 99732 : y i = VB and x i\u22121 = will and x i+2 = bill It's also important to have features that help with unknown words. One of the most important is word shape features, which represent the abstract letter pattern word shape of the word by mapping lower-case letters to 'x', upper-case to 'X', numbers to 'd', and retaining punctuation. Thus for example I.M.F would map to X.X.X. and DC10-30 would map to XXdd-dd. A second class of shorter word shape features is also used. In these features consecutive character types are removed, so words in all caps map to X, words with initial-caps map to Xx, DC10-30 would be mapped to Xd-d but I.M.F would still map to X.X.X. Prefix and suffix features are also useful. In summary, here are some sample feature templates that help with unknown words:", "questions_and_answers": [{"answer_start": 170, "answer": "unknown words", "question": "What is it important to have features that help with?"}, {"answer_start": 214, "answer": "word shape features", "question": "What feature represents the abstract letter pattern word shape of a word?"}, {"answer_start": 438, "answer": "X.X.X.", "question": "What would I.M.F map to?"}, {"answer_start": 470, "answer": "XXdd-dd", "question": "What would DC10-30 map to?"}, {"answer_start": 479, "answer": "A second class of shorter word shape features", "question": "What is also used to help with unknown words?"}, {"answer_start": 557, "answer": "consecutive character types", "question": "What are removed in shorter word shape features?"}, {"answer_start": 732, "answer": "Prefix and suffix", "question": "What features are also useful?"}, {"answer_start": 170, "answer": "unknown words", "question": "What do some sample feature templates help with?"}]}, {"context": "x i contains a particular prefix (perhaps from all prefixes of length \u2264 2) x i contains a particular suffix (perhaps from all suffixes of length \u2264 2) x i 's word shape x i 's short word shape For example the word well-dressed might generate the following non-zero valued feature values:", "questions_and_answers": [{"answer_start": 0, "answer": "x i", "question": "What contains a particular prefix?"}, {"answer_start": 0, "answer": "x i", "question": "What contains a particular prefix?"}]}, {"context": "The known-word templates are computed for every word seen in the training set; the unknown word features can also be computed for all words in training, or only on training words whose frequency is below some threshold. The result of the known-word templates and word-signature features is a very large set of features. Generally a feature cutoff is used in which features are thrown out if they have count < 5 in the training set.", "questions_and_answers": [{"answer_start": 4, "answer": "known-word templates", "question": "What are computed for every word seen in the training set?"}, {"answer_start": 292, "answer": "very large set of features", "question": "What is the result of the known-word templates and word-signature features?"}, {"answer_start": 332, "answer": "feature cutoff", "question": "What is used when features are thrown out if they have count  5 in the training set?"}]}, {"context": "Remember that in a CRF we don't learn weights for each of these local features f k . Instead, we first sum the values of each local feature (for example feature f 3743 ) over the entire sentence, to create each global feature (for example F 3743 ). It is those global features that will then be multiplied by weight w 3743 . Thus for training and inference there is always a fixed set of K features with K weights, even though the length of each sentence is different.", "questions_and_answers": [{"answer_start": 19, "answer": "CRF", "question": "In what type of training do we not learn weights for each of the local features f k?"}, {"answer_start": 211, "answer": "global feature", "question": "What is created when we sum the values of each local feature over the entire sentence?"}, {"answer_start": 295, "answer": "multiplied by weight w 3743", "question": "What are the global features that are created in a CRF?"}, {"answer_start": 388, "answer": "K", "question": "For training and inference there is always a fixed set of what features with K weights?"}]}, {"context": "A CRF for NER makes use of very similar features to a POS tagger, as shown in Figure 8 .15. identity of w i , identity of neighboring words embeddings for w i , embeddings for neighboring words part of speech of w i , part of speech of neighboring words presence of w i in a gazetteer w i contains a particular prefix (from all prefixes of length \u2264 4) w i contains a particular suffix (from all suffixes of length \u2264 4) word shape of w i , word shape of neighboring words short word shape of w i , short word shape of neighboring words gazetteer features Figure 8 .15 Typical features for a feature-based NER system. One feature that is especially useful for locations is a gazetteer, a list of place gazetteer names, often providing millions of entries for locations with detailed geographical and political information. 3 This can be implemented as a binary feature indicating a phrase appears in the list. Other related resources like name-lists, for example from the United States Census Bureau 4 , can be used, as can other entity dictionaries like lists of corporations or products, although they may not be as helpful as a gazetteer (Mikheev et al., 1999) .", "questions_and_answers": [{"answer_start": 590, "answer": "feature-based", "question": "What type of NER system has typical features?"}, {"answer_start": 684, "answer": "a list of place gazetteer names", "question": "What is a gazetteer?"}, {"answer_start": 850, "answer": "a binary feature", "question": "What can a gazetteer be implemented as?"}, {"answer_start": 937, "answer": "name-lists", "question": "What is a related resource to a gazetteer?"}]}, {"context": "The sample named entity token L'Occitane would generate the following nonzero valued feature values (assuming that L'Occitane is neither in the gazetteer nor the census).", "questions_and_answers": [{"answer_start": 30, "answer": "L'Occitane", "question": "What is the name of the sample named entity token?"}]}, {"context": "suffix(x i ) = e word-shape(x i ) = X'Xxxxxxxx short-word-shape(x i ) = X'Xx Figure 8 .16 illustrates the result of adding part-of-speech tags and some shape information to our earlier example.", "questions_and_answers": [{"answer_start": 36, "answer": "X'Xxxxxxxx", "question": "What is the short-word-shape(x i ) =?"}]}, {"context": "How do we find the best tag sequence\u0176 for a given input X? We start with Eq. [ 8.22 ]:", "questions_and_answers": [{"answer_start": 24, "answer": "tag sequence", "question": "How do we find the best  for a given input X?"}, {"answer_start": 73, "answer": "Eq.", "question": "What is the starting point for finding the best tag sequence for a given input X?"}, {"answer_start": 79, "answer": "8.22", "question": "What is the tag sequence for a given input X?"}]}, {"context": "We can ignore the exp function and the denominator Z(X), as we do above, because exp doesn't change the argmax, and the denominator Z(X) is constant for a given observation sequence X. How should we decode to find this optimal tag sequence\u0177? Just as with HMMs, we'll turn to the Viterbi algorithm, which works because, like the HMM, the linearchain CRF depends at each timestep on only one previous output token y i\u22121 .", "questions_and_answers": [{"answer_start": 81, "answer": "exp doesn't change the argmax", "question": "Why can't we ignore the exp function and the denominator Z(X)?"}, {"answer_start": 219, "answer": "optimal tag sequence", "question": "What is the denominator Z(X) constant for a given observation sequence X?"}, {"answer_start": 255, "answer": "HMMs", "question": "What is the Viterbi algorithm similar to?"}]}, {"context": "The CRF requires only a slight change to this latter formula, replacing the a and b prior and likelihood probabilities with the CRF features:", "questions_and_answers": [{"answer_start": 128, "answer": "CRF features", "question": "What does the CRF replace the a and b prior and likelihood probabilities with?"}, {"answer_start": 76, "answer": "a and b prior and likelihood probabilities", "question": "The CRF replaces what with CRF features?"}]}, {"context": "Learning in CRFs relies on the same supervised learning algorithms we presented for logistic regression. Given a sequence of observations, feature functions, and corresponding outputs, we use stochastic gradient descent to train the weights to maximize the log-likelihood of the training corpus. The local nature of linear-chain CRFs means that a CRF version of the forward-backward algorithm (see Appendix A) can be used to efficiently compute the necessary derivatives. As with logistic regression, L1 or L2 regularization is important.", "questions_and_answers": [{"answer_start": 36, "answer": "supervised learning algorithms", "question": "Learning in CRFs relies on what we presented for logistic regression?"}, {"answer_start": 192, "answer": "stochastic gradient descent", "question": "What is used to train the weights in CRFs?"}, {"answer_start": 345, "answer": "a CRF version of the forward-backward algorithm", "question": "What can be used to efficiently compute the necessary derivatives?"}, {"answer_start": 501, "answer": "L1 or L2 regularization", "question": "What is important in linear-chain CRFs?"}]}, {"context": "Part-of-speech taggers are evaluated by the standard metric of accuracy. Named entity recognizers are evaluated by recall, precision, and F 1 measure. Recall that recall is the ratio of the number of correctly labeled responses to the total that should have been labeled; precision is the ratio of the number of correctly labeled responses to the total labeled; and F-measure is the harmonic mean of the two.", "questions_and_answers": [{"answer_start": 44, "answer": "standard metric of accuracy", "question": "What are part-of-speech taggers evaluated by?"}, {"answer_start": 115, "answer": "recall, precision, and F 1 measure", "question": "Named entity recognizers are evaluated by what?"}, {"answer_start": 173, "answer": "the ratio of the number of correctly labeled responses to the total that should have been labeled", "question": "What is recall?"}, {"answer_start": 123, "answer": "precision", "question": "What is the ratio of the number of correctly labeled responses to the total labeled?"}]}, {"context": "To know if the difference between the F 1 scores of two NER systems is a significant difference, we use the paired bootstrap test, or the similar randomization test (Section [ 4.9 ]).", "questions_and_answers": [{"answer_start": 108, "answer": "paired bootstrap test", "question": "What test is used to determine if the difference between scores of two NER systems is significant?"}, {"answer_start": 146, "answer": "randomization test", "question": "What is another name for the paired bootstrap test?"}]}, {"context": "For named entity tagging, the entity rather than the word is the unit of response. Thus in the example in Figure [ 8.16 ] , the two entities Jane Villanueva and United Airlines Holding and the non-entity discussed would each count as a single response.", "questions_and_answers": [{"answer_start": 26, "answer": "the entity", "question": "What is the unit of response for named entity tagging?"}, {"answer_start": 141, "answer": "Jane Villanueva and United Airlines Holding", "question": "What two entities would each count as a single response?"}]}, {"context": "The fact that named entity tagging has a segmentation component which is not present in tasks like text categorization or part-of-speech tagging causes some problems with evaluation. For example, a system that labeled Jane but not Jane Villanueva as a person would cause two errors, a false positive for O and a false negative for I-PER. In addition, using entities as the unit of response but words as the unit of training means that there is a mismatch between the training and test conditions.", "questions_and_answers": [{"answer_start": 41, "answer": "segmentation component", "question": "What component does named entity tagging not have?"}, {"answer_start": 271, "answer": "two errors", "question": "A system that labeled Jane but not Jane Villanueva as a person would cause how many errors?"}, {"answer_start": 444, "answer": "a mismatch", "question": "What is the result of using words as the unit of training?"}]}, {"context": "In this section we summarize a few remaining details of the data and models, beginning with data. Since the algorithms we have presented are supervised, hav-", "questions_and_answers": [{"answer_start": 60, "answer": "data", "question": "In this section we summarize a few remaining details of what?"}, {"answer_start": 141, "answer": "supervised", "question": "What type of algorithms are presented in this section?"}]}, {"context": "ing labeled data is essential for training and test. A wide variety of datasets exist for part-of-speech tagging and/or NER. The Universal Dependencies (UD) dataset (Nivre et al., 2016b) has POS tagged corpora in 92 languages at the time of this writing, as do the Penn Treebanks in English, Chinese, and Arabic. OntoNotes has corpora labeled for named entities in English, Chinese, and Arabic (Hovy et al., 2006) . Named entity tagged corpora also available in particular domains, such as for biomedical (Bada et al., 2012) and literary text (Bamman et al., 2019).", "questions_and_answers": [{"answer_start": 34, "answer": "training and test", "question": "Labeled data is essential for what?"}, {"answer_start": 90, "answer": "part-of-speech tagging and/or NER", "question": "A wide variety of datasets exist for what?"}, {"answer_start": 213, "answer": "92", "question": "How many languages does the Universal Dependencies dataset have POS tagged corpora in?"}, {"answer_start": 313, "answer": "OntoNotes", "question": "Who has corpora labeled for named entities in English, Chinese, and Arabic?"}, {"answer_start": 494, "answer": "biomedical", "question": "Named entity tagged corpora are available in what domain?"}]}, {"context": "One problem with the CRF and HMM architectures as presented is that the models are exclusively run left-to-right. While the Viterbi algorithm still allows present decisions to be influenced indirectly by future decisions, it would help even more if a decision about word w i could directly use information about future tags t i+1 and t i+2 .", "questions_and_answers": [{"answer_start": 99, "answer": "left-to-right", "question": "What direction are CRF and HMM models run?"}, {"answer_start": 124, "answer": "Viterbi algorithm", "question": "What algorithm allows present decisions to be influenced indirectly by future decisions?"}]}, {"context": "Alternatively, any sequence model can be turned into a bidirectional model by using multiple passes. For example, the first pass would use only part-of-speech features from already-disambiguated words on the left. In the second pass, tags for all words, including those on the right, can be used. Alternately, the tagger can be run twice, once left-to-right and once right-to-left. In Viterbi decoding, the labeler would chooses the higher scoring of the two sequences (left-to-right or right-to-left). Bidirectional models are quite standard for neural models, as we will see with the biLSTM models to be introduced in Chapter 9.", "questions_and_answers": [{"answer_start": 55, "answer": "bidirectional model", "question": "What can any sequence model be turned into?"}, {"answer_start": 144, "answer": "part-of-speech features", "question": "What would the first pass use from already-disambiguated words on the left?"}, {"answer_start": 234, "answer": "tags for all words, including those on the right", "question": "What can be used in the second pass to turn a sequence model into a bidirectional model?"}, {"answer_start": 339, "answer": "once left-to-right and once right-to-left", "question": "How many times can a tagger be run?"}, {"answer_start": 407, "answer": "labeler", "question": "In Viterbi decoding, who chooses the higher scoring of the two sequences?"}, {"answer_start": 503, "answer": "Bidirectional models", "question": "What are quite standard for neural models?"}]}, {"context": "While machine learned (neural or CRF) sequence models are the norm in academic research, commercial approaches to NER are often based on pragmatic combinations of lists and rules, with some smaller amount of supervised machine learning (Chiticariu et al., 2013) . For example in the IBM System T architecture, a user specifies declarative constraints for tagging tasks in a formal query language that includes regular expressions, dictionaries, semantic constraints, and other operators, which the system compiles into an efficient extractor (Chiticariu et al., 2018) .", "questions_and_answers": [{"answer_start": 6, "answer": "machine learned", "question": "What type of sequence models are the norm in academic research?"}, {"answer_start": 310, "answer": "a user", "question": "Who specifies declarative constraints for tagging tasks in the IBM System T architecture?"}]}, {"context": "One common approach is to make repeated rule-based passes over a text, starting with rules with very high precision but low recall, and, in subsequent stages, using machine learning methods that take the output of the first pass into account (an approach first worked out for coreference (Lee et al., 2017a)):", "questions_and_answers": [{"answer_start": 165, "answer": "machine learning methods", "question": "What method takes the output of the first pass into account?"}]}, {"context": "Rule-based methods were also the earliest methods for part-of-speech tagging. Rule-based taggers like the English Constraint Grammar system (Karlsson et al. 1995 , Voutilainen 1999 ) use a two-stage formalism invented in the 1950s and 1960s:", "questions_and_answers": [{"answer_start": 0, "answer": "Rule-based", "question": "What were the earliest methods for part-of-speech tagging?"}, {"answer_start": 106, "answer": "English Constraint Grammar system", "question": "What is an example of a rule-based tagger?"}, {"answer_start": 225, "answer": "1950s and 1960s", "question": "When was the English Constraint Grammar system invented?"}]}, {"context": "(1) a morphological analyzer with tens of thousands of word stem entries returns all parts of speech for a word, then (2) a large set of thousands of constraints are applied to the input sentence to rule out parts of speech inconsistent with the context.", "questions_and_answers": [{"answer_start": 122, "answer": "a large set of thousands", "question": "How many constraints are applied to the input sentence to rule out parts of speech inconsistent with context?"}, {"answer_start": 4, "answer": "a morphological analyzer", "question": "What returns all parts of speech for a word?"}]}, {"context": "Augmentations to tagging algorithms become necessary when dealing with languages with rich morphology like Czech, Hungarian and Turkish.", "questions_and_answers": [{"answer_start": 0, "answer": "Augmentations", "question": "What is needed when dealing with languages with rich morphology like Czech, Hungarian and Turkish?"}]}, {"context": "Using a morphological parse sequence like Noun+A3sg+Pnon+Gen as the partof-speech tag greatly increases the number of parts of speech, and so tagsets can be 4 to 10 times larger than the 50-100 tags we have seen for English. With such large tagsets, each word needs to be morphologically analyzed to generate the list of possible morphological tag sequences (part-of-speech tags) for the word. The role of the tagger is then to disambiguate among these tags. This method also helps with unknown words since morphological parsers can accept unknown stems and still segment the affixes properly.", "questions_and_answers": [{"answer_start": 157, "answer": "4 to 10 times larger", "question": "How large can tagsets be?"}, {"answer_start": 272, "answer": "morphologically analyzed", "question": "What is needed to generate the list of possible morphological tag sequences?"}, {"answer_start": 428, "answer": "disambiguate among these tags", "question": "What is the role of the tagger?"}, {"answer_start": 540, "answer": "unknown stems", "question": "What can morphological parsers accept?"}]}, {"context": "This chapter introduced parts of speech and named entities, and the tasks of partof-speech tagging and named entity recognition:", "questions_and_answers": [{"answer_start": 77, "answer": "partof-speech tagging", "question": "What is one of the tasks introduced in this chapter?"}]}, {"context": "[ \u2022 ] Languages generally have a small set of closed class words that are highly frequent, ambiguous, and act as function words, and open-class words like nouns, verbs, adjectives. Various part-of-speech tagsets exist, of between 40 and 200 tags. [ \u2022 ] Part-of-speech tagging is the process of assigning a part-of-speech label to each of a sequence of words. [ \u2022 ] Named entities are words for proper nouns referring mainly to people, places, and organizations, but extended to many other types that aren't strictly entities or even proper nouns.", "questions_and_answers": [{"answer_start": 113, "answer": "function words", "question": "Closed class words act as what?"}, {"answer_start": 222, "answer": "between 40 and 200", "question": "How many part-of-speech tagsets exist?"}, {"answer_start": 294, "answer": "assigning a part-of-speech label to each of a sequence of words", "question": "What is part-of-speech tagging?"}, {"answer_start": 365, "answer": "Named entities", "question": "What are words for proper nouns referring mainly to people, places, and organizations?"}]}, {"context": "[ \u2022 ] Two common approaches to sequence modeling are a generative approach, HMM tagging, and a discriminative approach, CRF tagging. We will see a neural approach in following chapters. [ \u2022 ] The probabilities in HMM taggers are estimated by maximum likelihood estimation on tag-labeled training corpora. The Viterbi algorithm is used for decoding, finding the most likely tag sequence [ \u2022 ] Conditional Random Fields or CRF taggers train a log-linear model that can choose the best tag sequence given an observation sequence, based on features that condition on the output tag, the prior output tag, the entire input sequence, and the current timestep. They use the Viterbi algorithm for inference, to choose the best sequence of tags, and a version of the Forward-Backward algorithm (see Appendix A) for training.", "questions_and_answers": [{"answer_start": 55, "answer": "generative approach", "question": "What is HMM tagging?"}, {"answer_start": 147, "answer": "neural", "question": "What type of approach will we see in the following chapters?"}, {"answer_start": 242, "answer": "maximum likelihood estimation on tag-labeled training corpora", "question": "How are the probabilities in HMM taggers estimated?"}, {"answer_start": 305, "answer": "The Viterbi algorithm", "question": "What is used for decoding, finding the most likely tag sequence?"}, {"answer_start": 689, "answer": "inference", "question": "What is the Viterbi algorithm used for?"}]}, {"context": "What is probably the earliest part-of-speech tagger was part of the parser in Zellig Harris's Transformations and Discourse Analysis Project (TDAP), implemented between June 1958 and July 1959 at the University of Pennsylvania (Harris, 1962), although earlier systems had used part-of-speech dictionaries. TDAP used 14 handwritten rules for part-of-speech disambiguation; the use of part-of-speech tag sequences and the relative frequency of tags for a word prefigures modern algorithms. The parser was implemented essentially as a cascade of finite-state transducers; see Joshi and Hopely (1999) and Karttunen (1999) for a reimplementation. The Computational Grammar Coder (CGC) of Klein and Simmons (1963) had three components: a lexicon, a morphological analyzer, and a context disambiguator. The small 1500-word lexicon listed only function words and other irregular words. The morphological analyzer used inflectional and derivational suffixes to assign part-of-speech classes. These were run over words to produce candidate parts of speech which were then disambiguated by a set of 500 context rules by relying on surrounding islands of unambiguous words. For example, one rule said that between an ARTICLE and a VERB, the only allowable sequences were ADJ-NOUN, NOUN-ADVERB, or NOUN-NOUN. The TAGGIT tagger (Greene and Rubin, 1971) used the same architecture as Klein and Simmons (1963) , with a bigger dictionary and more tags (87). TAGGIT was applied to the Brown corpus and, according to Francis and Ku\u010dera (1982, p. 9) , accurately tagged 77% of the corpus; the remainder of the Brown corpus was then tagged by hand. All these early algorithms were based on a two-stage architecture in which a dictionary was first used to assign each word a set of potential parts of speech, and then lists of handwritten disambiguation rules winnowed the set down to a single part of speech per word.", "questions_and_answers": [{"answer_start": 200, "answer": "University of Pennsylvania", "question": "Where was TDAP implemented?"}, {"answer_start": 316, "answer": "14", "question": "How many handwritten rules did TDAP use for part-of-speech disambiguation?"}, {"answer_start": 591, "answer": "1999", "question": "When was Joshi and Hopely published?"}, {"answer_start": 732, "answer": "lexicon, a morphological analyzer, and a context disambiguator", "question": "What were the three components of the CGC?"}, {"answer_start": 836, "answer": "function words and other irregular words", "question": "What did the small 1500-word lexicon list?"}, {"answer_start": 910, "answer": "inflectional and derivational suffixes", "question": "What did the morphological analyzer use to assign part-of-speech classes?"}, {"answer_start": 807, "answer": "500", "question": "How many context rules were used to disambiguate part-of-speech classes?"}, {"answer_start": 1259, "answer": "ADJ-NOUN, NOUN-ADVERB, or NOUN-NOUN", "question": "What were the only allowable sequences between an ARTICLE and a VERB?"}, {"answer_start": 1300, "answer": "TAGGIT", "question": "What tagger used the same architecture as Klein and Simmons (1963)?"}, {"answer_start": 1550, "answer": "77%", "question": "What percentage of the Brown corpus was accurately tagged by TAGGIT?"}, {"answer_start": 1703, "answer": "a dictionary", "question": "What was first used to assign each word a set of potential parts of speech?"}]}, {"context": "Probabilities were used in tagging by Stolz et al. (1965) and a complete probabilistic tagger with Viterbi decoding was sketched by Bahl and Mercer (1976) . The Lancaster-Oslo/Bergen (LOB) corpus, a British English equivalent of the Brown corpus, was tagged in the early 1980's with the CLAWS tagger (Marshall 1983; Marshall 1987; Garside 1987) , a probabilistic algorithm that approximated a simplified HMM tagger. The algorithm used tag bigram probabilities, but instead of storing the word likelihood of each tag, the algorithm marked tags either as rare (P(tag|word) < .01) infrequent (P(tag|word) < .10) or normally frequent (P(tag|word) > .10).", "questions_and_answers": [{"answer_start": 0, "answer": "Probabilities", "question": "What was used in tagging by Stolz et al. (1965)?"}, {"answer_start": 132, "answer": "Bahl and Mercer", "question": "Who sketched a complete probabilistic tagger with Viterbi decoding?"}, {"answer_start": 287, "answer": "CLAWS", "question": "What tagger was used to tag the Lancaster-Oslo/Bergen corpus?"}, {"answer_start": 439, "answer": "bigram probabilities", "question": "What did the CLAWS tagger use instead of storing the word likelihood of each tag?"}]}, {"context": "DeRose (1988) developed a quasi-HMM algorithm, including the use of dynamic programming, although computing P(t|w)P(w) instead of P(w|t)P(w). The same year, the probabilistic PARTS tagger of Church 1988 Church , 1989 was probably the first implemented HMM tagger, described correctly in Church (1989), although Church (1988) also described the computation incorrectly as P(t|w)P(w) instead of P(w|t)P(w). Church (p.c.) explained that he had simplified for pedagogical purposes because using the probability P(t|w) made the idea seem more understandable as \"storing a lexicon in an almost standard form\".", "questions_and_answers": [{"answer_start": 8, "answer": "1988", "question": "When did DeRose develop a quasi-HMM algorithm?"}, {"answer_start": 212, "answer": "1989", "question": "What year was probably the first implemented HMM tagger?"}, {"answer_start": 405, "answer": "Church (p.c.)", "question": "Who explained that he simplified the HMM algorithm for pedagogical purposes?"}, {"answer_start": 456, "answer": "pedagogical purposes", "question": "Why did Church simplify the algorithm?"}]}, {"context": "Later taggers explicitly introduced the use of the hidden Markov model (Kupiec 1992; Weischedel et al. 1993; Sch\u00fctze and Singer 1994) . Merialdo (1994) showed that fully unsupervised EM didn't work well for the tagging task and that reliance on hand-labeled data was important. Charniak et al. (1993) showed the importance of the most frequent tag baseline; the [ 92.3 ]% number we give above was from Abney et al. (1999) . See Brants (2000) for HMM tagger implementation details, including the extension to trigram contexts, and the use of sophisticated unknown word features; its performance is still close to state of the art taggers.", "questions_and_answers": [{"answer_start": 51, "answer": "hidden Markov model", "question": "Later taggers explicitly introduced the use of what model?"}, {"answer_start": 128, "answer": "1994", "question": "When did Sch\u00fctze and Singer introduce the hidden Markov model?"}, {"answer_start": 128, "answer": "1994", "question": "When was Merialdo published?"}, {"answer_start": 278, "answer": "Charniak et al.", "question": "Who showed the importance of the most frequent tag baseline?"}, {"answer_start": 103, "answer": "1993", "question": "When did Charniak et al. show the importance of the most frequent tag baseline?"}, {"answer_start": 416, "answer": "1999", "question": "In what year did Abney et al. show the importance of the most frequent tag baseline?"}, {"answer_start": 428, "answer": "Brants", "question": "Who wrote about HMM tagger implementation?"}]}, {"context": "The idea of using letter suffixes for unknown words is quite old; the early Klein and Simmons (1963) system checked all final letter suffixes of lengths 1-5. The unknown word features described on page 169 come mainly from Ratnaparkhi (1996) , with augmentations from Toutanova et al. (2003) and Manning (2011).", "questions_and_answers": [{"answer_start": 95, "answer": "1963", "question": "In what year did Klein and Simmons begin checking all final letter suffixes of lengths 1-5?"}, {"answer_start": 223, "answer": "Ratnaparkhi", "question": "What is the main source of the unknown word features described on page 169?"}, {"answer_start": 268, "answer": "Toutanova et al.", "question": "Who added augmentations to the word features described on page 169?"}, {"answer_start": 296, "answer": "Manning", "question": "Along with Toutanova et al. (2003) and 2011, who added augmentations to the word features described on page 169?"}]}, {"context": "State of the art POS taggers use neural algorithms, either bidirectional RNNs or Transformers like BERT; see Chapter 9 and Chapter 11. HMM (Brants 2000; Thede and Harper 1999) and CRF tagger accuracies are likely just a tad lower.", "questions_and_answers": [{"answer_start": 59, "answer": "bidirectional RNNs or Transformers", "question": "What are some examples of neural algorithms used by state of the art POS taggers?"}, {"answer_start": 218, "answer": "a tad lower", "question": "HMM and CRF tagger accuracies are likely just what?"}]}, {"context": "Manning (2011) investigates the remaining [ 2.7 ]% of errors in a high-performing tagger (Toutanova et al., 2003) . He suggests that a third or half of these remaining errors are due to errors or inconsistencies in the training data, a third might be solvable with richer linguistic models, and for the remainder the task is underspecified or unclear.", "questions_and_answers": [{"answer_start": 44, "answer": "2.7", "question": "What percentage of errors are in a tagger?"}, {"answer_start": 133, "answer": "a third or half", "question": "How many of the remaining errors are due to errors or inconsistencies in training data?"}]}, {"context": "Language is an inherently temporal phenomenon. Spoken language is a sequence of acoustic events over time, and we comprehend and produce both spoken and written language as a continuous input stream. The temporal nature of language is reflected in the metaphors we use; we talk of the flow of conversations, news feeds, and twitter streams, all of which emphasize that language is a sequence that unfolds in time. This temporal nature is reflected in some of the algorithms we use to process language. For example, the Viterbi algorithm applied to HMM part-of-speech tagging, proceeds through the input a word at a time, carrying forward information gleaned along the way. Yet other machine learning approaches, like those we've studied for sentiment analysis or other text classification tasks don't have this temporal naturethey assume simultaneous access to all aspects of their input.", "questions_and_answers": [{"answer_start": 0, "answer": "Language", "question": "What is an inherently temporal phenomenon?"}, {"answer_start": 173, "answer": "a continuous input stream", "question": "What do we comprehend and produce both spoken and written language as?"}, {"answer_start": 248, "answer": "the metaphors", "question": "What is the temporal nature of language reflected in?"}, {"answer_start": 463, "answer": "algorithms", "question": "What do we use to process language?"}, {"answer_start": 519, "answer": "Viterbi algorithm", "question": "What algorithm is applied to HMM part-of-speech tagging?"}, {"answer_start": 838, "answer": "simultaneous access to all aspects of their input", "question": "What does the Viterbi algorithm assume?"}]}, {"context": "This chapter introduces two important deep learning architectures designed to address these challenges: recurrent neural networks and transformer networks. Both approaches have mechanisms to deal directly with the sequential nature of language that allow them to capture and exploit the temporal nature of language. The recurrent network offers a new way to represent the prior context, allowing the model's deci- Figure 9 .1 Simplified sketch of a feedforward neural language model moving through a text. At each time step t the network converts N context words, each to a d-dimensional embedding, and concatenates the N embeddings together to get the Nd \u00d7 1 unit input vector x for the network. The output of the network is a probability distribution over the vocabulary representing the model's belief with respect to each word being the next possible word. sion to depend on information from hundreds of words in the past. The transformer offers new mechanisms (self-attention and positional encodings) that help represent time and help focus on how words relate to each other over long distances. We'll see how to apply both models to the task of language modeling, to sequence modeling tasks like part-of-speech tagging, and to text classification tasks like sentiment analysis.", "questions_and_answers": [{"answer_start": 104, "answer": "recurrent neural networks and transformer networks", "question": "What are two deep learning architectures designed to address these challenges?"}, {"answer_start": 287, "answer": "temporal nature of language", "question": "What do recurrent neural networks and transformer networks capture and exploit?"}, {"answer_start": 372, "answer": "prior context", "question": "The recurrent network offers a new way to represent what?"}, {"answer_start": 547, "answer": "N context words", "question": "At each time step t the network converts what?"}, {"answer_start": 728, "answer": "probability distribution", "question": "What is the output of the feedforward neural network?"}, {"answer_start": 896, "answer": "hundreds of words", "question": "The recurrent network relies on information from what in the past?"}, {"answer_start": 966, "answer": "self-attention and positional encodings", "question": "What are two new mechanisms in the transformer network?"}, {"answer_start": 1203, "answer": "part-of-speech tagging", "question": "What is a sequence modeling task?"}]}, {"context": "In this chapter, we'll begin exploring the RNN and transformer architectures through the lens of probabilistic language models, so let's briefly remind ourselves of the framework for language modeling. Recall from Chapter 3 that probabilistic language models predict the next word in a sequence given some preceding context. For example, if the preceding context is \"Thanks for all the\" and we want to know how likely the next word is \"fish\" we would compute:", "questions_and_answers": [{"answer_start": 97, "answer": "probabilistic language models", "question": "In this chapter, we'll begin exploring the RNN and transformer architectures through the lens of what?"}, {"answer_start": 267, "answer": "the next word in a sequence", "question": "What do probabilistic language models predict?"}, {"answer_start": 436, "answer": "fish", "question": "What is the next word in a sequence that probabilistic language models predict?"}]}, {"context": "Language models give us the ability to assign such a conditional probability to every possible next word, giving us a distribution over the entire vocabulary. We can also assign probabilities to entire sequences by using these conditional probabilities in combination with the chain rule:", "questions_and_answers": [{"answer_start": 0, "answer": "Language models", "question": "What gives us the ability to assign a conditional probability to every possible next word?"}, {"answer_start": 277, "answer": "chain rule", "question": "What rule can be used to assign probabilities to entire sequences?"}]}, {"context": "Recall that we evaluate language models by examining how well they predict unseen text. Intuitively, good models are those that assign higher probabilities to unseen data (are less surprised when encountering the new words).", "questions_and_answers": [{"answer_start": 53, "answer": "how well they predict unseen text", "question": "How do we evaluate language models?"}, {"answer_start": 135, "answer": "higher probabilities", "question": "What do good models assign to unseen data?"}]}, {"context": "To visualize how perplexity can be computed as a function of the probabilities our LM will compute for each new word, we can use the chain rule to expand the computation of probability of the test set:", "questions_and_answers": [{"answer_start": 129, "answer": "the chain rule", "question": "What can we use to expand the computation of probability of the test set?"}]}, {"context": "A recurrent neural network (RNN) is any network that contains a cycle within its network connections, meaning that the value of some unit is directly, or indirectly, dependent on its own earlier outputs as an input. While powerful, such networks are difficult to reason about and to train. However, within the general class of recurrent networks there are constrained architectures that have proven to be extremely effective when applied to language. In this section, we consider a class of recurrent networks referred to as Elman Networks (Elman, 1990) or simple recurrent net-Elman Networks works. These networks are useful in their own right and serve as the basis for more complex approaches like the Long Short-Term Memory (LSTM) networks discussed later in this chapter. In this chapter when we use the term RNN we'll be referring to these simpler more constrained networks (although you will often see the term RNN to mean any net with recurrent properties including LSTMs).", "questions_and_answers": [{"answer_start": 36, "answer": "any network that contains a cycle within its network connections", "question": "What is a recurrent neural network?"}, {"answer_start": 250, "answer": "difficult", "question": "What are recurrent neural networks?"}, {"answer_start": 356, "answer": "constrained architectures", "question": "What has proven to be extremely effective when applied to language?"}, {"answer_start": 525, "answer": "Elman Networks", "question": "What is another name for a class of recurrent networks?"}, {"answer_start": 705, "answer": "Long Short-Term Memory", "question": "What does LSTM stand for?"}, {"answer_start": 846, "answer": "simpler more constrained networks", "question": "What do we refer to when we use the term RNN?"}]}, {"context": "The hidden layer from the previous time step provides a form of memory, or context, that encodes earlier processing and informs the decisions to be made at later points in time. Critically, this approach does not impose a fixed-length limit on this prior context; the context embodied in the previous hidden layer can include information extending back to the beginning of the sequence.", "questions_and_answers": [{"answer_start": 0, "answer": "The hidden layer", "question": "What provides a form of memory that encodes earlier processing and informs the decisions to be made at later points in time?"}, {"answer_start": 264, "answer": "the context embodied in the previous hidden layer", "question": "What can include information extending back to the beginning of the sequence?"}]}, {"context": "Forward inference (mapping a sequence of inputs to a sequence of outputs) in an RNN is nearly identical to what we've already seen with feedforward networks. To compute an output y t for an input x t , we need the activation value for the hidden layer h t . To calculate this, we multiply the input x t with the weight matrix W, and the hidden layer from the previous time step h t\u22121 with the weight matrix U. We add these values together and pass them through a suitable activation function, g, to arrive at the activation value for the current hidden layer, h t . Once we have the values for the hidden layer, we proceed with the usual computation to generate the output vector.", "questions_and_answers": [{"answer_start": 0, "answer": "Forward inference", "question": "What is mapping a sequence of inputs to a sequence of outputs called?"}, {"answer_start": 252, "answer": "h t", "question": "What is the activation value for the hidden layer?"}, {"answer_start": 326, "answer": "W", "question": "What is the weight matrix for the hidden layer h t?"}, {"answer_start": 25, "answer": "g", "question": "What ether do we add these values to?"}, {"answer_start": 666, "answer": "output vector", "question": "What do we generate once we have the values for the hidden layer?"}]}, {"context": "It's worthwhile here to be careful about specifying the dimensions of the input, hidden and output layers, as well as the weight matrices to make sure these calculations are correct. Let's refer to the input, hidden and output layer dimensions as d in , d h , and d out respectively. Given this, our three parameter matrices are:", "questions_and_answers": [{"answer_start": 52, "answer": "the dimensions", "question": "What do we need to be careful about specifying in the input, hidden and output layers?"}, {"answer_start": 247, "answer": "d in", "question": "What are the dimensions of the input, hidden and output layers?"}, {"answer_start": 300, "answer": "three", "question": "How many parameter matrices are there?"}]}, {"context": "In the commonly encountered case of soft classification, computing y t consists of a softmax computation that provides a probability distribution over the possible output classes.", "questions_and_answers": [{"answer_start": 119, "answer": "a probability distribution over the possible output classes", "question": "What does a softmax computation provide?"}, {"answer_start": 36, "answer": "soft classification", "question": "What is the common case of computing y t?"}]}, {"context": "The fact that the computation at time t requires the value of the hidden layer from time t \u2212 1 mandates an incremental inference algorithm that proceeds from the start of the sequence to the end as illustrated in Figure 9 .4. The sequential nature of simple recurrent networks can also be seen by unrolling the network in time as is shown in Figure 9 .5. In this figure, the various layers of units are copied for each time step to illustrate that they will have differing values over time. However, the various weight matrices are shared across time.", "questions_and_answers": [{"answer_start": 107, "answer": "incremental inference algorithm", "question": "What does the fact that the computation at time t requires the value of the hidden layer from time t  1 mandate?"}, {"answer_start": 297, "answer": "unrolling the network in time", "question": "How can the sequential nature of simple recurrent networks be seen?"}, {"answer_start": 429, "answer": "to illustrate that they will have differing values over time", "question": "Why are the layers of units copied for each time step?"}, {"answer_start": 512, "answer": "weight matrices", "question": "What is shared across time?"}]}, {"context": "Tailoring the backpropagation algorithm to this situation leads to a two-pass algorithm for training the weights in RNNs. In the first pass, we perform forward inference, computing h t , y t , accumulating the loss at each step in time, saving the value of the hidden layer at each step for use at the next time step. In the second phase, we process the sequence in reverse, computing the required gradients as we go, computing and saving the error term for use in the hidden layer for each step backward in time. This general approach is commonly referred to as Backpropagation Through Time (Werbos 1974 , Rumelhart et al. 1986 , Werbos 1990 ).", "questions_and_answers": [{"answer_start": 69, "answer": "two-pass algorithm", "question": "Tailoring the backpropagation algorithm to this situation leads to what?"}, {"answer_start": 152, "answer": "forward inference", "question": "What is performed in the first pass of the backpropagation algorithm?"}, {"answer_start": 325, "answer": "second", "question": "In what phase of the backpropagation algorithm do we process the sequence in reverse?"}, {"answer_start": 563, "answer": "Backpropagation Through Time", "question": "What is the general approach used to train weights in RNNs called?"}, {"answer_start": 631, "answer": "Werbos 1990", "question": "When was Backpropagation Through Time first used?"}]}, {"context": "Fortunately, with modern computational frameworks and adequate computing resources, there is no need for a specialized approach to training RNNs. As illustrated in Figure 9 .5, explicitly unrolling a recurrent network into a feedforward computational graph eliminates any explicit recurrences, allowing the network weights to be trained directly. In such an approach, we provide a template that specifies the basic structure of the network, including all the necessary parameters for the input, output, and hidden layers, the weight matrices, as well as the activation and output functions to be used. Then, when presented with a specific input sequence, we can generate an unrolled feedforward network specific to that input, and use that graph to perform forward inference or training via ordinary backpropagation.", "questions_and_answers": [{"answer_start": 18, "answer": "modern computational frameworks and adequate computing resources", "question": "With what is there no need for a specialized approach to training RNNs?"}, {"answer_start": 225, "answer": "feedforward", "question": "What type of graph eliminates explicit recurrences?"}, {"answer_start": 379, "answer": "a template", "question": "What does a feedforward computational graph provide that specifies the basic structure of the network?"}, {"answer_start": 757, "answer": "forward inference or training via ordinary backpropagation", "question": "What can an unrolled feedforward network perform when presented with a specific input sequence?"}]}, {"context": "RNN language models (Mikolov et al., 2010) process the input sequence one word at a time, attempting to predict the next word from the current word and the previous hidden state. RNNs don't have the limited context problem that n-gram models have, since the hidden state can in principle represent information about all of the preceding words all the way back to the beginning of the sequence.", "questions_and_answers": [{"answer_start": 0, "answer": "RNN language models", "question": "What model processes the input sequence one word at a time?"}, {"answer_start": 37, "answer": "2010", "question": "In what year did Mikolov and his colleagues publish their RNN language models?"}, {"answer_start": 254, "answer": "the hidden state", "question": "What can in principle represent information about all of the preceding words all the way back to the beginning of the sequence?"}]}, {"context": "x N ] consists of a series of word embeddings each represented as a one-hot vector of size |V |\u00d71, and the output prediction, y, is a vector representing a probability distribution over the vocabulary. At each step, the model uses the word embedding matrix E to retrieve the embedding for the current word, and then combines it with the hidden layer from the previous step to compute a new hidden layer. This hidden layer is then used to generate an output layer which is passed through a softmax layer to generate a probability distribution over the entire vocabulary. That is, at time t:", "questions_and_answers": [{"answer_start": 66, "answer": "a one-hot vector of size", "question": "What are the word embeddings represented as?"}, {"answer_start": 231, "answer": "the word embedding matrix E", "question": "What does the model use to retrieve the embedding for the current word?"}, {"answer_start": 487, "answer": "a softmax layer", "question": "What is the output layer passed through to generate a probability distribution over the entire vocabulary?"}, {"answer_start": 579, "answer": "at time t", "question": "When is the output layer passed through a softmax layer to generate a probability distribution over the entire vocabulary?"}]}, {"context": "The vector resulting from Vh can be thought of as a set of scores over the vocabulary given the evidence provided in h. Passing these scores through the softmax normalizes the scores into a probability distribution. The probability that a particular word i in the vocabulary is the next word is represented by y t [i], the ith component of y t :", "questions_and_answers": [{"answer_start": 50, "answer": "a set of scores over the vocabulary", "question": "The vector resulting from Vh can be thought of as what?"}, {"answer_start": 230, "answer": "y t", "question": "What component of y t represents a word i in the vocabulary?"}]}, {"context": "To train an RNN as a language model, we use a corpus of text as training material, having the model predict the next word at each time step t. We train the model to minimize the error in predicting the true next word in the training sequence, using cross-entropy as the loss function. Recall that the cross-entropy loss measures the difference between a predicted probability distribution and the correct distribution.", "questions_and_answers": [{"answer_start": 249, "answer": "cross-entropy", "question": "What loss function is used to minimize the error in predicting the true next word in the training sequence?"}, {"answer_start": 329, "answer": "the difference between a predicted probability distribution and the correct distribution", "question": "What does the cross-entropy loss measure?"}]}, {"context": "In the case of language modeling, the correct distribution y t comes from knowing the next word. This is represented as a one-hot vector corresponding to the vocabulary where the entry for the actual next word is 1, and all the other entries are 0. Thus, the cross-entropy loss for language modeling is determined by the probability the model assigns to the correct next word. So at time t the CE loss is the negative log probability the model assigns to the next word in the training sequence.", "questions_and_answers": [{"answer_start": 74, "answer": "knowing the next word", "question": "What does the correct distribution y t come from?"}, {"answer_start": 213, "answer": "1", "question": "What is the entry for the actual next word?"}, {"answer_start": 321, "answer": "probability", "question": "What is the cross-entropy loss determined by?"}, {"answer_start": 409, "answer": "negative log probability", "question": "What is the CE loss determined by the model assigning to the next word in the training sequence?"}]}, {"context": "Thus at each word position t of the input, the model takes as input the correct sequence of tokens w 1:t , and uses them to compute a probability distribution over possible next words so as to compute the model's loss for the next token w t+1 . Then we move to the next word, we ignore what the model predicted for the next word and instead use the correct sequence of tokens w 1:t+1 to estimate the probability of token w t+2 . This idea that we always give the model the correct history sequence to", "questions_and_answers": [{"answer_start": 68, "answer": "the correct sequence of tokens", "question": "What does the model take as input at each word position t?"}, {"answer_start": 396, "answer": "the probability of token w t+2", "question": "What does the model use the correct sequence of tokens w 1:t+1 to estimate?"}, {"answer_start": 469, "answer": "the correct history sequence", "question": "What do we always give the model to estimate the probability of token w+2?"}]}, {"context": "The final layer matrix V provides a way to score the likelihood of each word in the vocabulary given the evidence present in the final hidden layer of the network through the calculation of Vh. This entails that it also has the dimensionality |V | \u00d7 d h . That is, the rows of V provide a second set of learned word embeddings that capture relevant aspects of word meaning and function. This leads to an obvious question -is it even necessary to have both? Weight tying is a method that Weight tying dispenses with this redundancy and uses a single set of embeddings at the input and softmax layers. That is, E = V. To do this, we set the dimensionality of the final hidden layer to be the same d h , (or add an additional projection layer to do the same thing), and simply use the same matrix for both layers. In addition to providing improved perplexity results, this approach significantly reduces the number of parameters required for the model.", "questions_and_answers": [{"answer_start": 43, "answer": "score the likelihood of each word in the vocabulary", "question": "What does the final layer matrix V provide a way to do?"}, {"answer_start": 228, "answer": "dimensionality", "question": "The final layer matrix V provides a way to score the likelihood of each word in the vocabulary given the evidence present in the final hidden layer of the network"}, {"answer_start": 265, "answer": "the rows of V", "question": "What provide a second set of learned word embeddings?"}, {"answer_start": 422, "answer": "is it even necessary to have both", "question": "What is the question that arises from the rows of V providing a second set of learned word embeddings that capture relevant aspects of word meaning"}, {"answer_start": 457, "answer": "Weight tying", "question": "What is a method that dispenses with redundancy and uses a single set of embeddings at the input and softmax"}, {"answer_start": 609, "answer": "E = V", "question": "Weight tying uses a single set of embeddings at the input and softmax layers?"}, {"answer_start": 879, "answer": "significantly reduces the number of parameters required for the model", "question": "What is the benefit of Weight tying?"}]}, {"context": "Now that we've seen the basic RNN architecture, let's consider how to apply it to three types of NLP tasks: sequence classification tasks like sentiment analysis and topic classification, sequence labeling tasks like part-of-speech tagging, and and text generation tasks. And we'll see in Chapter 10 how to use them for encoder-decoder approaches to summarization, machine translation, and question answering.ling", "questions_and_answers": [{"answer_start": 249, "answer": "text generation tasks", "question": "What is another type of NLP task that uses RNN?"}, {"answer_start": 143, "answer": "sentiment analysis and topic classification", "question": "What are two examples of sequence classification tasks?"}, {"answer_start": 320, "answer": "encoder-decoder", "question": "What approaches to summarization will we see in Chapter 10?"}]}, {"context": "In this figure, the inputs at each time step are pre-trained word embeddings corresponding to the input tokens. The RNN block is an abstraction that represents an unrolled simple recurrent network consisting of an input layer, hidden layer, and output layer at each time step, as well as the shared U, V and W weight matrices that comprise the network. The outputs of the network at each time step represent the distribution over the POS tagset generated by a softmax layer.", "questions_and_answers": [{"answer_start": 49, "answer": "pre-trained word embeddings corresponding to the input tokens", "question": "What are the inputs at each time step?"}, {"answer_start": 129, "answer": "an abstraction", "question": "What is the RNN block?"}, {"answer_start": 434, "answer": "POS tagset", "question": "The outputs of the network at each time step represent the distribution over what generated by a softmax layer?"}]}, {"context": "To generate a sequence of tags for a given input, we run forward inference over the input sequence and select the most likely tag from the softmax at each step. Since we're using a softmax layer to generate the probability distribution over the output tagset at each time step, we will again employ the cross-entropy loss during training.", "questions_and_answers": [{"answer_start": 57, "answer": "forward inference", "question": "What is used to generate a sequence of tags for a given input?"}, {"answer_start": 303, "answer": "cross-entropy loss", "question": "What will we use to generate the probability distribution over the output tagset at each time step?"}]}, {"context": "Another use of RNNs is to classify entire sequences rather than the tokens within them. We've already encountered sentiment analysis in Chapter 4, in which we classify a text as positive or negative. Other sequence classification tasks for mapping sequences of text to one from a small set of categories include document-level topic classification, spam detection, or message routing for customer service applications.", "questions_and_answers": [{"answer_start": 35, "answer": "entire sequences", "question": "What are RNNs used to classify?"}, {"answer_start": 178, "answer": "positive or negative", "question": "What do we classify a text as in Chapter 4?"}, {"answer_start": 312, "answer": "document-level topic classification", "question": "What is a sequence classification task for mapping sequences of text to one from a small set of categories?"}]}, {"context": "Note that in this approach there don't need intermediate outputs for the words in the sequence preceding the last element. Therefore, there are no loss terms associated with those elements. Instead, the loss function used to train the weights in the network is based entirely on the final text classification task. The output from the softmax output from the feedforward classifier together with a cross-entropy loss drives the training. The error signal from the classification is backpropagated all the way through the weights in the feedforward classifier through, to its input, and then through to the three sets of weights in the RNN as described earlier in Section [ 9.2 ].2. The training regimen that uses the loss from a downstream application to adjust the weights all the way through the network is referred to as end-to-end training.", "questions_and_answers": [{"answer_start": 44, "answer": "intermediate outputs", "question": "What do the words in the sequence preceding the last element not need?"}, {"answer_start": 147, "answer": "loss terms", "question": "There are no what associated with the words in the sequence preceding the last element?"}, {"answer_start": 283, "answer": "final text classification task", "question": "What is the loss function used to train the weights in the network based on?"}, {"answer_start": 359, "answer": "feedforward", "question": "The output from the softmax output from what classifier drives the training?"}, {"answer_start": 355, "answer": "the feedforward classifier", "question": "The error signal from the classification is backpropagated all the way through the weights in what?"}, {"answer_start": 824, "answer": "end-to-end training", "question": "What is the training regimen that uses the loss from a downstream application to adjust the weights all the way through the network called?"}]}, {"context": "Another option, instead of using just the last token h n to represent the whole sequence, is to use some sort of pooling function of all the hidden states h i for each pooling word i in the sequence. For example, we can create a representation that pools all the n hidden states by taking their element-wise mean:", "questions_and_answers": [{"answer_start": 113, "answer": "pooling function", "question": "What is another way to represent the hidden states h i?"}, {"answer_start": 113, "answer": "pooling function", "question": "What is another way to represent the hidden states h i?"}, {"answer_start": 295, "answer": "element-wise mean", "question": "What do we take to create a representation that pools all the hidden states?"}]}, {"context": "Or we can take the element-wise max; the element-wise max of a set of n vectors is a new vector whose kth element is the max of the kth elements of all the n vectors.", "questions_and_answers": [{"answer_start": 15, "answer": "the element-wise max", "question": "What is a new vector whose kth element is the max of all the kth elements of all the n vectors?"}, {"answer_start": 15, "answer": "the element-wise max", "question": "What is a new vector whose kth element is the max of all the kth elements of all the n vectors?"}]}, {"context": "Today, this approach of using a language model to incrementally generate words by repeatedly sampling the next word conditioned on our previous choices is called autoregressive generation. The procedure is basically the same as that described autoregressive generation on 38, in a neural context:", "questions_and_answers": [{"answer_start": 162, "answer": "autoregressive generation", "question": "What is the approach of using a language model to incrementally generate words by repeatedly sampling the next word conditioned on our previous choices called?"}, {"answer_start": 272, "answer": "38", "question": "On how many words was the procedure described?"}]}, {"context": "Recurrent networks are quite flexible. By combining the feedforward nature of unrolled computational graphs with vectors as common inputs and outputs, complex networks can be treated as modules that can be combined in creative ways. This", "questions_and_answers": [{"answer_start": 0, "answer": "Recurrent networks", "question": "What type of networks are flexible?"}, {"answer_start": 56, "answer": "feedforward", "question": "What is the nature of unrolled computational graphs?"}, {"answer_start": 113, "answer": "vectors", "question": "What are common inputs and outputs of recurrent networks?"}, {"answer_start": 233, "answer": "This", "question": "How can recurrent networks be treated as modules that can be combined in creative ways?"}]}, {"context": "section introduces two of the more common network architectures used in language processing with RNNs.", "questions_and_answers": [{"answer_start": 19, "answer": "two", "question": "How many common network architectures are used in language processing with RNNs?"}]}, {"context": "In our examples thus far, the inputs to our RNNs have consisted of sequences of word or character embeddings (vectors) and the outputs have been vectors useful for predicting words, tags or sequence labels. However, nothing prevents us from using the entire sequence of outputs from one RNN as an input sequence to another one. Stacked RNNs generally outperform single-layer networks. One reason for this success seems to be that the network induces representations at differing levels of abstraction across layers. Just as the early stages of the human visual system detect edges that are then used for finding larger regions and shapes, the initial layers of stacked networks can induce representations that serve as useful abstractions for further layers -representations that might prove difficult to induce in a single RNN. The optimal number of stacked RNNs is specific to each application and to each training set. However, as the number of stacks is increased the training costs rise quickly.", "questions_and_answers": [{"answer_start": 110, "answer": "vectors", "question": "What are the inputs to our RNNs called?"}, {"answer_start": 297, "answer": "input sequence", "question": "What does nothing prevent us from using the entire sequence of outputs from one RNN as?"}, {"answer_start": 328, "answer": "Stacked RNNs", "question": "What generally outperform single-layer networks?"}, {"answer_start": 430, "answer": "the network induces representations at differing levels of abstraction across layers", "question": "Why do stacked RNNs generally outperform single-layer networks?"}, {"answer_start": 639, "answer": "the initial layers of stacked networks", "question": "What can induce representations that serve as useful abstractions for further layers?"}, {"answer_start": 908, "answer": "training set", "question": "The optimal number of stacked RNNs is specific to each application and to what?"}, {"answer_start": 972, "answer": "training costs", "question": "As the number of stacks is increased, what rises quickly?"}]}, {"context": "The RNN uses information from the left (prior) context to make its predictions at time t. But in many applications we have access to the entire input sequence; in those cases we would like to use words from the context to the right of t. One way to do this is to run two separate RNNs, one left-to-right, and one right-to-left, and concatenate their representations.", "questions_and_answers": [{"answer_start": 267, "answer": "two", "question": "How many separate RNNs are there?"}]}, {"context": "In the left-to-right RNNs we've discussed so far, the hidden state at a given time t represents everything the network knows about the sequence up to that point. The state is a function of the inputs x 1 , ..., x t and represents the context of the network to the left of the current time.", "questions_and_answers": [{"answer_start": 96, "answer": "everything the network knows about the sequence up to that point", "question": "What does the hidden state at a given time represent?"}, {"answer_start": 230, "answer": "the context of the network", "question": "What does the hidden state represent to the left of the current time?"}]}, {"context": "x 3 x n Bidirectional RNNs have also proven to be quite effective for sequence classification. Recall from Figure 9 .8 that for sequence classification we used the final hidden state of the RNN as the input to a subsequent feedforward classifier. A difficulty with this approach is that the final state naturally reflects more information about the end of the sentence than its beginning. Bidirectional RNNs provide a simple solution to this problem; as shown in Figure 9 .12, we simply combine the final hidden states from the forward and backward passes (for example by concatenation) and use that as input for follow-on processing.", "questions_and_answers": [{"answer_start": 0, "answer": "x 3 x n", "question": "How many bidirectional RNNs have proven to be quite effective for sequence classification?"}, {"answer_start": 164, "answer": "final hidden state of the RNN", "question": "What did we use as input to a subsequent feedforward classifier?"}, {"answer_start": 287, "answer": "the final state naturally reflects more information about the end of the sentence than its beginning", "question": "What is a problem with using the final hidden state of the RNN as the input to a subsequent feedforward classifier?"}, {"answer_start": 8, "answer": "Bidirectional RNNs", "question": "What provides a simple solution to this problem?"}]}, {"context": ".12 A bidirectional RNN for sequence classification. The final hidden units from the forward and backward passes are combined to represent the entire sequence. This combined representation serves as input to the subsequent classifier.", "questions_and_answers": [{"answer_start": 6, "answer": "bidirectional", "question": "What type of RNN is used for sequence classification?"}, {"answer_start": 53, "answer": "The final hidden units", "question": "What are combined to represent the entire sequence?"}, {"answer_start": 199, "answer": "input", "question": "The combined representation serves as what to the subsequent classifier?"}]}, {"context": "In practice, it is quite difficult to train RNNs for tasks that require a network to make use of information distant from the current point of processing. Despite having access to the entire preceding sequence, the information encoded in hidden states tends to be fairly local, more relevant to the most recent parts of the input sequence and recent decisions. Yet distant information is critical to many language applications. Consider the following example in the context of language modeling.", "questions_and_answers": [{"answer_start": 53, "answer": "tasks that require a network to make use of information distant from the current point of processing", "question": "What is it difficult to train RNNs for?"}, {"answer_start": 271, "answer": "local", "question": "Information encoded in hidden states tends to be fairly what?"}, {"answer_start": 405, "answer": "language applications", "question": "What is distant information critical to?"}, {"answer_start": 477, "answer": "language modeling", "question": "What is the context of the following example?"}]}, {"context": "Assigning a high probability to was following airline is straightforward since airline provides a strong local context for the singular agreement. However, assigning an appropriate probability to were is quite difficult, not only because the plural flights is quite distant, but also because the intervening context involves singular constituents. Ideally, a network should be able to retain the distant information about plural flights until it is needed, while still processing the intermediate parts of the sequence correctly. One reason for the inability of RNNs to carry forward critical information is that the hidden layers, and, by extension, the weights that determine the values in the hidden layer, are being asked to perform two tasks simultaneously: provide information useful for the current decision, and updating and carrying forward information required for future decisions.", "questions_and_answers": [{"answer_start": 98, "answer": "strong local context", "question": "What does airline provide for the singular agreement?"}, {"answer_start": 242, "answer": "plural flights", "question": "What is quite distant?"}, {"answer_start": 437, "answer": "until it is needed", "question": "When should a network be able to retain distant information about plural flights?"}, {"answer_start": 763, "answer": "provide information useful for the current decision, and updating and carrying forward information required for future decisions", "question": "What are the hidden layers being asked to do simultaneously?"}]}, {"context": "A second difficulty with training RNNs arises from the need to backpropagate the error signal back through time. Recall from Section [ 9.2 ].2 that the hidden layer at time t contributes to the loss at the next time step since it takes part in that calculation. As a result, during the backward pass of training, the hidden layers are subject to repeated multiplications, as determined by the length of the sequence. A frequent result of this process is that the gradients are eventually driven to zero, a situation called the vanishing gradients problem.", "questions_and_answers": [{"answer_start": 63, "answer": "backpropagate", "question": "What is a second difficulty with training RNNs?"}, {"answer_start": 148, "answer": "the hidden layer at time t", "question": "What contributes to the loss at the next time step?"}, {"answer_start": 346, "answer": "repeated multiplications", "question": "What are hidden layers subject to during the backward pass of training?"}, {"answer_start": 523, "answer": "the vanishing gradients problem", "question": "What is the situation where the gradients are eventually driven to zero called?"}]}, {"context": "To address these issues, more complex network architectures have been designed to explicitly manage the task of maintaining relevant context over time, by enabling the network to learn to forget information that is no longer needed and to remember information required for decisions still to come.", "questions_and_answers": [{"answer_start": 25, "answer": "more complex network architectures", "question": "What has been designed to address the problem of maintaining relevant context over time?"}]}, {"context": "The most commonly used such extension to RNNs is the Long short-term memory (LSTM) network (Hochreiter and Schmidhuber, 1997) . LSTMs divide the context management problem into two sub-problems: removing information no longer needed from the context, and adding information likely to be needed for later decision making. The key to solving both problems is to learn how to manage this context rather than hard-coding a strategy into the architecture. LSTMs accomplish this by first adding an explicit context layer to the architecture (in addition to the usual recurrent hidden layer), and through the use of specialized neural units that make use of gates to control the flow of information into and out of the units that comprise the network layers. These gates are implemented through the use of additional weights that operate sequentially on the input, and previous hidden layer, and previous context layers. The gates in an LSTM share a common design pattern; each consists of a feedforward layer, followed by a sigmoid activation function, followed by a pointwise multiplication with the layer being gated. The choice of the sigmoid as the activation function arises from its tendency to push its outputs to either 0 or 1. Combining this with a pointwise multiplication has an effect similar to that of a binary mask. Values in the layer being gated that align with values near 1 in the mask are passed through nearly unchanged; values corresponding to lower values are essentially erased.", "questions_and_answers": [{"answer_start": 53, "answer": "Long short-term memory", "question": "What is the most commonly used extension to RNNs?"}, {"answer_start": 145, "answer": "context management", "question": "What problem do LSTMs divide into two sub-problems?"}, {"answer_start": 360, "answer": "learn how to manage this context", "question": "What is the key to solving the context management problem?"}, {"answer_start": 609, "answer": "specialized neural units", "question": "What makes use of gates to control the flow of information into and out of the units that comprise the network layers?"}, {"answer_start": 799, "answer": "additional weights", "question": "What is used to implement the gates that control the flow of information into and out of the units that comprise the network layers?"}, {"answer_start": 983, "answer": "a feedforward layer, followed by a sigmoid activation function, followed by a pointwise multiplication", "question": "What are the gates in an LSTM?"}, {"answer_start": 1179, "answer": "its tendency to push its outputs to either 0 or 1", "question": "The choice of the sigmoid as the activation function arises from what?"}, {"answer_start": 1310, "answer": "a binary mask", "question": "What is the effect of combining a pointwise multiplication with a sigmoid activation function with a pointwise multiplication similar"}, {"answer_start": 1373, "answer": "values near 1 in the mask", "question": "Values in the layer being gated that align with what are passed through nearly unchanged?"}]}, {"context": "The first gate we'll consider is the forget gate. The purpose of this gate to delete information from the context that is no longer needed. The forget gate computes a weighted sum of the previous state's hidden layer and the current input and passes that through a sigmoid. This mask is then multiplied element-wise by the context vector to remove the information from context that is no longer required. Elementwise multiplication of two vectors (represented by the operator , and sometimes called the Hadamard product) is the vector of the same dimension as the two input vectors, where each element i is the product of element i in the two input vectors:", "questions_and_answers": [{"answer_start": 37, "answer": "forget gate", "question": "What is the first gate we'll consider?"}, {"answer_start": 78, "answer": "delete information from the context", "question": "What does the forget gate do?"}, {"answer_start": 265, "answer": "sigmoid", "question": "The forget gate computes a weighted sum of the previous state's hidden layer and the current input and passes that through what?"}, {"answer_start": 106, "answer": "context", "question": "The forget gate is multiplied element-wise by what vector to remove the information from context that is no longer needed?"}, {"answer_start": 503, "answer": "Hadamard product", "question": "Elementwise multiplication of two vectors is sometimes called what?"}]}, {"context": "The next task is compute the actual information we need to extract from the previous hidden state and current inputs -the same basic computation we've been using for all our recurrent networks.", "questions_and_answers": [{"answer_start": 17, "answer": "compute the actual information", "question": "What is the next task we need to extract from the previous hidden state and current inputs?"}]}, {"context": "Next, we generate the mask for the add gate to select the information to add to the add gate current context. Next, we add this to the modified context vector to get our new context vector.", "questions_and_answers": [{"answer_start": 80, "answer": "the add gate current context", "question": "The mask for the add gate is used to select the information to add to what?"}, {"answer_start": 144, "answer": "context vector", "question": "To get our new context vector, we add the mask to what?"}]}, {"context": "The final gate we'll use is the output gate which is used to decide what informaoutput gate tion is required for the current hidden state (as opposed to what information needs to be preserved for future decisions).", "questions_and_answers": [{"answer_start": 28, "answer": "the output gate", "question": "What is the final gate we'll use?"}]}, {"context": "The increased complexity of the LSTM units is encapsulated within the unit itself. The only additional external complexity for the LSTM over the basic recurrent unit (b) is the presence of the additional context vector as an input and output.", "questions_and_answers": [{"answer_start": 46, "answer": "encapsulated within the unit itself", "question": "Where is the increased complexity of the LSTM units?"}, {"answer_start": 204, "answer": "context vector", "question": "What is the only external complexity for the LSTM over the basic recurrent unit?"}]}, {"context": "This modularity is key to the power and widespread applicability of LSTM units. LSTM units (or other varieties, like GRUs) can be substituted into any of the network architectures described in Section [ 9.5 ]. And, as with simple RNNs, multi-layered networks making use of gated units can be unrolled into deep feedforward networks and trained in the usual fashion with backpropagation.", "questions_and_answers": [{"answer_start": 5, "answer": "modularity", "question": "What is key to the power and widespread applicability of LSTM units?"}, {"answer_start": 117, "answer": "GRUs", "question": "What other type of LSTM units can be substituted into any network architecture described in Section 9.5?"}, {"answer_start": 273, "answer": "gated units", "question": "What can be unrolled into deep feedforward networks?"}]}, {"context": "At the core of an attention-based approach is the ability to compare an item of interest to a collection of other items in a way that reveals their relevance in the current context. In the case of self-attention, the set of comparisons are to other elements within a given sequence. The result of these comparisons is then used to compute an output for the current input. For example, returning to Figure 9 .15, the computation of y 3 is based on a set of comparisons between the input x 3 and its preceding elements x 1 and x 2 , and to x 3 itself. The simplest form of comparison between elements in a self-attention layer is a dot product. Let's refer to the result of this comparison as a score (we'll be updating this equation to add attention to the computation of this score):", "questions_and_answers": [{"answer_start": 50, "answer": "ability to compare", "question": "What is at the core of an attention-based approach?"}, {"answer_start": 197, "answer": "self-attention", "question": "What type of attention-based approach uses a set of comparisons to other elements within a given sequence?"}, {"answer_start": 331, "answer": "compute an output for the current input", "question": "What is the result of the comparisons used for?"}, {"answer_start": 486, "answer": "x 3", "question": "The computation of y 3 is based on a set of comparisons between what input and its preceding elements?"}, {"answer_start": 628, "answer": "a dot product", "question": "What is the simplest form of comparison between elements in a self-attention layer?"}, {"answer_start": 691, "answer": "a score", "question": "What is the result of a comparison between elements in a self-attention layer called?"}]}, {"context": "The result of a dot product is a scalar value ranging from \u2212\u221e to \u221e, the larger the value the more similar the vectors that are being compared. Continuing with our example, the first step in computing y 3 would be to compute three scores:", "questions_and_answers": [{"answer_start": 33, "answer": "scalar", "question": "What is the result of a dot product?"}, {"answer_start": 216, "answer": "compute three scores", "question": "What is the first step in computing y 3?"}]}, {"context": "Then to make effective use of these scores, we'll normalize them with a softmax to create a vector of weights, \u03b1 i j , that indicates the proportional relevance of each input to the input element i that is the current focus of attention.", "questions_and_answers": [{"answer_start": 90, "answer": "a vector of weights", "question": "What will we create to make effective use of the scores?"}, {"answer_start": 19, "answer": "i", "question": "To make use of these scores, we'll normalize them with a softmax to create a vector of weights,  i"}]}, {"context": "Given the proportional scores in \u03b1, we then generate an output value y i by taking the sum of the inputs seen so far, weighted by their respective \u03b1 value.", "questions_and_answers": [{"answer_start": 10, "answer": "proportional scores", "question": "What is the output value y i generated by taking the sum of the inputs seen so far, weighted by their respective  value"}, {"answer_start": 69, "answer": "y i", "question": "What is the output value?"}]}, {"context": "The steps embodied in Equations [ 9.27 ] through [ 9.30 ] represent the core of an attention-based approach: a set of comparisons to relevant items in some context, a normalization of those scores to provide a probability distribution, followed by a weighted sum using this distribution. The output y is the result of this straightforward computation over the inputs.", "questions_and_answers": [{"answer_start": 109, "answer": "a set of comparisons to relevant items in some context", "question": "What are the steps embodied in Equations 9.27 through 9.30?"}, {"answer_start": 165, "answer": "a normalization of those scores to provide a probability distribution", "question": "What are the steps embodied in Equations 9.27 through 9.30?"}, {"answer_start": 323, "answer": "straightforward computation over the inputs", "question": "What is the output y?"}]}, {"context": "This kind of simple attention can be useful, and indeed we'll see in Chapter 10 how to use this simple idea of attention for LSTM-based encoder-decoder models for machine translation.", "questions_and_answers": [{"answer_start": 13, "answer": "simple attention", "question": "What kind of attention can be useful?"}]}, {"context": "But transformers allow us to create a more sophisticated way of representing how words can contribute to the representation of longer inputs. Consider the three different roles that each input embedding plays during the course of the attention process.", "questions_and_answers": [{"answer_start": 4, "answer": "transformers", "question": "What allows us to create a more sophisticated way of representing how words can contribute to the representation of longer inputs?"}, {"answer_start": 155, "answer": "three", "question": "How many different roles does each input embedding play during the attention process?"}]}, {"context": "[ \u2022 ] As the current focus of attention when being compared to all of the other preceding inputs. We'll refer to this role as a query.", "questions_and_answers": [{"answer_start": 13, "answer": "current focus of attention", "question": "What is the current focus of attention when being compared to all of the other preceding inputs?"}, {"answer_start": 128, "answer": "query", "question": "What is the current focus of attention when being compared to all of the other preceding inputs?"}]}, {"context": "[ \u2022 ] In its role as a preceding input being compared to the current focus of attention. We'll refer to this role as a key. key", "questions_and_answers": [{"answer_start": 61, "answer": "current focus of attention", "question": "In its role as a preceding input being compared to what?"}, {"answer_start": 119, "answer": "key", "question": "What is the role of a preceding input being compared to the current focus of attention?"}, {"answer_start": 119, "answer": "key", "question": "What is the role of a key compared to the current focus of attention?"}]}, {"context": "[ \u2022 ] And finally, as a value used to compute the output for the current focus of value attention.", "questions_and_answers": [{"answer_start": 38, "answer": "compute the output", "question": "What is a value used to do for the current focus of value attention?"}]}, {"context": "The inputs x and outputs y of transformers, as well as the intermediate vectors after the various layers, all have the same dimensionality 1 \u00d7 d. For now let's assume the dimensionalities of the transform matrices are W Q \u2208 R d\u00d7d , W K \u2208 R d\u00d7d , and W V \u2208 R d\u00d7d . Later we'll need separate dimensions for these matrices when we introduce multi-headed attention, so let's just make a note that we'll have a dimension d k for the key and query vectors, and a dimension d v for the value vectors, both of which for now we'll set to d. In the original transformer work (Vaswani et al., 2017) , d was 1024.", "questions_and_answers": [{"answer_start": 15, "answer": "d", "question": "When we introduce multi-headed attention, what will separate dimensions for these matrices?"}]}, {"context": "The ensuing softmax calculation resulting in \u03b1 i, j remains the same, but the output calculation for y i is now based on a weighted sum over the value vectors v. Figure 9 .16 illustrates this calculation in the case of computing the third output y 3 in a sequence.", "questions_and_answers": [{"answer_start": 246, "answer": "y 3", "question": "What is the third output in a sequence?"}]}, {"context": "Given these matrices we can compute all the requisite query-key comparisons simultaneously by multiplying Q and K in a single matrix multiplication (the product is of shape N \u00d7 N; Figure 9 .17 shows a visualization). Taking this one step further, we can scale these scores, take the softmax, and then multiply the result by V resulting in a matrix of shape N \u00d7 d: a vector embedding representation for each token in the input. We've reduced the entire self-attention step for an entire sequence of N tokens to the following computation:", "questions_and_answers": [{"answer_start": 91, "answer": "by multiplying Q and K in a single matrix multiplication", "question": "How can we compute all the query-key comparisons simultaneously?"}, {"answer_start": 366, "answer": "vector embedding representation", "question": "What is the matrix of shape N  d?"}, {"answer_start": 524, "answer": "computation", "question": "What is the self-attention step for an entire sequence of N tokens reduced to?"}]}, {"context": "Figure [ 9.17 ] The N \u00d7 N QT matrix showing the q i [ \u2022 ] k j values, with the upper-triangle portion of the comparisons matrix zeroed out (set to \u2212\u221e, which the softmax will turn to zero).", "questions_and_answers": [{"answer_start": 58, "answer": "k j values", "question": "What values are shown in the N  N QT matrix?"}, {"answer_start": 48, "answer": "q i", "question": "What values are shown in the N  N QT matrix?"}]}, {"context": "Figure 9 .17 also makes it clear that attention is quadratic in the length of the input, since at each layer we need to compute dot products between each pair of tokens in the input. This makes it extremely expensive for the input to a transformer to consist of long documents (like entire Wikipedia pages, or novels), and so most applications have to limit the input length, for example to at most a page or a paragraph of text at a time. Finding more efficient attention mechanisms is an ongoing research direction.", "questions_and_answers": [{"answer_start": 51, "answer": "quadratic", "question": "Figure 9.17 makes it clear that attention is what in the length of the input?"}, {"answer_start": 290, "answer": "Wikipedia", "question": "What is an example of a long document that can be input to a transformer?"}, {"answer_start": 440, "answer": "Finding more efficient attention mechanisms", "question": "What is an ongoing research direction?"}]}, {"context": "Given these values, the vector components are normalized by subtracting the mean from each and dividing by the standard deviation. The result of this computation is a new vector with zero mean and a standard deviation of one.", "questions_and_answers": [{"answer_start": 57, "answer": "by subtracting the mean from each and dividing by the standard deviation", "question": "How are the vector components normalized?"}, {"answer_start": 183, "answer": "zero mean", "question": "What is the result of normalizing the vector components?"}]}, {"context": "The different words in a sentence can relate to each other in many different ways simultaneously. For example, distinct syntactic, semantic, and discourse relationships can hold between verbs and their arguments in a sentence. It would be difficult for a single transformer block to learn to capture all of the different kinds of parallel relations among its inputs. Transformers address this issue with multihead selfattention layers. These are sets of self-attention layers, called heads, that reside in multihead self-attention layers parallel layers at the same depth in a model, each with its own set of parameters. Given these distinct sets of parameters, each head can learn different aspects of the relationships that exist among inputs at the same level of abstraction.", "questions_and_answers": [{"answer_start": 38, "answer": "relate", "question": "The different words in a sentence can do what to each other in many different ways simultaneously?"}, {"answer_start": 111, "answer": "distinct syntactic, semantic, and discourse relationships", "question": "What can hold between verbs and their arguments in a sentence?"}, {"answer_start": 330, "answer": "parallel relations", "question": "What kind of relationships can a single transformer block learn to capture?"}, {"answer_start": 404, "answer": "multihead selfattention layers", "question": "What are sets of self-attention layers called heads that reside in multihead self-attention layers parallel layers at the same depth in a model?"}, {"answer_start": 484, "answer": "heads", "question": "What are sets of self-attention layers called?"}, {"answer_start": 682, "answer": "different aspects of the relationships", "question": "What can each head learn?"}]}, {"context": "To implement this notion, each head, i, in a self-attention layer is provided with its own set of key, query and value matrices:", "questions_and_answers": [{"answer_start": 45, "answer": "self-attention layer", "question": "In what layer is each head provided with its own set of key, query and value matrices?"}, {"answer_start": 98, "answer": "key, query and value matrices", "question": "What is provided to each head in a self-attention layer?"}]}, {"context": "One simple solution is to modify the input embeddings by combining them with positional embeddings specific to each position in an input sequence.", "questions_and_answers": [{"answer_start": 77, "answer": "positional embeddings", "question": "What can be combined with the input embeddings?"}]}, {"context": "Figure 9 .19 Multihead self-attention: Each of the multihead self-attention layers is provided with its own set of key, query and value weight matrices. The outputs from each of the layers are concatenated and then projected down to d, thus producing an output of the same size as the input so layers can be stacked.", "questions_and_answers": [{"answer_start": 115, "answer": "key, query and value weight matrices", "question": "What are each of the multihead self-attention layers provided with?"}, {"answer_start": 254, "answer": "output of the same size", "question": "What do the outputs from each of the layers produce?"}]}, {"context": "A simple variation on autoregressive generation that underlies a number of practical applications uses a prior context to prime the autoregressive generation process. Figure 9 .22 illustrates this with the task of text completion. Here a standard language model is given the prefix to some text and is asked to generate a possible completion to it. Note that as the generation process proceeds, the model has direct access to the priming context as well as to all of its own subsequently generated outputs. This ability to incorporate the entirety of the earlier context and generated outputs at each time step is the key to the power of these models. Text summarization is a practical application of context-based autoregressive Text summarization generation. The task is to take a full-length article and produce an effective summary of it. To train a transformer-based autoregressive model to perform this task, we start with a corpus consisting of full-length articles accompanied by their corresponding summaries. Figure 9 .23 shows an example of this kind of data from a widely used summarization corpus consisting of CNN and Daily Mirror news articles.", "questions_and_answers": [{"answer_start": 103, "answer": "a prior context", "question": "What does a simple variation on autoregressive generation use to prime the autoregressive generation process?"}, {"answer_start": 214, "answer": "text completion", "question": "What is the task of priming the autoregressive generation process?"}, {"answer_start": 236, "answer": "a standard language model", "question": "Who is given the prefix to some text and asked to generate a possible completion to it?"}, {"answer_start": 430, "answer": "priming", "question": "As the generation process proceeds, the model has direct access to what context?"}, {"answer_start": 555, "answer": "earlier", "question": "The ability to incorporate the entirety of what context and generated outputs at each time step is the key to the power of these models."}, {"answer_start": 652, "answer": "Text summarization", "question": "What is a practical application of context-based autoregressive Text summarization generation?"}, {"answer_start": 776, "answer": "take a full-length article and produce an effective summary of it", "question": "What is the task of Text summarization?"}, {"answer_start": 952, "answer": "full-length articles accompanied by their corresponding summaries", "question": "What does the corpus consist of to train a transformer-based autoregressive model to perform this task?"}, {"answer_start": 1124, "answer": "CNN and Daily Mirror", "question": "What are two examples of a widely used summarization corpus consisting of full-length articles accompanied by their corresponding summaries?"}]}, {"context": "A simple but surprisingly effective approach to applying transformers to summarization is to append a summary to each full-length article in a corpus, with a unique marker separating the two. More formally, each article-summary pair (x 1 , ..., x m ), (y 1 , ..., y n ) in a training corpus is converted into a single training instance (x 1 , ..., x m , \u03b4 , y 1 , ...y n ) with an overall length of n + m + 1. These training instances are treated as long sentences and then used to train an autoregressive language model using teacher forcing, exactly as we did earlier.", "questions_and_answers": [{"answer_start": 93, "answer": "append a summary", "question": "What is a simple but effective way to apply transformers to summarization?"}, {"answer_start": 212, "answer": "article-summary pair", "question": "What is converted into a single training instance?"}, {"answer_start": 491, "answer": "autoregressive language model", "question": "What are the training instances used to train?"}]}, {"context": "Once trained, full articles ending with the special marker are used as the context to prime the generation process to produce a summary as illustrated in Figure 9 .24. Note that, in contrast to RNNs, the model has access to the original article as well as to the newly generated text throughout the process.", "questions_and_answers": [{"answer_start": 14, "answer": "full articles ending with the special marker", "question": "What is used as the context to prime the generation process to produce a summary?"}, {"answer_start": 224, "answer": "the original article", "question": "In contrast to RNNs, the model has access to what?"}]}, {"context": "As we'll see in later chapters, variations on this simple scheme are the basis for successful text-to-text applications including machine translation, summarization and question answering.", "questions_and_answers": [{"answer_start": 130, "answer": "machine translation, summarization and question answering", "question": "What are some examples of successful text-to-text applications?"}]}, {"context": "Transformers can also be used for sequence labeling tasks (like part-of-speech tagging or named entity tagging) and sequence classification tasks (like sentiment classification), as we'll see in detail in Chapter 11. Just to give a preview, however, we don't directly train a raw transformer on these tasks. Instead, we use a technique called pretraining, in which we first train a transformer language model on a large corpus of text, in a normal self-supervised way, and only afterwards add a linear or feedforward layer on top that we finetune on a smaller dataset hand-labeled withfinetune part-of-speech or sentiment labels. Pretraining on large amounts of data via the self-supervised language model objective turns out to be a very useful way of incorporating rich information about language, and the resulting representations make it much easier to learn from the generally smaller supervised datasets for tagging or sentiment.", "questions_and_answers": [{"answer_start": 90, "answer": "named entity tagging", "question": "Transformers can also be used for sequence labeling tasks like what?"}, {"answer_start": 253, "answer": "don't directly train a raw transformer", "question": "How do we train a transformer?"}, {"answer_start": 343, "answer": "pretraining", "question": "What technique is used to train a transformer language model on a large corpus of text?"}, {"answer_start": 753, "answer": "incorporating rich information about language", "question": "Pretraining on large amounts of data via the self-supervised language model objective turns out to be a very useful way of what?"}]}, {"context": "This chapter has introduced the concepts of recurrent neural networks and transformers and how they can be applied to language problems. Here\u2019s a summary of the main points that we covered:", "questions_and_answers": [{"answer_start": 44, "answer": "recurrent neural networks", "question": "What concepts did this chapter introduce?"}, {"answer_start": 146, "answer": "summary", "question": "What is a summary of the main points that we covered in this chapter?"}]}, {"context": "[ \u2022 ] In simple Recurrent Neural Networks sequences are processed one element at a time, with the output of each neural unit at time t based both on the current input at t and the hidden layer from time t \u2212 1. [ \u2022 ] RNNs can be trained with a straightforward extension of the backpropagation algorithm, known as backpropagation through time (BPTT). [ \u2022 ] Simple recurrent networks fail on long inputs because of problems like vanishing gradients; instead modern systems use more complex gated architectures such as LSTMs that explicitly decide what to remember and forget in their hidden and context layers. [ \u2022 ] Transformers are non-recurrent networks based on self-attention. A selfattention layer maps input sequences to output sequences of the same length, based on a set of attention heads that each model how the surrounding words are relevant for the processing of the current word. [ \u2022 ] A transformer block consists of a single attention layer followed by a feedforward layer with residual connections and layer normalizations following each. Transformer blocks can be stacked to make deeper and more powerful networks. [ \u2022 ] Common language-based applications for RNNs and transformers include:", "questions_and_answers": [{"answer_start": 66, "answer": "one element at a time", "question": "How are simple Recurrent Neural Networks sequences processed?"}, {"answer_start": 312, "answer": "backpropagation through time", "question": "What is BPTT?"}, {"answer_start": 426, "answer": "vanishing gradients", "question": "Why do simple recurrent networks fail on long inputs?"}, {"answer_start": 663, "answer": "self-attention", "question": "Transformers are non-recurrent networks based on what?"}, {"answer_start": 679, "answer": "A selfattention layer", "question": "What maps input sequences to output sequences of the same length?"}, {"answer_start": 897, "answer": "A transformer block", "question": "What consists of a single attention layer followed by a feedforward layer with residual connections and layer normalizations following each?"}, {"answer_start": 1053, "answer": "Transformer blocks", "question": "What can be stacked to make deeper and more powerful networks?"}, {"answer_start": 1136, "answer": "Common language-based applications", "question": "What are RNNs and transformers used for?"}]}, {"context": "-Probabilistic language modeling: assigning a probability to a sequence, or to the next element of a sequence given the preceding words. -Auto-regressive generation using a trained language model. -Sequence labeling like part-of-speech tagging, where each element of a sequence is assigned a label. -Sequence classification, where an entire text is assigned to a category, as in spam detection, sentiment analysis or topic classification.", "questions_and_answers": [{"answer_start": 46, "answer": "probability", "question": "-Probabilistic language modeling assigns what to a sequence?"}, {"answer_start": 173, "answer": "trained language model", "question": "What is used for automatic regressive generation?"}, {"answer_start": 221, "answer": "part-of-speech tagging", "question": "What is sequence labeling similar to?"}, {"answer_start": 299, "answer": "-Sequence classification", "question": "What is the term for a category where an entire text is assigned to a category?"}]}, {"context": "Influential investigations of RNNs were conducted in the context of the Parallel Distributed Processing (PDP) group at UC San Diego in the 1980's. Much of this work was directed at human cognitive modeling rather than practical NLP applications Rumelhart and McClelland 1986c McClelland and Rumelhart 1986 . Models using recurrence at the hidden layer in a feedforward network (Elman networks) were introduced by Elman (1990) . Similar architectures were investigated by Jordan (1986) with a recurrence from the output layer, and Mathis and Mozer (1995) with the addition of a recurrent context layer prior to the hidden layer. The possibility of unrolling a recurrent network into an equivalent feedforward network is discussed in (Rumelhart and McClelland, 1986c) . In parallel with work in cognitive modeling, RNNs were investigated extensively in the continuous domain in the signal processing and speech communities (Giles et al. 1994 , Robinson et al. 1996 . Schuster and Paliwal (1997) introduced bidirectional RNNs and described results on the TIMIT phoneme transcription task.", "questions_and_answers": [{"answer_start": 72, "answer": "Parallel Distributed Processing", "question": "What group at UC San Diego investigated RNNs in the 1980's?"}, {"answer_start": 181, "answer": "human cognitive modeling", "question": "Much of the work at UC San Diego in the 1980's was directed at what?"}, {"answer_start": 378, "answer": "Elman networks", "question": "What is another name for feedforward networks?"}, {"answer_start": 471, "answer": "Jordan", "question": "Who investigated RNNs with a recurrence from the output layer?"}, {"answer_start": 685, "answer": "equivalent feedforward network", "question": "What is the possibility of unrolling a recurrent network into?"}, {"answer_start": 855, "answer": "continuous domain", "question": "In what domain were RNNs investigated extensively?"}, {"answer_start": 935, "answer": "1994", "question": "When were RNNs investigated extensively in the continuous domain in the signal processing and speech communities?"}, {"answer_start": 958, "answer": "1996", "question": "When were RNNs investigated extensively in the continuous domain in the signal processing and speech communities?"}, {"answer_start": 1052, "answer": "TIMIT", "question": "What phoneme transcription task did Schuster and Paliwal describe?"}]}, {"context": "While theoretically interesting, the difficulty with training RNNs and managing context over long sequences impeded progress on practical applications. This situation changed with the introduction of LSTMs in Hochreiter and Schmidhuber (1997) and Gers et al. (2000) . Impressive performance gains were demonstrated on tasks at the boundary of signal processing and language processing including phoneme recognition (Graves and Schmidhuber, 2005) , handwriting recognition (Graves et al., 2007) and most significantly speech recognition (Graves et al., 2013b) .", "questions_and_answers": [{"answer_start": 37, "answer": "difficulty with training RNNs and managing context over long sequences", "question": "What impeded progress on practical applications?"}, {"answer_start": 237, "answer": "1997", "question": "When did Hochreiter and Schmidhuber introduce LSTMs?"}, {"answer_start": 260, "answer": "2000", "question": "In what year did Gers et al. introduce LSTMs?"}, {"answer_start": 517, "answer": "speech recognition", "question": "What was the most significant performance gain demonstrated by Gains et al., 2013b?"}]}, {"context": "Interest in applying neural networks to practical NLP problems surged with the work of Collobert and Weston (2008) and Collobert et al. (2011) . These efforts made use of learned word embeddings, convolutional networks, and end-to-end training. They demonstrated near state-of-the-art performance on a number of standard shared tasks including part-of-speech tagging, chunking, named entity recognition and semantic role labeling without the use of hand-engineered features.", "questions_and_answers": [{"answer_start": 87, "answer": "Collobert and Weston", "question": "Who did the interest in applying neural networks to practical NLP problems surge with?"}, {"answer_start": 137, "answer": "2011", "question": "When did Collobert et al. publish their work?"}, {"answer_start": 179, "answer": "word embeddings, convolutional networks, and end-to-end training", "question": "What did Collobert et al. make use of?"}, {"answer_start": 449, "answer": "hand-engineered features", "question": "What did Collobert et al. not use?"}]}, {"context": "Approaches that married LSTMs with pre-trained collections of word-embeddings based on word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) , quickly came to dominate many common tasks: part-of-speech tagging (Ling et al., 2015) , syntactic chunking (S\u00f8gaard and Goldberg, 2016), named entity recognition (Chiu and Nichols, 2016; Ma and Hovy, 2016) , opinion mining (Irsoy and Cardie, 2014), semantic role labeling (Zhou and Xu, 2015a) and AMR parsing (Foland and Martin, 2016) . As with the earlier surge of progress involving statistical machine learning, these advances were made possible by the availability of training data provided by CONLL, SemEval, and other shared tasks, as well as shared resources such as Ontonotes (Pradhan et al., 2007b), and PropBank (Palmer et al., 2005) .", "questions_and_answers": [{"answer_start": 87, "answer": "word2vec", "question": "What are pre-trained collections of word-embeddings based on?"}, {"answer_start": 733, "answer": "Ontonotes", "question": "What was the name of the shared resource used by Pradhan et al., 2007b?"}]}, {"context": "The transformer (Vaswani et al., 2017) was developed drawing on two lines of prior research: self-attention and memory networks. Encoder-decoder attention, the idea of using a soft weighting over the encodings of input words to inform a generative decoder (see Chapter 10) was developed by Graves (2013) in the context of handwriting generation, and Bahdanau et al. (2015) for MT. This idea was extended to self-attention by dropping the need for separate encoding and decoding sequences and instead seeing attention a way of weighting the tokens in collecting information passed from lower layers to higher layers (Ling et al., 2015; Cheng et al., 2016; Liu et al., 2016b) . Other aspects of the transformer, including the terminology of key, query, and value, came from memory networks, a mechanism for adding an external read-write memory to networks, by using an embedding of a query to match keys representing content in an associative memory (Sukhbaatar et al., 2015; Weston et al., 2015; Graves et al., 2014) .", "questions_and_answers": [{"answer_start": 93, "answer": "self-attention and memory networks", "question": "What two lines of prior research were used to develop the transformer?"}, {"answer_start": 174, "answer": "a soft weighting over the encodings of input words", "question": "Encoder-decoder attention is the idea of using what to inform a generative decoder?"}, {"answer_start": 366, "answer": "(2015)", "question": "When did Bahdanau develop the idea of encoding-decoder attention?"}, {"answer_start": 93, "answer": "self-attention", "question": "The idea of using a soft weighting over the encodings of input words to inform a generative decoder was extended to what"}, {"answer_start": 739, "answer": "key, query, and value", "question": "What terms were used in the transformer?"}]}, {"context": "This chapter introduces machine translation (MT), the use of computers to translate from one language to another. Of course translation, in its full generality, such as the translation of literature, or poetry, is a difficult, fascinating, and intensely human endeavor, as rich as any other area of human creativity.", "questions_and_answers": [{"answer_start": 24, "answer": "machine translation", "question": "What does MT stand for?"}, {"answer_start": 203, "answer": "poetry", "question": "What is another example of machine translation?"}]}, {"context": "Machine translation in its present form therefore focuses on a number of very practical tasks. Perhaps the most common current use of machine translation is for information access. We might want to translate some instructions on the web, information access perhaps the recipe for a favorite dish, or the steps for putting together some furniture. Or we might want to read an article in a newspaper, or get information from an online resource like Wikipedia or a government webpage in a foreign language. MT for information access is probably one of the most common uses of NLP technology, and Google Translate alone (shown above) translates hundreds of billions of words a day between over 100 languages.", "questions_and_answers": [{"answer_start": 0, "answer": "Machine translation", "question": "What focuses on a number of very practical tasks?"}, {"answer_start": 161, "answer": "information access", "question": "What is the most common current use of machine translation?"}, {"answer_start": 300, "answer": "the steps for putting together some furniture", "question": "What is a common use of machine translation?"}, {"answer_start": 447, "answer": "Wikipedia", "question": "What is an example of an online resource?"}, {"answer_start": 593, "answer": "Google Translate", "question": "What company alone translates hundreds of billions of words a day between over 100 languages?"}]}, {"context": "Another common use of machine translation is to aid human translators. MT systems are routinely used to produce a draft translation that is fixed up in a post-editing post-editing phase by a human translator. This task is often called computer-aided translation or CAT. CAT is commonly used as part of localization: the task of adapting content CAT localization or a product to a particular language community.", "questions_and_answers": [{"answer_start": 48, "answer": "aid human translators", "question": "What is another common use of machine translation?"}, {"answer_start": 71, "answer": "MT systems", "question": "What is routinely used to produce a draft translation that is fixed up in a post-editing post-editing phase by a human"}, {"answer_start": 235, "answer": "computer-aided translation", "question": "What is the term for a task that is fixed up in a post-editing post-editing phase by a human translator called?"}, {"answer_start": 302, "answer": "localization", "question": "What is the task of adapting content CAT localization or a product to a particular language community called?"}]}, {"context": "Finally, a more recent application of MT is to in-the-moment human communication needs. This includes incremental translation, translating speech on-the-fly before the entire sentence is complete, as is commonly used in simultaneous interpretation. Image-centric translation can be used for example to use OCR of the text on a phone camera image as input to an MT system to translate menus or street signs.", "questions_and_answers": [{"answer_start": 47, "answer": "in-the-moment human communication needs", "question": "What is a more recent application of MT?"}, {"answer_start": 102, "answer": "incremental translation", "question": "What is MT used for in-the-moment human communication?"}, {"answer_start": 249, "answer": "Image-centric translation", "question": "What can be used for example to use OCR of the text on a phone camera image as input to an MT system to translate menus or"}]}, {"context": "The standard algorithm for MT is the encoder-decoder network, also called the sequence to sequence network, an architecture that can be implemented with RNNs or with Transformers. We've seen in prior chapters that RNN or Transformer architecture can be used to do classification (for example to map a sentence to a positive or negative sentiment tag for sentiment analysis), or can be used to do sequence labeling (for example to assign each word in an input sentence with a part-of-speech, or with a named entity tag). For part-of-speech tagging, recall that the output tag is associated directly with each input word, and so we can just model the tag as output y t for each input word x t .", "questions_and_answers": [{"answer_start": 74, "answer": "the sequence to sequence network", "question": "What is another name for the encoder-decoder network?"}, {"answer_start": 264, "answer": "classification", "question": "What can the RNN or Transformer architecture be used for?"}, {"answer_start": 656, "answer": "output y t", "question": "For part-of-speech tagging, what is the output tag associated directly with each input word?"}]}, {"context": "Encoder-decoder or sequence-to-sequence models are used for a different kind of sequence modeling in which the output sequence is a complex function of the entire input sequencer; we must map from a sequence of input words or tokens to a sequence of tags that are not merely direct mappings from individual words.", "questions_and_answers": [{"answer_start": 0, "answer": "Encoder-decoder or sequence-to-sequence models", "question": "What are used for a different kind of sequence modeling in which the output sequence is a complex function of the entire input sequencer?"}]}, {"context": "Machine translation is exactly such a task: the words of the target language don't necessarily agree with the words of the source language in number or order. Consider translating the following made-up English sentence into Japanese. Note that the elements of the sentences are in very different places in the different languages. In English, the verb is in the middle of the sentence, while in Japanese, the verb kaita comes at the end. The Japanese sentence doesn't require the pronoun he, while English does. Such differences between languages can be quite complex. In the following actual sentence from the United Nations, notice the many changes between the Chinese sentence (we've given in in red a word-by-word gloss of the Chinese characters) and its English equivalent.", "questions_and_answers": [{"answer_start": 0, "answer": "Machine translation", "question": "What is a task where the words of the target language don't necessarily agree with the words of the source language in number or order?"}, {"answer_start": 224, "answer": "Japanese", "question": "What language is the English sentence translated into?"}, {"answer_start": 281, "answer": "very different", "question": "Where are the elements of the sentences in the different languages?"}, {"answer_start": 414, "answer": "kaita", "question": "What verb comes at the end of a Japanese sentence?"}, {"answer_start": 45, "answer": "he", "question": "What Japanese sentence doesn't require the pronoun he?"}, {"answer_start": 560, "answer": "complex", "question": "How can the differences between languages be?"}, {"answer_start": 699, "answer": "red", "question": "What color are the Chinese characters in the sentence?"}]}, {"context": "([ 10.2 ]) \u5927\u4f1a[ /General Assembly \u5728/ ]on 1982\u5e74[ /1982 12\u6708/ ]December 10\u65e5[ /10 \u901a\u8fc7 \u4e86/ ]adopted \u7b2c37\u53f7[ /37th \u51b3\u8bae/ ]resolution \uff0c\u6838\u51c6\u4e86[ /approved \u7b2c\u4e8c \u6b21/ ]second \u63a2\u7d22[ /exploration \u53ca/ ]and \u548c\u5e73peaceful \u5229\u7528[ /using \u5916\u5c42\u7a7a \u95f4/ ]outer space \u4f1a\u8bae[ /conference \u7684/ ]of \u5404\u9879[ /various \u5efa\u8bae/ ]suggestions \u3002 On 10 December 1982 , the General Assembly adopted resolution 37 in which it endorsed the recommendations of the Second United Nations Conference on the Exploration and Peaceful Uses of Outer Space .", "questions_and_answers": [{"answer_start": 385, "answer": "Second United Nations Conference on the Exploration and Peaceful Uses of Outer Space", "question": "What conference did the General Assembly endorse?"}]}, {"context": "Encoder-decoder networks are very successful at handling these sorts of complicated cases of sequence mappings. Indeed, the encoder-decoder algorithm is not just for MT; it's the state of the art for many other tasks where complex mappings between two sequences are involved. These include summarization (where we map from a long text to its summary, like a title or an abstract), dialogue (where we map from what the user said to what our dialogue system should respond), semantic parsing (where we map from a string of words to a semantic representation like logic or SQL), and many others.", "questions_and_answers": [{"answer_start": 0, "answer": "Encoder-decoder networks", "question": "What are very successful at handling these kinds of complicated cases of sequence mappings?"}, {"answer_start": 124, "answer": "encoder-decoder algorithm", "question": "What is the state of the art for many other tasks where complex mappings between two sequences are involved?"}, {"answer_start": 473, "answer": "semantic parsing", "question": "What is the process where we map from a string of words to a semantic representation like logic or SQL?"}]}, {"context": "But first, in the next section, we begin by summarizing the linguistic background to MT: key differences among languages that are important to consider when considering the task of translation.", "questions_and_answers": [{"answer_start": 89, "answer": "key differences among languages", "question": "What are important to consider when considering the task of translation?"}]}, {"context": "Some aspects of human language seem to be universal, holding true for every lanuniversal guage, or are statistical universals, holding true for most languages. Many universals arise from the functional role of language as a communicative system by humans. Every language, for example, seems to have words for referring to people, for talking about eating and drinking, for being polite or not. There are also structural linguistic universals; for example, every language seems to have nouns and verbs (Chapter 8), has ways to ask questions, or issue commands, linguistic mechanisms for indicating agreement or disagreement.", "questions_and_answers": [{"answer_start": 103, "answer": "statistical universals", "question": "What holds true for most languages?"}, {"answer_start": 224, "answer": "communicative", "question": "Many universals arise from the functional role of language as what system by humans?"}, {"answer_start": 348, "answer": "eating and drinking", "question": "What does every language talk about?"}, {"answer_start": 502, "answer": "Chapter 8", "question": "What chapter describes how every language seems to have nouns and verbs?"}]}, {"context": "Yet languages also differ in many ways, and an understanding of what causes such translation divergences will help us build better MT models. We often distin-translation divergence guish the idiosyncratic and lexical differences that must be dealt with one by one (the word for \"dog\" differs wildly from language to language), from systematic differences that we can model in a general way (many languages put the verb before the direct object; others put the verb after the direct object). The study of these systematic cross-linguistic similarities and differences is called linguistic typology. This typology section sketches some typological facts that impact machine translation; the interested reader should also look into WALS, the World Atlas of Language Structures, which gives many typological facts about languages (Dryer and Haspelmath, 2013).", "questions_and_answers": [{"answer_start": 4, "answer": "languages", "question": "What other types of languages differ in many ways?"}, {"answer_start": 332, "answer": "systematic", "question": "What type of differences can we model in a general way?"}, {"answer_start": 577, "answer": "linguistic typology", "question": "What is the study of systematic cross-linguistic similarities and differences called?"}, {"answer_start": 739, "answer": "World Atlas of Language Structures", "question": "What is WALS?"}]}, {"context": "As we hinted it in our example above comparing English and Japanese, languages differ in the basic word order of verbs, subjects, and objects in simple declarative clauses. German, French, English, and Mandarin, for example, are all SVO SVO (Subject-Verb-Object) languages, meaning that the verb tends to come between the subject and object. Hindi and Japanese, by contrast, are SOV languages, mean-SOV ing that the verb tends to come at the end of basic clauses, and Irish and Arabic are VSO languages. Two languages that share their basic word order type often have VSO other similarities. For example, VO languages generally have prepositions, whereas OV languages generally have postpositions.", "questions_and_answers": [{"answer_start": 93, "answer": "basic word order", "question": "What does English and Japanese differ in?"}, {"answer_start": 242, "answer": "Subject-Verb-Object", "question": "What does SVO stand for?"}, {"answer_start": 489, "answer": "VSO languages", "question": "What are Irish and Arabic called?"}, {"answer_start": 568, "answer": "VSO other similarities", "question": "What do two languages that share their basic word order type often have?"}, {"answer_start": 633, "answer": "prepositions", "question": "What do VO languages generally have?"}]}, {"context": "Let's look in more detail at the example we saw above. In this SVO English sentence, the verb wrote is followed by its object a letter and the prepositional phrase to a friend, in which the preposition to is followed by its argument a friend. Arabic, with a VSO order, also has the verb before the object and prepositions. By contrast, in the Japanese example that follows, each of these orderings is reversed; the verb is preceded by its arguments, and the postposition follows its argument. .1 shows examples of other word order differences. All of these word order differences between languages can cause problems for translation, requiring the system to do huge structural reorderings as it generates the output.", "questions_and_answers": [{"answer_start": 33, "answer": "example", "question": "What is the SVO English sentence that follows the verb's object a letter and the prepositional phrase to a friend?"}, {"answer_start": 63, "answer": "SVO English", "question": "In what language is the verb written followed by its object a letter and the prepositional phrase to a friend?"}, {"answer_start": 258, "answer": "VSO", "question": "What order does Arabic have?"}, {"answer_start": 343, "answer": "Japanese", "question": "In what language is the verb preceded by its arguments?"}, {"answer_start": 493, "answer": ".1", "question": "What is the number of examples of other word order differences?"}, {"answer_start": 608, "answer": "problems for translation", "question": "What can word order differences between languages cause?"}]}, {"context": "Of course we also need to translate the individual words from one language to another. For any translation, the appropriate word can vary depending on the context. The English source-language word bass, for example, can appear in Spanish as the fish lubina or the musical instrument bajo. German uses two distinct words for what in English would be called a wall: Wand for walls inside a building, and Mauer for walls outside a building. Where English uses the word brother for any male sibling, Chinese and many other languages have distinct words for older brother and younger brother (Mandarin gege and didi, respectively). In all these cases, translating bass, wall, or brother from English would require a kind of specialization, disambiguating the different uses of a word. For this reason the fields of MT and Word Sense Disambiguation (Chapter 18) are closely linked.", "questions_and_answers": [{"answer_start": 26, "answer": "translate the individual words", "question": "How do we translate words from one language to another?"}, {"answer_start": 155, "answer": "context", "question": "The appropriate word can vary depending on what?"}, {"answer_start": 197, "answer": "bass", "question": "What English source-language word can appear in Spanish as the fish lubina or the musical instrument bajo?"}, {"answer_start": 364, "answer": "Wand", "question": "What is the German word for walls inside a building?"}, {"answer_start": 402, "answer": "Mauer", "question": "What is the German word for walls outside a building?"}, {"answer_start": 466, "answer": "brother", "question": "What word does English use for any male sibling?"}, {"answer_start": 709, "answer": "a kind of specialization", "question": "What would be required to translate a word from English to Chinese?"}, {"answer_start": 810, "answer": "MT and Word Sense Disambiguation", "question": "What two fields are closely linked?"}]}, {"context": "Sometimes one language places more grammatical constraints on word choice than another. We saw above that English marks nouns for whether they are singular or plural. Mandarin doesn't. Or French and Spanish, for example, mark grammatical gender on adjectives, so an English translation into French requires specifying adjective gender.", "questions_and_answers": [{"answer_start": 35, "answer": "grammatical", "question": "What kind of constraints do some languages place on word choice?"}, {"answer_start": 130, "answer": "whether they are singular or plural", "question": "What does English mark nouns for?"}, {"answer_start": 167, "answer": "Mandarin", "question": "Which language doesn't mark nouns for whether they are singular or plural?"}, {"answer_start": 188, "answer": "French and Spanish", "question": "Which languages mark grammatical gender on adjectives?"}]}, {"context": "Morphologically, languages are often characterized along two dimensions of variation. The first is the number of morphemes per word, ranging from isolating isolating languages like Vietnamese and Cantonese, in which each word generally has one morpheme, to polysynthetic languages like Siberian Yupik (\"Eskimo\"), in which a polysynthetic single word may have very many morphemes, corresponding to a whole sentence in English. The second dimension is the degree to which morphemes are segmentable, ranging from agglutinative languages like Turkish, in which morphemes have relagglutinative atively clean boundaries, to fusion languages like Russian, in which a single affix fusion may conflate multiple morphemes, like -om in the word stolom (table-SG-INSTR-DECL1), which fuses the distinct morphological categories instrumental, singular, and first declension. Translating between languages with rich morphology requires dealing with structure below the word level, and for this reason modern systems generally use subword models like the wordpiece or BPE models of Section [ 10.7 ].1.", "questions_and_answers": [{"answer_start": 0, "answer": "Morphologically", "question": "How are languages often characterized along two dimensions of variation?"}, {"answer_start": 103, "answer": "number of morphemes per word", "question": "What is the first dimension of variation?"}, {"answer_start": 510, "answer": "agglutinative", "question": "What kind of languages are morphemes segmentable?"}, {"answer_start": 484, "answer": "segmentable", "question": "What is the degree to which morphemes are?"}, {"answer_start": 1015, "answer": "subword models", "question": "What do modern systems use to deal with structure below the word level?"}]}, {"context": "Finally, languages vary along a typological dimension related to the things they tend to omit. Some languages, like English, require that we use an explicit pronoun when talking about a referent that is given in the discourse. In other languages, however, we can sometimes omit pronouns altogether, as the following example from Spanish shows 1 : ([ 10.6 ]) [El jefe] i dio con un libro. / 0 i Mostr\u00f3 a un descifrador ambulante. [The boss] came upon a book. [He] showed it to a wandering decoder.", "questions_and_answers": [{"answer_start": 32, "answer": "typological", "question": "Languages vary along what dimension related to the things they tend to omit?"}, {"answer_start": 116, "answer": "English", "question": "What language requires that we use an explicit pronoun when talking about a referent that is given in the discourse?"}, {"answer_start": 273, "answer": "omit pronouns altogether", "question": "What can we sometimes do in other languages?"}, {"answer_start": 351, "answer": "0", "question": "What is the number of pronouns that mostr\u00f3 a descifrador ambulante?"}, {"answer_start": 450, "answer": "a book", "question": "What did the boss come upon?"}, {"answer_start": 478, "answer": "wandering", "question": "What type of decoder did the boss show the book to?"}]}, {"context": "Translating from languages with extensive pro-drop, like Chinese or Japanese, to non-pro-drop languages like English can be difficult since the model must somehow identify each zero and recover who or what is being talked about in order to insert the proper pronoun.", "questions_and_answers": [{"answer_start": 57, "answer": "Chinese or Japanese", "question": "What are two examples of languages with extensive pro-drop?"}, {"answer_start": 109, "answer": "English", "question": "What is a non-pro-drop language?"}]}, {"context": "Encoder-decoder networks, or sequence-to-sequence networks, are models ca-encoderdecoder pable of generating contextually appropriate, arbitrary length, output sequences. Encoder-decoder networks have been applied to a very wide range of applications including machine translation, summarization, question answering, and dialogue.", "questions_and_answers": [{"answer_start": 29, "answer": "sequence-to-sequence networks", "question": "What are encoder-decoder networks?"}, {"answer_start": 261, "answer": "machine translation, summarization, question answering, and dialogue", "question": "Encoder-decoder networks have been applied to a wide range of applications including what?"}]}, {"context": "The key idea underlying these networks is the use of an encoder network that takes an input sequence and creates a contextualized representation of it, often called the context. This representation is then passed to a decoder which generates a taskspecific output sequence. Figure 10 .3 illustrates the architecture Encoder-decoder networks consist of three components:", "questions_and_answers": [{"answer_start": 165, "answer": "the context", "question": "What is a contextualized representation of an encoder network called?"}, {"answer_start": 216, "answer": "a decoder", "question": "What generates a taskspecific output sequence?"}, {"answer_start": 352, "answer": "three", "question": "How many components are in Encoder-decoder networks?"}]}, {"context": "[ 3. ] A decoder, which accepts c as input and generates an arbitrary length sequence of hidden states h m 1 , from which a corresponding sequence of output states y m 1 , can be obtained. Just as with encoders, decoders can be realized by any kind of sequence architecture.", "questions_and_answers": [{"answer_start": 0, "answer": "[ 3. ]", "question": "A decoder that accepts c as input and generates an arbitrary length sequence of hidden states h m 1 can be obtained?"}, {"answer_start": 11, "answer": "c", "question": "What accepts c as input and generates an arbitrary length sequence of hidden states h m 1?"}, {"answer_start": 164, "answer": "y m 1", "question": "A decoder that accepts c as input and generates an arbitrary length sequence of hidden states h m 1 can be obtained from"}, {"answer_start": 103, "answer": "h m 1", "question": "What is the arbitrary length sequence of hidden states generated by a decoder?"}, {"answer_start": 164, "answer": "y m 1", "question": "A decoder that accepts c as input and generates an arbitrary length sequence of hidden states h m 1 can be obtained from"}, {"answer_start": 240, "answer": "any kind of sequence architecture", "question": "How can decoders be realized?"}]}, {"context": "Let's begin by describing an encoder-decoder network based on a pair of RNNs. 2 Recall the conditional RNN language model from Chapter 9 for computing p(y), the probability of a sequence y. Like any language model, we can break down the probability as follows:", "questions_and_answers": [{"answer_start": 29, "answer": "encoder-decoder network", "question": "What is based on a pair of RNNs?"}, {"answer_start": 157, "answer": "the probability of a sequence y", "question": "What is p(y)?"}, {"answer_start": 249, "answer": "as follows", "question": "How can we break down the probability of a sequence y?"}]}, {"context": "At a particular time t, we pass the prefix of t \u2212 1 tokens through the language model, using forward inference to produce a sequence of hidden states, ending with the hidden state corresponding to the last word of the prefix. We then use the final hidden state of the prefix as our starting point to generate the next token.", "questions_and_answers": [{"answer_start": 93, "answer": "forward inference", "question": "What is used to produce a sequence of hidden states?"}, {"answer_start": 238, "answer": "the final hidden state of the prefix", "question": "What is used as our starting point to generate the next token?"}]}, {"context": "More formally, if g is an activation function like tanh or ReLU, a function of the input at time t and the hidden state at time t \u2212 1, and f is a softmax over the set of possible vocabulary items, then at time t the output y t and hidden state h t are computed as:", "questions_and_answers": [{"answer_start": 5, "answer": "f", "question": "What is a softmax over the set of possible vocabulary items?"}, {"answer_start": 18, "answer": "g", "question": "What is an activation function like tanh or ReLU?"}]}, {"context": "hidden state of the decoder. That is, the first decoder RNN cell uses c as its prior hidden state h d 0 . The decoder autoregressively generates a sequence of outputs, an element at a time, until an end-of-sequence marker is generated. Each hidden state is conditioned on the previous hidden state and the output generated in the previous state. Figure 10 .6 Allowing every hidden state of the decoder (not just the first decoder state) to be influenced by the context c produced by the encoder.", "questions_and_answers": [{"answer_start": 0, "answer": "hidden state", "question": "What state of the decoder is the first decoder RNN cell using c as its prior hidden state h d 0?"}, {"answer_start": 22, "answer": "c", "question": "The first decoder uses what as its prior hidden state h d 0?"}, {"answer_start": 196, "answer": "an end-of-sequence marker", "question": "What is generated when the decoder generates a sequence of outputs?"}, {"answer_start": 276, "answer": "previous hidden state", "question": "Each hidden state is conditioned on what?"}, {"answer_start": 461, "answer": "context c produced by the encoder", "question": "What influences every hidden state of the decoder?"}]}, {"context": "One weakness of this approach as described so far is that the influence of the context vector, c, will wane as the output sequence is generated. A solution is to make the context vector c available at each step in the decoding process by adding it as a parameter to the computation of the current hidden state, using the following equation (illustrated in Figure [ 10.6 ] ):", "questions_and_answers": [{"answer_start": 58, "answer": "the influence of the context vector, c", "question": "What will wane as the output sequence is generated?"}, {"answer_start": 235, "answer": "by adding it as a parameter", "question": "How is the context vector c made available at each step in the decoding process?"}]}, {"context": "Now we're ready to see the full equations for this version of the decoder in the basic encoder-decoder model, with context available at each decoding timestep. Recall that g is a stand-in for some flavor of RNN and\u0177 t\u22121 is the embedding for the output sampled from the softmax at the previous step:", "questions_and_answers": [{"answer_start": 87, "answer": "encoder-decoder model", "question": "In what model are the full equations for this version of the decoder?"}, {"answer_start": 148, "answer": "g", "question": "What is a stand-in for some flavor of RNN?"}]}, {"context": "Finally, as shown earlier, the output y at each time step consists of a softmax computation over the set of possible outputs (the vocabulary, in the case of language modeling or MT). We compute the most likely output at each time step by taking the argmax over the softmax output:", "questions_and_answers": [{"answer_start": 126, "answer": "the vocabulary", "question": "What is the set of possible outputs in the case of language modeling or MT?"}, {"answer_start": 178, "answer": "MT", "question": "What is another name for language modeling?"}, {"answer_start": 249, "answer": "argmax", "question": "What is taken over the softmax output to compute the most likely output at each time step?"}]}, {"context": "Encoder-decoder architectures are trained end-to-end, just as with the RNN language models of Chapter 9. Each training example is a tuple of paired strings, a source and a target. Concatenated with a separator token, these source-target pairs can now serve as training data.", "questions_and_answers": [{"answer_start": 0, "answer": "Encoder-decoder architectures", "question": "What are trained end-to-end, just like with the RNN language models of Chapter 9?"}, {"answer_start": 141, "answer": "paired strings", "question": "Each training example is a tuple of what?"}, {"answer_start": 223, "answer": "source-target pairs", "question": "What pairs can now serve as training data?"}]}, {"context": "For MT, the training data typically consists of sets of sentences and their translations. These can be drawn from standard datasets of aligned sentence pairs, as we'll discuss in Section [ 10.7 ].2. Once we have a training set, the training itself proceeds as with any RNN-based language model. The network is given the source text and then starting with the separator token is trained autoregressively to predict the next word, as shown in Figure [ 10.7 ] .", "questions_and_answers": [{"answer_start": 48, "answer": "sets of sentences and their translations", "question": "What does the training data typically consist of?"}, {"answer_start": 135, "answer": "aligned sentence pairs", "question": "What can be drawn from standard datasets?"}, {"answer_start": 269, "answer": "RNN", "question": "The training itself proceeds as with what based language model?"}, {"answer_start": 295, "answer": "The network", "question": "Who is given the source text?"}]}, {"context": "Total loss is the average cross-entropy loss per target word: Figure 10 .7 Training the basic RNN encoder-decoder approach to machine translation. Note that in the decoder we usually don't propagate the model's softmax outputs\u0177 t , but use teacher forcing to force each input to the correct gold value for training. We compute the softmax output distribution over\u0177 in the decoder in order to compute the loss at each token, which can then be averaged to compute a loss for the sentence.", "questions_and_answers": [{"answer_start": 0, "answer": "Total loss", "question": "What is the average cross-entropy loss per target word?"}, {"answer_start": 240, "answer": "teacher forcing", "question": "What is used to force each input to the correct gold value for training?"}, {"answer_start": 392, "answer": "compute the loss at each token", "question": "What is the purpose of computing the softmax output distribution over in the decoder?"}]}, {"context": "The simplicity of the encoder-decoder model is its clean separation of the encoder -which builds a representation of the source text -from the decoder, which uses this context to generate a target text. In the model as we've described it so far, this context vector is h n , the hidden state of the last (nth) time step of the source text. This final hidden state is thus acting as a bottleneck: it must represent absolutely everything about the meaning of the source text, since the only thing the decoder knows about the source text is what's in this context vector (Figure [ 10.8 ]) . Information at the beginning of the sentence, especially for long sentences, may not be equally well represented in the context vector.", "questions_and_answers": [{"answer_start": 22, "answer": "encoder-decoder model", "question": "The simplicity of what model is due to its clean separation of the encoder from the decoder?"}, {"answer_start": 269, "answer": "h n", "question": "What is the hidden state of the last (nth) time step of the source text?"}, {"answer_start": 396, "answer": "it must represent absolutely everything", "question": "What is the final hidden state of the last (nth) time step of the source text?"}, {"answer_start": 588, "answer": "Information at the beginning of the sentence", "question": "What may not be equally well represented in the context vector?"}]}, {"context": "The attention mechanism is a solution to the bottleneck problem, a way of attention mechanism allowing the decoder to get information from all the hidden states of the encoder, not just the last hidden state.", "questions_and_answers": [{"answer_start": 0, "answer": "The attention mechanism", "question": "What is a solution to the bottleneck problem?"}]}, {"context": "Encoder Decoder bottleneck bottleneck Figure 10 .8 Requiring the context c to be only the encoder's final hidden state forces all the information from the entire source sentence to pass through this representational bottleneck.", "questions_and_answers": [{"answer_start": 0, "answer": "Encoder Decoder", "question": "What bottleneck bottleneck does the context c have to be only the encoder's final hidden state?"}]}, {"context": "input, we can't use the entire tensor of encoder hidden state vectors directly as the context for the decoder. The idea of attention is instead to create the single fixed-length vector c by taking a weighted sum of all the encoder hidden states. The weights focus on ('attend to') a particular part of the source text that is relevant for the token the decoder is currently producing. Attention thus replaces the static context vector with one that is dynamically derived from the encoder hidden states, different for each token in decoding.", "questions_and_answers": [{"answer_start": 41, "answer": "encoder hidden state vectors", "question": "Input, we can't use the entire tensor of what directly as the context for the decoder?"}, {"answer_start": 187, "answer": "by taking a weighted sum of all the encoder hidden states", "question": "How does attention create the single fixed-length vector c?"}, {"answer_start": 281, "answer": "a particular part of the source text", "question": "What do the weights focus on that is relevant for the token the decoder is currently producing?"}, {"answer_start": 385, "answer": "Attention", "question": "What replaces the static context vector with one that is dynamically derived from the encoder hidden states?"}]}, {"context": "This context vector, c i , is generated anew with each decoding step i and takes all of the encoder hidden states into account in its derivation. We then make this context available during decoding by conditioning the computation of the current decoder hidden state on it (along with the prior hidden state and the previous output generated by the decoder), as we see in this equation (and Figure [ 10.9 ] ): Figure 10 .9 The attention mechanism allows each hidden state of the decoder to see a different, dynamic, context, which is a function of all the encoder hidden states.", "questions_and_answers": [{"answer_start": 21, "answer": "c i", "question": "What is the context vector that is generated anew with each decoding step i?"}, {"answer_start": 198, "answer": "by conditioning the computation of the current decoder hidden state on it", "question": "How do we make this context available during decoding?"}]}, {"context": "The first step in computing c i is to compute how much to focus on each encoder state, how relevant each encoder state is to the decoder state captured in h d i\u22121 . We capture relevance by computing-at each state i during decoding-a score(h d i\u22121 , h e j ) for each encoder state j.", "questions_and_answers": [{"answer_start": 38, "answer": "compute how much to focus on each encoder state", "question": "What is the first step in computing c i?"}, {"answer_start": 189, "answer": "computing-at each state i during decoding-a score", "question": "How do we capture relevance?"}]}, {"context": "The score that results from this dot product is a scalar that reflects the degree of similarity between the two vectors. The vector of these scores across all the encoder hidden states gives us the relevance of each encoder state to the current step of the decoder.", "questions_and_answers": [{"answer_start": 50, "answer": "scalar", "question": "What is the score that results from this dot product?"}, {"answer_start": 194, "answer": "the relevance of each encoder state to the current step of the decoder", "question": "The vector of these scores across all encoder hidden states gives us what?"}]}, {"context": "Finally, given the distribution in \u03b1, we can compute a fixed-length context vector for the current decoder state by taking a weighted average over all the encoder hidden states. [ 10.17 ]) With this, we finally have a fixed-length context vector that takes into account information from the entire encoder state that is dynamically updated to reflect the needs of the decoder at each step of decoding. Figure 10 .10 illustrates an encoderdecoder network with attention, focusing on the computation of one context vector c i .", "questions_and_answers": [{"answer_start": 116, "answer": "taking a weighted average over all the encoder hidden states", "question": "How can we compute a fixed-length context vector for the current decoder state?"}, {"answer_start": 251, "answer": "takes into account information from the entire encoder state that is dynamically updated to reflect the needs of the decoder at each step of decoding", "question": "What does a fixed-length context vector do?"}, {"answer_start": 501, "answer": "one", "question": "How many context vectors does Figure 10.10 focus on?"}]}, {"context": "information from the entire encoder state that is dynamically updated to reflect the", "questions_and_answers": [{"answer_start": 17, "answer": "the entire encoder state", "question": "What part of the encoder is dynamically updated to reflect the changes in information?"}, {"answer_start": 50, "answer": "dynamically updated", "question": "how is information from the entire encoder state updated?"}]}, {"context": "decoder network with attention, focusing on the computation of one context vector", "questions_and_answers": [{"answer_start": 48, "answer": "computation of one context vector", "question": "What is the focus of the decoder network?"}]}, {"context": "Figure 10 .10 A sketch of the encoder-decoder network with attention, focusing on the computation of c i . The context value c i is one of the inputs to the computation of h d i . It is computed by taking the weighted sum of all the encoder hidden states, each weighted by their dot product with the prior decoder hidden state h d i\u22121 .", "questions_and_answers": [{"answer_start": 86, "answer": "computation of c i", "question": "A sketch of the encoder-decoder network with attention, focusing on what?"}, {"answer_start": 111, "answer": "context value", "question": "What is one of the inputs to the computation of h d i?"}, {"answer_start": 195, "answer": "by taking the weighted sum of all the encoder hidden states", "question": "How is the context value c i computed?"}]}, {"context": "It's also possible to create more sophisticated scoring functions for attention models. Instead of simple dot product attention, we can get a more powerful function that computes the relevance of each encoder hidden state to the decoder hidden state by parameterizing the score with its own set of weights, W s .", "questions_and_answers": [{"answer_start": 48, "answer": "scoring functions", "question": "What is it possible to create more sophisticated for attention models?"}, {"answer_start": 250, "answer": "by parameterizing the score with its own set of weights", "question": "How can we get a more powerful function that computes the relevance of each encoder hidden state to the decoder hidden state?"}]}, {"context": "The weights W s , which are then trained during normal end-to-end training, give the network the ability to learn which aspects of similarity between the decoder and encoder states are important to the current application. This bilinear model also allows the encoder and decoder to use different dimensional vectors, whereas the simple dot-product attention requires the encoder and decoder hidden states have the same dimensionality.", "questions_and_answers": [{"answer_start": 0, "answer": "The weights", "question": "What gives the network the ability to learn which aspects of similarity between the decoder and encoder states are important to the current application?"}, {"answer_start": 228, "answer": "bilinear model", "question": "What model allows the encoder and decoder to use different dimensional vectors?"}]}, {"context": "The decoding algorithm we gave above for generating translations has a problem (as does the autoregressive generation we introduced in Chapter 9 for generating from a conditional language model). Recall that algorithm: at each time step in decoding, the output y t is chosen by computing a softmax over the set of possible outputs (the vocabulary, in the case of language modeling or MT), and then choosing the highest probability token (the argmax):", "questions_and_answers": [{"answer_start": 4, "answer": "decoding algorithm", "question": "What did we give above for generating translations?"}, {"answer_start": 438, "answer": "the argmax", "question": "What is the highest probability token?"}, {"answer_start": 332, "answer": "the vocabulary", "question": "What is the set of possible outputs in the case of language modeling or MT?"}]}, {"context": "Recall from Chapter 8 that for part-of-speech tagging we used dynamic programming search (the Viterbi algorithm) to address this problem. Unfortunately, dynamic programming is not applicable to generation problems with long-distance dependencies between the output decisions. The only method guaranteed to find the best solution is exhaustive search: computing the probability of every one of the V T possible sentences (for some length value T ) which is obviously too slow.", "questions_and_answers": [{"answer_start": 94, "answer": "Viterbi algorithm", "question": "What is the name of the dynamic programming search used for part-of-speech tagging?"}, {"answer_start": 219, "answer": "long-distance dependencies between the output decisions", "question": "Dynamic programming is not applicable to generation problems with what?"}, {"answer_start": 332, "answer": "exhaustive search", "question": "What is the only method guaranteed to find the best solution to part-of-speech tagging?"}]}, {"context": "Instead, decoding in MT and other sequence generation problems generally uses a method called beam search. In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step. This fixed-size memory footprint k is called the beam width, on the metaphor of a flashlight beam beam width that can be parameterized to be wider or narrower.", "questions_and_answers": [{"answer_start": 94, "answer": "beam search", "question": "What is the method used for decoding in MT and other sequence generation problems?"}, {"answer_start": 208, "answer": "k possible tokens", "question": "In beam search, instead of choosing the best token beam search to generate at each step, we keep what at each step?"}, {"answer_start": 285, "answer": "the beam width", "question": "What is the fixed-size memory footprint k called?"}]}, {"context": "Thus at the first step of decoding, we compute a softmax over the entire vocabulary, assigning a probability to each word. We then select the k-best options from this softmax output. These initial k outputs are the search frontier and these k initial words are called hypotheses. A hypothesis is an output sequence, a translation-sofar, together with its probability. Figure 10 .12 Beam search decoding with a beam width of k = 2. At each time step, we choose the k best hypotheses, compute the V possible extensions of each hypothesis, score the resulting k * V possible hypotheses and choose the best k to continue. At time 1, the frontier is filled with the best 2 options from the initial state of the decoder: arrived and the. We then extend each of those, compute the probability of all the hypotheses so far (arrived the, arrived aardvark, the green, the witch) and compute the best 2 (in this case the green and the witch) to be the search frontier to extend on the next step. On the arcs we show the decoders that we run to score the extension words (although for simplicity we haven't shown the context value c i that is input at each step).", "questions_and_answers": [{"answer_start": 97, "answer": "probability", "question": "At the first step of decoding, we compute a softmax over the entire vocabulary, assigning a what to each word?"}, {"answer_start": 142, "answer": "k-best options", "question": "What do we select from the softmax output?"}, {"answer_start": 268, "answer": "hypotheses", "question": "What are the k initial words called?"}, {"answer_start": 296, "answer": "an output sequence, a translation-sofar, together with its probability", "question": "What is a hypothesis?"}, {"answer_start": 424, "answer": "k = 2", "question": "What is the beam width of Beam search decoding?"}, {"answer_start": 464, "answer": "k best hypotheses", "question": "What do we choose at each time step?"}, {"answer_start": 715, "answer": "arrived and the", "question": "What are the best 2 options from the initial state of the decoder?"}, {"answer_start": 657, "answer": "the best 2", "question": "What is the search frontier to extend on the next step?"}, {"answer_start": 1119, "answer": "c i", "question": "What is the context value that is input at each step of decoding?"}]}, {"context": ";initial state frontier \u2190 state ;initial frontier while frontier contains incomplete paths and beamwidth > 0 extended frontier \u2190 for each state \u2208 frontier do y \u2190 DECODE(state) for each word i \u2208 Vocabulary do successor \u2190 NEWSTATE(state, i, y i ) new agenda \u2190 ADDTOBEAM(successor, extended frontier, beam width)", "questions_and_answers": [{"answer_start": 258, "answer": "ADDTOBEAM", "question": "What is the acronym for successor, extended frontier, beam width?"}]}, {"context": "for each state in extended frontier do if state is complete do complete paths \u2190 APPEND(complete paths, state) extended frontier \u2190 REMOVE(extended frontier, state) beam width \u2190 beam width -1 frontier \u2190 extended frontier to apply some form of length normalization to each of the hypotheses, for example simply dividing the negative log probability by the number of words:", "questions_and_answers": [{"answer_start": 130, "answer": "REMOVE", "question": "What does extended frontier do if state is complete?"}, {"answer_start": 39, "answer": "if state is complete", "question": "What do complete paths do for each state in extended frontier?"}]}, {"context": "Beam search is common in large production MT systems, generally with beam widths k between 5 and 10. What do we do with the resulting k hypotheses? In some cases, all we need from our MT algorithm is the single best hypothesis, so we can return that. In other cases our downstream application might want to look at all k hypotheses, so we can pass them all (or a subset) to the downstream application with their respective scores.", "questions_and_answers": [{"answer_start": 81, "answer": "k between 5 and 10", "question": "What are the beam widths in large production MT systems?"}, {"answer_start": 134, "answer": "k hypotheses", "question": "What do we do with the resulting beam search?"}, {"answer_start": 200, "answer": "the single best hypothesis", "question": "In some cases, all we need from our MT algorithm is what?"}, {"answer_start": 315, "answer": "all k hypotheses", "question": "What might our downstream application want to look at?"}]}, {"context": "But the components of the architecture differ somewhat from the RNN and also from the transformer block we've seen. First, in order to attend to the source language, the transformer blocks in the decoder has an extra cross-attention layer. Recall that the transformer block of Chapter 9 consists of a self-attention layer that attends to the input from the previous layer, followed by layer norm, a feed forward layer, and another layer norm. The decoder transformer block includes an extra layer with a special kind of attention, cross-attention (also sometimes called cross-attention encoder-decoder attention or source attention). Cross-attention has the same form as the multi-headed self-attention in a normal transformer block, except that while the queries as usual come from the previous layer of the decoder, the keys and values come from the output of the encoder.", "questions_and_answers": [{"answer_start": 60, "answer": "the RNN", "question": "The components of the architecture differ somewhat from what?"}, {"answer_start": 211, "answer": "extra cross-attention layer", "question": "What do the transformer blocks in the decoder have in order to attend to the source language?"}, {"answer_start": 301, "answer": "self-attention layer", "question": "What does the transformer block of Chapter 9 consist of?"}, {"answer_start": 570, "answer": "cross-attention encoder-decoder attention or source attention", "question": "What is another name for cross-attention?"}, {"answer_start": 848, "answer": "the output of the encoder", "question": "Where do the keys and values come from?"}]}, {"context": "That is, the final output of the encoder H enc = h 1 , ..., h t is multiplied by the cross-attention layer's key weights W K and value weights W V , but the output from the prior decoder layer H dec [i\u22121] is multiplied by the cross-attention layer's query weights W Q : Figure 10 .16 The transformer block for the encoder and the decoder. Each decoder block has an extra cross-attention layer, which uses the output of the final encoder layer H enc = h 1 , ..., h t to produce its key and value vectors.", "questions_and_answers": [{"answer_start": 81, "answer": "the cross-attention layer's key weights W K and value weights W V", "question": "What is multiplied by the final output of the encoder H enc = h 1,..., h t?"}, {"answer_start": 362, "answer": "an extra cross-attention layer", "question": "What does each decoder block have?"}]}, {"context": "The cross attention thus allows the decoder to attend to each of the source language words as projected into the the entire encoder final output representations. The other attention layer in each decoder block, the self-attention layer, is the same causal (leftto-right) self-attention that we saw in Chapter 9. The self-attention in the encoder, however, is allowed to look ahead at the entire source language text.", "questions_and_answers": [{"answer_start": 4, "answer": "cross attention", "question": "What allows the decoder to attend to each of the source language words as projected into the entire encoder final output representations?"}, {"answer_start": 211, "answer": "the self-attention layer", "question": "What is the other attention layer in each decoder block?"}, {"answer_start": 370, "answer": "look ahead", "question": "What is the self-attention in the encoder allowed to do?"}]}, {"context": "In training, just as for RNN encoder-decoders, we use teacher forcing, and train autoregressively, at each time step predicting the next token in the target language, using cross-entropy loss.", "questions_and_answers": [{"answer_start": 54, "answer": "teacher forcing", "question": "What do we use in training RNN encoder-decoders?"}, {"answer_start": 173, "answer": "cross-entropy loss", "question": "What is used to predict the next token in the target language?"}]}, {"context": "Machine translation systems generally use a fixed vocabulary, A common way to generate this vocabulary is with the BPE or wordpiece algorithms sketched in Chapwordpiece ter 2. Generally a shared vocabulary is used for the source and target languages, which makes it easy to copy tokens (like names) from source to target, so we build the wordpiece/BPE lexicon on a corpus that contains both source and target language data. Wordpieces use a special symbol at the beginning of each token; here's a resulting tokenization from the Google MT system (Wu et al., 2016):", "questions_and_answers": [{"answer_start": 155, "answer": "Chapwordpiece ter 2", "question": "Where are the BPE or wordpiece algorithms sketched?"}, {"answer_start": 188, "answer": "shared vocabulary", "question": "What is used for the source and target languages?"}, {"answer_start": 439, "answer": "a special symbol", "question": "What do wordpieces use at the beginning of each token?"}]}, {"context": "Jet makers feud over seat width with big orders at stake wordpieces: J et makers fe ud over seat width with big orders at stake", "questions_and_answers": [{"answer_start": 0, "answer": "Jet makers", "question": "Who feuds over seat width with big orders at stake wordpieces?"}]}, {"context": "We gave the BPE algorithm in detail in Chapter 2; here are more details on the wordpiece algorithm, which is given a training corpus and a desired vocabulary size and proceeds as follows:", "questions_and_answers": [{"answer_start": 115, "answer": "a training corpus and a desired vocabulary size", "question": "What is given to the wordpiece algorithm?"}, {"answer_start": 39, "answer": "Chapter 2", "question": "Where did we give the BPE algorithm in detail?"}]}, {"context": "(a) Train an n-gram language model on the training corpus, using the current set of wordpieces. (b) Consider the set of possible new wordpieces made by concatenating two wordpieces from the current lexicon. Choose the one new wordpiece that most increases the language model probability of the training corpus.", "questions_and_answers": [{"answer_start": 4, "answer": "Train an n-gram language model", "question": "What can be done on the training corpus?"}, {"answer_start": 152, "answer": "concatenating two wordpieces", "question": "How are new wordpieces made?"}, {"answer_start": 246, "answer": "increases", "question": "What effect does the new wordpiece make on the language model probability of the training corpus?"}]}, {"context": "Machine translation models are trained on a parallel corpus, sometimes called a parallel corpus bitext, a text that appears in two (or more) languages. Large numbers of parallel corpora are available. Some are governmental; the Europarl corpus (Koehn,", "questions_and_answers": [{"answer_start": 42, "answer": "a parallel corpus", "question": "Machine translation models are trained on what?"}, {"answer_start": 78, "answer": "a parallel corpus bitext", "question": "What is another name for a parallel corpus?"}, {"answer_start": 152, "answer": "Large numbers", "question": "How many parallel corpora are available?"}, {"answer_start": 210, "answer": "governmental", "question": "Some parallel corpora are what?"}]}, {"context": "[ \u2022 ] a cost function that takes a span of source sentences and a span of target sentences and returns a score measuring how likely these spans are to be translations. [ \u2022 ] an alignment algorithm that takes these scores to find a good alignment between the documents.", "questions_and_answers": [{"answer_start": 6, "answer": "a cost function", "question": "What takes a span of source sentences and a span of target sentences and returns a score measuring how likely these spans are to be translations"}, {"answer_start": 177, "answer": "alignment algorithm", "question": "What algorithm takes these scores to find a good alignment between documents?"}]}, {"context": "Since it is possible to induce multilingual sentence embeddings (Artetxe and Schwenk, 2019), cosine similarity of such embeddings provides a natural scoring function (Schwenk, 2018) . Thompson and Koehn (2019) give the following cost function between two sentences or spans x,y from the source and target documents respectively: c(x, y) =", "questions_and_answers": [{"answer_start": 149, "answer": "scoring function", "question": "What does cosine similarity of multilingual sentence embeddings provide?"}, {"answer_start": 329, "answer": "c(x, y)", "question": "What is the cost function between two sentences?"}]}, {"context": "(1 \u2212 cos(x, y))nSents(x) nSents(y) where nSents() gives the number of sentences (this biases the metric toward many alignments of single sentences instead of aligning very large spans). The denominator helps to normalize the similarities, and so x 1 , ..., x S , y 1 , ..., y S , are randomly selected sentences sampled from the respective documents. Usually dynamic programming is used as the alignment algorithm (Gale and Church, 1993), in a simple extension of the minimum edit distance algorithm we introduced in Chapter 2.", "questions_and_answers": [{"answer_start": 41, "answer": "nSents()", "question": "What gives the number of sentences?"}, {"answer_start": 186, "answer": "The denominator", "question": "What helps to normalize the similarities?"}, {"answer_start": 359, "answer": "dynamic programming", "question": "What is used as the alignment algorithm?"}]}, {"context": "Figure 10 .17 A sample alignment between sentences in English and French, with sentences extracted from Antoine de Saint-Exupery's Le Petit Prince and a hypothetical translation. Sentence alignment takes sentences e 1 , ..., e n , and f 1 , ..., f n and finds minimal sets of sentences that are translations of each other, including single sentence mappings like (e 1 ,f 1 ), (e 4 -f 3 ), (e 5 -f 4 ), (e 6 -f 6 ) as well as 2-1 alignments (e 2 [ /e 3 ,f 2 ), (e 7 / ]e 8 -f 7 ), and null alignments (f 5 ).", "questions_and_answers": [{"answer_start": 131, "answer": "Le Petit Prince", "question": "What is the title of Antoine de Saint-Exupery's book?"}, {"answer_start": 425, "answer": "2-1", "question": "What type of alignments are found between sentences in English and French?"}]}, {"context": "Finally, it's helpful to do some corpus cleanup by removing noisy sentence pairs. This can involve handwritten rules to remove low-precision pairs (for example removing sentences that are too long, too short, have different URLs, or even pairs that are too similar, suggesting that they were copies rather than translations). Or pairs can be ranked by their multilingual embedding cosine score and low-scoring pairs discarded.", "questions_and_answers": [{"answer_start": 33, "answer": "corpus cleanup", "question": "What is it helpful to do by removing noisy sentence pairs?"}, {"answer_start": 99, "answer": "handwritten", "question": "What type of rules can be used to remove low-precision pairs?"}, {"answer_start": 358, "answer": "multilingual embedding cosine score", "question": "What can pairs be ranked by?"}]}, {"context": "We're often short of data for training MT models, since parallel corpora may be limited for particular languages or domains. However, often we can find a large monolingual corpus, to add to the smaller parallel corpora that are available.", "questions_and_answers": [{"answer_start": 56, "answer": "parallel", "question": "What type of corpora may be limited for particular languages or domains?"}, {"answer_start": 160, "answer": "monolingual", "question": "What type of corpus can we find to add to the smaller parallel corpora that are available?"}]}, {"context": "Backtranslation is a way of making use of monolingual corpora in the target backtranslation language by creating synthetic bitexts. In backtranslation, we train an intermediate target-to-source MT system on the small bitext to translate the monolingual target data to the source language. Now we can add this synthetic bitext (natural target sentences, aligned with MT-produced source sentences) to our training data, and retrain our source-to-target MT model. For example suppose we want to translate from Navajo to English but only have a small Navajo-English bitext, although of course we can find lots of monolingual English data. We use the small bitext to build an MT engine going the other way (from English to Navajo). Once we translate the monolingual English text to Navajo, we can add this synthetic Navajo/English bitext to our training data. Backtranslation has various parameters. One is how we generate the backtranslated data; we can run the decoder in greedy inference, or use beam search. Or we can do sampling, or Monte Carlo search. In Monte Carlo decoding, at each Monte Carlo search timestep, instead of always generating the word with the highest softmax probability, we roll a weighted die, and use it to choose the next word according to its [ 10.8 ] [ \u2022 ] MT EVALUATION 227 softmax probability. This works just like the sampling algorithm we saw in Chapter 3 for generating random sentences from n-gram language models. Imagine there are only 4 words and the softmax probability distribution at time t is (the: [ 0.6 ], green: [ 0.2 ], a: [ 0.1 ], witch: [ 0.1 ]). We roll a weighted die, with the 4 sides weighted [ 0.6 ], [ 0.2 ], [ 0.1 ], and [ 0.1 ], and chose the word based on which side comes up. Another parameter is the ratio of backtranslated data to natural bitext data; we can choose to upsample the bitext data (include multiple copies of each sentence).", "questions_and_answers": [{"answer_start": 104, "answer": "creating synthetic bitexts", "question": "Backtranslation is a way of making use of monolingual corpora in the target backtranslation language by what?"}, {"answer_start": 177, "answer": "target-to-source MT system", "question": "What does backtranslation train on the small bitext to translate the monolingual target data to the source language?"}, {"answer_start": 327, "answer": "natural target sentences", "question": "What is a synthetic bitext aligned with MT-produced source sentences?"}, {"answer_start": 547, "answer": "Navajo-English", "question": "What is the only bitext we have to translate from Navajo to English?"}, {"answer_start": 662, "answer": "build an MT engine", "question": "What do we use the small bitext to do?"}, {"answer_start": 811, "answer": "Navajo/English", "question": "What is the name of the bitext we can add to our training data?"}, {"answer_start": 875, "answer": "various parameters", "question": "What does backtranslation have?"}, {"answer_start": 969, "answer": "greedy inference", "question": "In what way can we run the decoder?"}, {"answer_start": 1033, "answer": "Monte Carlo search", "question": "What is another name for sampling?"}, {"answer_start": 1201, "answer": "weighted die", "question": "What is used to choose the next word according to its softmax probability?"}, {"answer_start": 1422, "answer": "n-gram", "question": "What language model is used to generate random sentences?"}, {"answer_start": 1469, "answer": "4", "question": "How many words are there in a random sentence?"}, {"answer_start": 1199, "answer": "a weighted die", "question": "What is used to choose the next word based on which side comes up?"}, {"answer_start": 1825, "answer": "upsample", "question": "What can we do with the bitext data?"}]}, {"context": "In general backtranslation works surprisingly well; one estimate suggests that a system trained on backtranslated text gets about 2/3 of the gain as would training on the same amount of natural bitext (Edunov et al., 2018).", "questions_and_answers": [{"answer_start": 130, "answer": "2/3", "question": "How much gain does a system trained on backtranslated text get?"}]}, {"context": "1. adequacy: how well the translation captures the exact meaning of the source adequacy sentence. Sometimes called faithfulness or fidelity.", "questions_and_answers": [{"answer_start": 3, "answer": "adequacy", "question": "What is the term for how well the translation captures the exact meaning of the source adequacy sentence?"}, {"answer_start": 115, "answer": "faithfulness or fidelity", "question": "What is another term for adequacy?"}]}, {"context": "2. fluency: how fluent the translation is in the target language (is it grammatical, fluency clear, readable, natural).", "questions_and_answers": [{"answer_start": 3, "answer": "fluency", "question": "What is the term for how fluent the translation is in the target language?"}, {"answer_start": 3, "answer": "fluency", "question": "What is the term for how fluent the translation is in the target language?"}, {"answer_start": 3, "answer": "fluency", "question": "What is the term for how fluent the translation is in the target language?"}, {"answer_start": 85, "answer": "fluency clear", "question": "Is the translation clear or grammatical?"}, {"answer_start": 85, "answer": "fluency clear, readable", "question": "Is the translation grammatical, readable, or natural?"}, {"answer_start": 3, "answer": "fluency", "question": "What is the term for how fluent the translation is in the target language?"}]}, {"context": "The most accurate evaluations use human raters, such as online crowdworkers, to evaluate each translation along the two dimensions. For example, along the dimension of fluency, we can ask how intelligible, how clear, how readable, or how natural the MT output (the target text) is. We can give the raters a scale, for example, from 1 (totally unintelligible) to 5 (totally intelligible, or 1 to 100, and ask them to rate each sentence or paragraph of the MT output.", "questions_and_answers": [{"answer_start": 34, "answer": "human raters", "question": "What do the most accurate evaluations use?"}, {"answer_start": 168, "answer": "fluency", "question": "Along what dimension can we ask how intelligible, clear, readable, or natural the MT output (the target text) is?"}, {"answer_start": 332, "answer": "1", "question": "How unintelligible is the target text?"}]}, {"context": "We can do the same thing to judge the second dimension, adequacy, using raters to assign scores on a scale. If we have bilingual raters, we can give them the source sentence and a proposed target sentence, and rate, on a 5-point or 100-point scale, how much of the information in the source was preserved in the target. If we only have monolingual raters but we have a good human translation of the source text, we can give the monolingual raters the human reference translation and a target machine translation and again rate how much information is preserved. An alternative is to do ranking: give the raters a pair of candidate translations, and ask them which one ranking they prefer.", "questions_and_answers": [{"answer_start": 56, "answer": "adequacy", "question": "What is the second dimension?"}, {"answer_start": 249, "answer": "how much of the information in the source was preserved in the target", "question": "What do raters rate on a 5-point or 100-point scale?"}, {"answer_start": 367, "answer": "a good human translation of the source text", "question": "If we have monolingual raters but not a target machine translation, what can we give them?"}, {"answer_start": 586, "answer": "ranking", "question": "What is an alternative to giving raters a pair of candidate translations?"}]}, {"context": "Training of human raters (who are often online crowdworkers) is essential; raters without translation expertise find it difficult to separate fluency and adequacy, and so training includes examples carefully distinguishing these. Raters often disagree (sources sentences may be ambiguous, raters will have different world knowledge, raters may apply scales differently). It is therefore common to remove outlier raters, and (if we use a fine-grained enough scale) normalizing raters by subtracting the mean from their scores and dividing by the variance.", "questions_and_answers": [{"answer_start": 189, "answer": "examples carefully distinguishing these", "question": "What does training of raters include?"}, {"answer_start": 253, "answer": "sources sentences may be ambiguous", "question": "Why do raters often disagree?"}, {"answer_start": 486, "answer": "subtracting the mean from their scores and dividing by the variance", "question": "How can raters be normalized?"}]}, {"context": "While humans produce the best evaluations of machine translation output, running a human evaluation can be time consuming and expensive. For this reason automatic metrics are often used. Automatic metrics are less accurate than human evaluation, but can help test potential system improvements, and even be used as an automatic loss function for training. In this section we introduce two families of such metrics, those based on character-or word-overlap and those based on embedding similarity.", "questions_and_answers": [{"answer_start": 6, "answer": "humans", "question": "Who produces the best evaluations of machine translation output?"}, {"answer_start": 153, "answer": "automatic metrics", "question": "What is often used to evaluate machine translation output?"}, {"answer_start": 153, "answer": "automatic", "question": "Automatic metrics can be used as what type of loss function for training?"}, {"answer_start": 430, "answer": "character-or word-overlap", "question": "What are the two families of automatic metrics based on?"}, {"answer_start": 475, "answer": "embedding similarity", "question": "What are the two families of automatic metrics based on?"}]}, {"context": "The simplest and most robust metric for MT evaluation is called chrF, which stands chrF for character F-score (Popovi\u0107, 2015) . chrF (along with many other earlier related metrics like BLEU, METEOR, TER, and others) is based on a simple intuition derived from the pioneering work of Miller and Beebe-Center (1956): a good machine translation will tend to contain characters and words that occur in a human translation of the same sentence. Consider a test set from a parallel corpus, in which each source sentence has both a gold human target translation and a candidate MT translation we'd like to evaluate. The chrF metric ranks each MT target sentence by a function of the number of character n-gram overlaps with the human translation.", "questions_and_answers": [{"answer_start": 92, "answer": "character F-score", "question": "What does chrF stand for?"}, {"answer_start": 64, "answer": "chrF", "question": "What is the simplest and most robust metric for MT evaluation?"}, {"answer_start": 315, "answer": "a good machine translation", "question": "What will tend to contain characters and words that occur in a human translation of the same sentence?"}, {"answer_start": 465, "answer": "a parallel corpus", "question": "What is a test set from where each source sentence has both a gold human target translation and a candidate MT translation?"}, {"answer_start": 696, "answer": "n-gram", "question": "The chrF metric ranks each MT target sentence by a function of the number of character overlaps with the human translation?"}]}, {"context": "chrP percentage of character 1-grams, 2-grams, ..., k-grams in the hypothesis that occur in the reference, averaged. chrR of character 1-grams, 2-grams,..., k-grams in the reference that occur in the hypothesis, averaged.", "questions_and_answers": [{"answer_start": 0, "answer": "chrP", "question": "What percentage of character 1-grams, 2-grams,..., k-grams in the hypothesis that occur in the reference, averaged"}, {"answer_start": 107, "answer": "averaged", "question": "What is the chrP percentage of character 1-grams, 2-grams,..., k-grams in the reference that occur in"}]}, {"context": "The metric then computes an F-score by combining chrP and chrR using a weighting parameter \u03b2 . It is common to set \u03b2 = 2, thus weighing recall twice as much as precision:", "questions_and_answers": [{"answer_start": 49, "answer": "chrP and chrR", "question": "The metric computes an F-score by combining what?"}, {"answer_start": 127, "answer": "weighing recall twice as much as precision", "question": "What is the result of setting  = 2?"}]}, {"context": "For example, consider two hypotheses that we'd like to score against the reference translation witness for the past. Here are the hypotheses along with chrF values computed using parameters k = \u03b2 = 2 (in real examples, k would be a higher number like 6): REF: witness for the past, HYP1: witness of the past, chrF2,2 = .86 HYP2: past witness chrF2,2 = .62", "questions_and_answers": [{"answer_start": 22, "answer": "two", "question": "How many hypotheses do we want to score against the reference translation witness for the past?"}, {"answer_start": 319, "answer": ".86", "question": "What is the chrF2 value of HYP1?"}, {"answer_start": 352, "answer": ".62", "question": "What is the chrF2 of HYP2?"}]}, {"context": "Next let's see how many unigrams and bigrams match between the reference and hypothesis: unigrams that match: w i t n e s s f o t h e p a s t , (17 unigrams) bigrams that match: wi it tn ne es ss th he ep pa as st t, (13 bigrams)", "questions_and_answers": [{"answer_start": 218, "answer": "13", "question": "How many bigrams are there?"}]}, {"context": "Finally we average to get chrP and chrR, and compute the F-score: chrP = (17[ /17 + 13/ ]16)[ /2 = .906 chrR = (17/ ]18 + 13[ /17)/ ]2 = .855 chrF2,2 = 5 chrP * chrR 4chrP + chrR = .86 chrF is simple, robust, and correlates very well with human judgments in many languages (Kocmi et al., 2021) . There are various alternative overlap metrics. For example, before the development of chrF, it was common to use a word-based overlap metric called BLEU (for BiLingual Evaluation Understudy), that is purely precision-based rather than combining precision and recall (Papineni et al., 2002) . The BLEU score for a corpus of candidate translation sentences is a function of the n-gram word precision over all the sentences combined with a brevity penalty computed over the corpus as a whole. Because BLEU is a word-based metric, it is very sensitive to word tokenization, making it difficult to compare across situations, and doesn't work as well in languages with complex morphology.", "questions_and_answers": [{"answer_start": 26, "answer": "chrP and chrR", "question": "What do we average to get?"}, {"answer_start": 306, "answer": "various alternative overlap metrics", "question": "What is there besides chrP and chrR?"}, {"answer_start": 444, "answer": "BLEU", "question": "What was the word-based overlap metric before chrF?"}, {"answer_start": 672, "answer": "n-gram word precision", "question": "What is the BLEU score for a corpus of candidate translation sentences a function of?"}, {"answer_start": 847, "answer": "word tokenization", "question": "What is BLEU sensitive to?"}]}, {"context": "Character or word overlap-based metrics like chrF (or BLEU, or etc.) are mainly used to compare two systems, with the goal of answering questions like: did the new algorithm we just invented improve our MT system? To know if the difference between the chrF scores of two MT systems is a significant difference, we use the paired bootstrap test, or the similar randomization test.", "questions_and_answers": [{"answer_start": 45, "answer": "chrF", "question": "What is a character or word overlap-based metrics called?"}, {"answer_start": 85, "answer": "to compare two systems", "question": "What is chrF used for?"}, {"answer_start": 322, "answer": "paired bootstrap test", "question": "What test is used to determine if the difference between chrF scores of two MT systems is a significant difference?"}]}, {"context": "To get a confidence interval on a single chrF score using the bootstrap test, recall from Section [ 4.9 ] that we take our test set (or devset) and create thousands of pseudotestsets by repeatedly sampling with replacement from the original test set. We now compute the chrF score of each of the pseudo-testsets. If we drop the top [ 2.5 ]% and bottom [ 2.5 ]% of the scores, the remaining scores will give us the 95% confidence interval for the chrF score of our system.", "questions_and_answers": [{"answer_start": 148, "answer": "create thousands of pseudotestsets", "question": "How do we get a confidence interval on a single chrF score?"}, {"answer_start": 258, "answer": "compute the chrF score of each of the pseudo-testsets", "question": "How do we get a confidence interval on a single chrF score?"}, {"answer_start": 414, "answer": "95%", "question": "What is the confidence interval for the chrF score of our system?"}]}, {"context": "To compare two MT systems A and B, we draw the same set of pseudo-testsets, and compute the chrF scores for each of them. We then compute the percentage of pseudo-test-sets in which A has a higher chrF score than B.", "questions_and_answers": [{"answer_start": 92, "answer": "chrF scores", "question": "What do we compute for each set of pseudo-testsets?"}, {"answer_start": 59, "answer": "pseudo-testsets", "question": "To compare two MT systems A and B, we draw the same set of what?"}, {"answer_start": 190, "answer": "higher", "question": "What is the percentage of pseudo-test-sets in which A has a higher or lower chrF score than B?"}]}, {"context": "While automatic character and word-overlap metrics like chrF or BLEU are useful, they have important limitations. chrF is very local: a large phrase that is moved around might barely change the chrF score at all, and chrF can't evaluate crosssentence properties of a document like its discourse coherence (Chapter 22). chrF and similar automatic metrics also do poorly at comparing very different kinds of systems, such as comparing human-aided translation against machine translation, or different machine translation architectures against each other (Callison-Burch et al., 2006) . Instead, automatic overlap metrics like chrF are most appropriate when evaluating changes to a single system.", "questions_and_answers": [{"answer_start": 56, "answer": "chrF or BLEU", "question": "What are two examples of automatic character and word-overlap metrics?"}, {"answer_start": 285, "answer": "discourse coherence", "question": "What is a crosssentence property of a document that chrF can't evaluate?"}, {"answer_start": 372, "answer": "comparing very different kinds of systems", "question": "What do chrF and similar automatic metrics do poorly at?"}, {"answer_start": 56, "answer": "chrF", "question": "What is the name of the automatic overlap metrics that are most appropriate when evaluating changes to a single system?"}]}, {"context": "The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common. However, this criterion is overly strict, since a good translation may use alternate words or paraphrases. A solution first pioneered in early metrics like METEOR (Banerjee and Lavie, 2005) was to allow synonyms to match between the reference x and candidatex. More recent metrics use BERT or other embeddings to implement this intuition.", "questions_and_answers": [{"answer_start": 4, "answer": "chrF", "question": "What metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common?"}, {"answer_start": 209, "answer": "alternate words or paraphrases", "question": "What can a good translation use?"}, {"answer_start": 337, "answer": "synonyms", "question": "What did METEOR allow to match between the reference x and candidatex?"}, {"answer_start": 419, "answer": "BERT", "question": "What embedding is used to implement the chrF metric?"}]}, {"context": "In other cases, however, we don't have such human-labeled datasets. In that case we can measure the similarity of x andx by the similarity of their embeddings. The BERTSCORE algorithm (Zhang et al., 2020) shown in Figure 10 .18, for example, passes the reference x and the candidatex through BERT, computing a BERT embedding for each token x i andx j . Each pair of tokens (x i ,x j ) is scored by its cosine", "questions_and_answers": [{"answer_start": 44, "answer": "human-labeled datasets", "question": "What do we not have in other cases?"}, {"answer_start": 128, "answer": "similarity of their embeddings", "question": "How can we measure the similarity of x andx?"}, {"answer_start": 185, "answer": "Zhang et al.", "question": "Who created the BERTSCORE algorithm?"}, {"answer_start": 398, "answer": "its cosine", "question": "How is each pair of tokens scored?"}]}, {"context": "Each token in x is matched to a token inx to compute recall, and each token i\u00f1 x is matched to a token in x to compute precision (with each token greedily matched to the most similar token in the corresponding sentence). BERTSCORE provides precision and recall (and hence F 1 ):", "questions_and_answers": [{"answer_start": 53, "answer": "recall", "question": "Each token in x is matched to a token inx to compute what?"}, {"answer_start": 119, "answer": "precision", "question": "What is each token i x matched to a token in x to compute?"}, {"answer_start": 221, "answer": "BERTSCORE", "question": "What provides precision and recall?"}]}, {"context": "Hungarian (gender neutral) source English MT output o egy\u00e1pol\u00f3 she is a nurse o egy tud\u00f3s he is a scientist o egy m\u00e9rn\u00f6k he is an engineer o egy p\u00e9k he is a baker o egy tan\u00e1r she is a teacher o egy vesk\u00fcv\u0151szervez\u0151 she is a wedding organizer o egy vez\u00e9rigazgat\u00f3 he is a CEO Figure 10 .19 When translating from gender-neutral languages like Hungarian into English, current MT systems interpret people from traditionally male-dominated occupations as male, and traditionally female-dominated occupations as female (Prates et al., 2019) .", "questions_and_answers": [{"answer_start": 130, "answer": "engineer", "question": "What is the profession of o egy\u00e1pol\u00f3?"}, {"answer_start": 130, "answer": "engineer", "question": "What is the profession of o egy\u00e1pol\u00f3?"}]}, {"context": "Similarly, a recent challenge set, the WinoMT dataset (Stanovsky et al., 2019) shows that MT systems perform worse when they are asked to translate sentences that describe people with non-stereotypical gender roles, like \"The doctor asked the nurse to help her in the operation\".", "questions_and_answers": [{"answer_start": 35, "answer": "the WinoMT dataset", "question": "What dataset shows that MT systems perform worse when asked to translate sentences that describe people with non-stereotypical gender roles?"}]}, {"context": "Many ethical questions in MT require further research. One open problem is developing metrics for knowing what our systems don't know. This is because MT systems can be used in urgent situations where human translators may be unavailable or delayed: in medical domains, to help translate when patients and doctors don't speak the same language, or in legal domains, to help judges or lawyers communicate with witnesses or defendants. In order to 'do no harm', systems need ways to assign confidence values to candidate translations, so they can abstain from giving confidence incorrect translations that may cause harm.", "questions_and_answers": [{"answer_start": 5, "answer": "ethical", "question": "What type of questions in MT require further research?"}, {"answer_start": 75, "answer": "developing metrics", "question": "What is one open problem in MT?"}, {"answer_start": 253, "answer": "medical domains", "question": "Where can MT systems be used to help translate when patients and doctors don't speak the same language?"}, {"answer_start": 509, "answer": "candidate translations", "question": "What do systems need to assign confidence values to?"}]}, {"context": "Machine translation is one of the most widely used applications of NLP, and the encoder-decoder model, first developed for MT is a key tool that has applications throughout NLP.", "questions_and_answers": [{"answer_start": 0, "answer": "Machine translation", "question": "What is one of the most widely used applications of NLP?"}]}, {"context": "MT was proposed seriously by the late 1940s, soon after the birth of the computer (Weaver, 1949 (Weaver, /1955 . In 1954, the first public demonstration of an MT system prototype (Dostert, 1955) led to great excitement in the press (Hutchins, 1997). The next decade saw a great flowering of ideas, prefiguring most subsequent developments. But this work was ahead of its time-implementations were limited by, for example, the fact that pending the development of disks there was no good way to store dictionary information.", "questions_and_answers": [{"answer_start": 91, "answer": "1949", "question": "When was MT first proposed?"}, {"answer_start": 106, "answer": "1955", "question": "When was the first public demonstration of an MT system prototype?"}, {"answer_start": 272, "answer": "great flowering", "question": "What was the result of the first public demonstration of a MT system?"}, {"answer_start": 500, "answer": "dictionary information", "question": "What did MT have no good way to store pending the development of disks?"}]}, {"context": "In the early years, the space of MT architectures spanned three general models. In direct translation, the system proceeds word-by-word through the sourcelanguage text, translating each word incrementally. Direct translation uses a large bilingual dictionary, each of whose entries is a small program with the job of translating one word. In transfer approaches, we first parse the input text and then apply rules to transform the source-language parse into a target language parse. We then generate the target language sentence from the parse tree. In interlingua approaches, we analyze the source language text into some abstract meaning representation, called an interlingua. We then generate into the target language from this interlingual representation. A common way to visualize these three early approaches was the Vauquois triangle shown in Figure 10 .20. The triangle shows the", "questions_and_answers": [{"answer_start": 58, "answer": "three", "question": "How many general models did MT architectures span in the early years?"}, {"answer_start": 83, "answer": "direct translation", "question": "What is the system that proceeds word-by-word through the sourcelanguage text?"}, {"answer_start": 238, "answer": "bilingual dictionary", "question": "Direct translation uses a large what?"}, {"answer_start": 342, "answer": "transfer approaches", "question": "In what approach do we first parse the input text and then apply rules to transform the source-language parse into a target language par"}, {"answer_start": 504, "answer": "target language sentence", "question": "What is generated from the parse tree?"}, {"answer_start": 553, "answer": "interlingua", "question": "What approach analyzes the source language text into some abstract meaning representation called an interlingua?"}, {"answer_start": 731, "answer": "interlingual representation", "question": "What do we generate into the target language from?"}, {"answer_start": 823, "answer": "Vauquois triangle", "question": "What is shown in Figure 10.20?"}, {"answer_start": 865, "answer": "The triangle", "question": "What shows the Vauquois triangle?"}]}, {"context": "increasing depth of analysis required (on both the analysis and generation end) as we move from the direct approach through transfer approaches to interlingual approaches. In addition, it shows the decreasing amount of transfer knowledge needed as we move up the triangle, from huge amounts of transfer at the direct level (almost all knowledge is transfer knowledge for each word) through transfer (transfer rules only for parse trees or thematic roles) through interlingua (no specific transfer knowledge). We can view the encoder-decoder network as an interlingual approach, with attention acting as an integration of direct and transfer, allowing words or their representations to be directly accessed by the decoder. Statistical methods began to be applied around 1990, enabled first by the development of large bilingual corpora like the Hansard corpus of the proceedings of the Canadian Parliament, which are kept in both French and English, and then by the growth of the Web. Early on, a number of researchers showed that it was possible to extract pairs of aligned sentences from bilingual corpora, using words or simple cues like sentence length (Kay and R\u00f6scheisen 1988 , Gale and Church 1991 , Gale and Church 1993 , Kay and R\u00f6scheisen 1993 .", "questions_and_answers": [{"answer_start": 0, "answer": "increasing depth of analysis", "question": "What is required as we move from the direct approach through transfer approaches to interlingual approaches?"}, {"answer_start": 124, "answer": "transfer", "question": "What type of knowledge is decreasing as we move up the triangle?"}, {"answer_start": 147, "answer": "interlingual approach", "question": "What is the encoder-decoder network seen as?"}, {"answer_start": 844, "answer": "Hansard corpus of the proceedings of the Canadian Parliament", "question": "What is an example of a large bilingual corpora?"}, {"answer_start": 1057, "answer": "pairs of aligned sentences", "question": "What did researchers show it was possible to extract from bilingual corpora?"}]}, {"context": "At the same time, the IBM group, drawing directly on the noisy channel model for speech recognition, proposed two related paradigm for statistical MT. These statistical MT include the generative algorithms that became known as IBM Models 1 through IBM Models 5, implemented in the Candide system. The algorithms (except for the decoder) Candide were published in full detail-encouraged by the US government which had par- (Papineni et al., 2002) , NIST (Doddington, 2002) , TER (Translation Error Rate) (Snover et al., 2006) , Precision and Recall (Turian et al., 2003) , and METEOR (Banerjee and Lavie, 2005); character n-gram overlap methods like chrF (Popovi\u0107, 2015) came later. More recent evaluation work, echoing the ALPAC report, has emphasized the importance of careful statistical methodology and the use of human evaluation (Kocmi et al., 2021; Marie et al., 2021) .", "questions_and_answers": [{"answer_start": 110, "answer": "two", "question": "How many related paradigms did the IBM group propose for statistical MT?"}, {"answer_start": 227, "answer": "IBM Models 1 through IBM Models 5", "question": "What were the generative algorithms that were implemented in the Candide system called?"}, {"answer_start": 393, "answer": "US government", "question": "Who encouraged the Candide system?"}, {"answer_start": 723, "answer": "ALPAC", "question": "What report echoes the importance of careful statistical methodology and the use of human evaluation?"}]}, {"context": "The early history of MT is surveyed in Hutchins 1986 and 1997; Nirenburg et al. (2002) collects early readings. See Croft (1990) or Comrie (1989) for introductions to linguistic typology.", "questions_and_answers": [{"answer_start": 48, "answer": "1986 and 1997", "question": "When was the early history of MT surveyed?"}, {"answer_start": 63, "answer": "Nirenburg et al.", "question": "Who collected early readings of MT?"}, {"answer_start": 96, "answer": "early readings", "question": "Nirenburg et al. (2002) collects what?"}, {"answer_start": 123, "answer": "1990", "question": "When was Croft published?"}]}, {"context": "Fluent speakers bring an enormous amount of knowledge to bear during comprehension and production of language. This knowledge is embodied in many forms, perhaps most obviously in the vocabulary. That is, in the rich representations associated with the words we know, including their grammatical function, meaning, real-world reference, and pragmatic function. This makes the vocabulary a useful lens to explore the acquisition of knowledge from text, by both people and machines.", "questions_and_answers": [{"answer_start": 0, "answer": "Fluent speakers", "question": "Who brings an enormous amount of knowledge to bear during comprehension and production of language?"}, {"answer_start": 183, "answer": "vocabulary", "question": "What is embodied in the rich representations associated with the words we know?"}, {"answer_start": 211, "answer": "rich representations", "question": "What kind of representations are associated with the words we know?"}, {"answer_start": 459, "answer": "people and machines", "question": "Who can use the vocabulary to explore the acquisition of knowledge from text?"}]}, {"context": "Estimates of the size of adult vocabularies vary widely both within and across languages. For example, estimates of the vocabulary size of young adult speakers of American English range from 30,000 to 100,000 depending on the resources used to make the estimate and the definition of what it means to know a word. What is agreed upon is that the vast majority of words that mature speakers use in their dayto-day interactions are acquired early in life through spoken interactions in context with care givers and peers, usually well before the start of formal schooling. This active vocabulary is extremely limited compared to the size of the adult vocabulary (usually on the order of 2000 words for young speakers) and is quite stable, with very few additional words learned via casual conversation beyond this early stage. Obviously, this leaves a very large number of words to be acquired by some other means.", "questions_and_answers": [{"answer_start": 0, "answer": "Estimates", "question": "What is the size of adult vocabularies vary widely both within and across languages?"}, {"answer_start": 191, "answer": "30,000 to 100,000", "question": "What are the estimates of the size of adult vocabularies in American English?"}, {"answer_start": 497, "answer": "care givers and peers", "question": "Who are the majority of words that mature speakers use in their dayto-day interactions in context with?"}, {"answer_start": 685, "answer": "2000", "question": "What is the average size of adult vocabularies for young speakers?"}, {"answer_start": 848, "answer": "a very large number", "question": "How many words are left to be acquired by other means?"}]}, {"context": "The most likely remaining explanation is that the bulk of this knowledge acquisition happens as a by-product of reading. Research into the average amount of time children spend reading, and the lexical diversity of the texts they read, indicate that it is possible to achieve the desired rate. But the mechanism behind this rate of learning must be remarkable indeed, since at some points during learning the rate of vocabulary growth exceeds the rate at which new words are appearing to the learner!", "questions_and_answers": [{"answer_start": 98, "answer": "by-product of reading", "question": "What is the most likely explanation for the bulk of knowledge acquisition?"}, {"answer_start": 194, "answer": "lexical diversity", "question": "What does research indicate about the texts children read?"}, {"answer_start": 417, "answer": "vocabulary growth", "question": "At some points during learning, the rate of what exceeds the rate at which new words are appearing to the learner?"}]}, {"context": "Many of these facts have motivated approaches to word learning based on the distributional hypothesis, introduced in Chapter 6. This is the idea that something about what we're loosely calling word meanings can be learned even without any grounding in the real world, solely based on the content of the texts we've encountered over our lives. This knowledge is based on the complex association of words with the words they co-occur with (and with the words that those words occur with).", "questions_and_answers": [{"answer_start": 76, "answer": "distributional hypothesis", "question": "Many of these facts have motivated approaches to word learning based on what hypothesis?"}, {"answer_start": 288, "answer": "content of the texts", "question": "What does the distributional hypothesis rely on?"}, {"answer_start": 374, "answer": "complex association of words with the words they co-occur with", "question": "What is knowledge based on?"}]}, {"context": "The crucial insight of the distributional hypothesis is that the knowledge that we acquire through this process can be brought to bear during language processing long after its initial acquisition in novel contexts. We saw in Chapter 6 that embeddings (static word representations) can be learned from text and then employed for other purposes like measuring word similarity or studying meaning change over time.", "questions_and_answers": [{"answer_start": 142, "answer": "language processing", "question": "The distributional hypothesis is that the knowledge that we acquire through this process can be brought to bear during what?"}, {"answer_start": 241, "answer": "embeddings", "question": "What are static word representations?"}]}, {"context": "In this chapter, we expand on this idea in two large ways. First, we'll introduce the idea of contextual embeddings: representations for words in context. The methods of Chapter 6 like word2vec or GloVe learned a single vector embedding for each unique word w in the vocabulary. By contrast, with contextual embeddings, such as those learned by popular methods like BERT (Devlin et al., 2019) or GPT (Radford et al., 2019) or their descendants, each word w will be represented by a different vector each time it appears in a different context.", "questions_and_answers": [{"answer_start": 43, "answer": "two large ways", "question": "How many ways do we expand on the idea of contextual embeddings?"}, {"answer_start": 94, "answer": "contextual embeddings", "question": "What are representations for words in context?"}, {"answer_start": 213, "answer": "single vector embedding", "question": "What did the methods of Chapter 6 learn for each unique word w in the vocabulary?"}, {"answer_start": 480, "answer": "a different vector", "question": "What will each word w be represented by each time it appears in a different context?"}]}, {"context": "Second, we'll introduce in this chapter the idea of pretraining and fine-tuning. We call pretraining the process of learning some sort of representation of meaning for words or sentences by processing very large amounts of text. We'll call these pretrained models pretrained language models, since they can take the form of the transformer language models we introduced in Chapter 9. We call fine-tuning the process of taking the representations from these pretrained models, and further training the model, often via an added neural net classifier, to perform some downstream task like named entity tagging or question answering or coreference. The intuition is that the pretraining phase learns a language model that instantiates a rich representations of word meaning, that thus enables the model to more easily learn ('be fine-tuned to') the requirements of a downstream language understanding task. The pretrain-finetune paradigm is an instance of what is called transfer learning in machine learning: the method of acquiring knowledge from one task or domain, and then applying it (transferring it) to solve a new task. Of course, adding grounding from vision or from real-world interaction into pretrained models can help build even more powerful models, but even text alone is remarkably useful, and we will limit our attention here to purely textual models. There are two common paradigms for pretrained language models. One is the causal or left-to-right transformer model we introduced in Chapter 9. In this chapter we'll introduce a second paradigm, called the bidirectional transformer encoder, and the method of masked language modeling, introduced with the BERT model (Devlin et al., 2019 ) that allows the model to see entire texts at a time, including both the right and left context.", "questions_and_answers": [{"answer_start": 68, "answer": "fine-tuning", "question": "What is the process of learning some sort of representation of meaning for words or sentences by processing very large amounts of text?"}, {"answer_start": 52, "answer": "pretraining", "question": "What is the process of learning some sort of representation of meaning for words or sentences by processing very large amounts of text?"}, {"answer_start": 328, "answer": "transformer language models", "question": "What did we introduce in Chapter 9?"}, {"answer_start": 587, "answer": "named entity tagging or question answering or coreference", "question": "What is a downstream task that a model is trained to perform?"}, {"answer_start": 52, "answer": "pretraining", "question": "What phase learns a language model that instantiates a rich representation of word meaning?"}, {"answer_start": 968, "answer": "transfer learning", "question": "The pretrain-finetune paradigm is an instance of what in machine learning?"}, {"answer_start": 1271, "answer": "text alone", "question": "What is remarkably useful in machine learning?"}, {"answer_start": 1377, "answer": "two", "question": "How many common paradigms are there for pretrained language models?"}, {"answer_start": 1451, "answer": "left-to-right transformer model", "question": "What is the causal model?"}, {"answer_start": 1569, "answer": "the bidirectional transformer encoder", "question": "What is the second paradigm introduced in this chapter?"}]}, {"context": "Finally, we'll show how the contextual embeddings from these pretrained language models can be used to transfer the knowledge embodied in these models to novel applications via fine-tuning. Indeed, in later chapters we'll see pretrained language models fine-tuned to tasks from parsing to question answering, from information extraction to semantic parsing.", "questions_and_answers": [{"answer_start": 177, "answer": "fine-tuning", "question": "How can contextual embeddings from pretrained language models be used to transfer knowledge to novel applications?"}, {"answer_start": 314, "answer": "information extraction", "question": "From parsing to question answering, to semantic parsing, what is a task that pre-trained language models fine-tuned"}]}, {"context": "This contextualization is accomplished through the use of the same self-attention mechanism used in causal models. As with these models, the first step is to generate a set of key, query and value embeddings for each element of the input vector x through the use of learned weight matrices W Q , W K , and W V . These weights project each input vector x i into its specific role as a key, query, or value.", "questions_and_answers": [{"answer_start": 67, "answer": "self-attention mechanism", "question": "What mechanism is used in causal models?"}, {"answer_start": 266, "answer": "learned weight matrices", "question": "What is used to create a set of key, query, and value embeddings for each element of the input vector x?"}, {"answer_start": 384, "answer": "key, query, or value", "question": "What do the weights project each input vector x i into its specific role as?"}]}, {"context": "The output vector y i corresponding to each input element x i is a weighted sum of all the input value vectors v, as follows:", "questions_and_answers": [{"answer_start": 18, "answer": "y i", "question": "What is the output vector corresponding to each input element x i?"}]}, {"context": "The \u03b1 weights are computed via a softmax over the comparison scores between every element of an input sequence considered as a query and every other element as a key, where the comparison scores are computed using dot products.", "questions_and_answers": [{"answer_start": 214, "answer": "dot products", "question": "What are the comparison scores computed using?"}, {"answer_start": 31, "answer": "a softmax", "question": "How are the  weights computed?"}]}, {"context": "As shown in Figure 11 .3, the full set of self-attention scores represented by QK T constitute an all-pairs comparison between the keys and queries for each element of the input. In the case of causal language models in Chapter 9, we masked the upper triangular portion of this matrix (in Figure ??) to eliminate information about future words since this would make the language modeling training task trivial. With bidirectional encoders we simply skip the mask, allowing the model to contextualize each token using information from the entire input.", "questions_and_answers": [{"answer_start": 98, "answer": "all-pairs comparison", "question": "What do the self-attention scores represent in Figure 11.3?"}, {"answer_start": 245, "answer": "upper triangular portion", "question": "What portion of the matrix was masked in the case of causal language models in Chapter 9?"}, {"answer_start": 361, "answer": "make the language modeling training task trivial", "question": "Why did we masked the upper triangular portion of the matrix?"}, {"answer_start": 416, "answer": "bidirectional encoders", "question": "What allows the model to contextualize each token using information from the entire input?"}]}, {"context": "Beyond this simple change, all of the other elements of the transformer architecture remain the same for bidirectional encoder models. Inputs to the model are segmented using subword tokenization and are combined with positional embeddings before being passed through a series of standard transformer blocks consisting of self-attention and feedforward layers augmented with residual connections and layer normalization, as shown in Figure 11 .4. To make this more concrete, the original bidirectional transformer encoder model, BERT (Devlin et al., 2019) , consisted of the following:", "questions_and_answers": [{"answer_start": 105, "answer": "bidirectional encoder models", "question": "For what model do all of the other elements of the transformer architecture remain the same?"}, {"answer_start": 322, "answer": "self-attention and feedforward layers", "question": "What are the standard transformer blocks consisting of?"}, {"answer_start": 529, "answer": "BERT", "question": "What is the original bidirectional transformer encoder model?"}]}, {"context": "[ \u2022 ] A subword vocabulary consisting of 30,000 tokens generated using the Word-Piece algorithm (Schuster and Nakajima, 2012) , [ \u2022 ] Hidden layers of size of 768, [ \u2022 ] 12 layers of transformer blocks, with 12 multihead attention layers each.", "questions_and_answers": [{"answer_start": 41, "answer": "30,000", "question": "How many tokens are in the Word-Piece algorithm?"}, {"answer_start": 75, "answer": "Word-Piece algorithm", "question": "What algorithm generates subword vocabulary?"}]}, {"context": "The result is a model with over 100M parameters. The use of WordPiece (one of the large family of subword tokenization algorithms that includes the BPE algorithm we saw in Chapter 2) means that BERT and its descendants are based on subword tokens rather than words. Every input sentence first has to be tokenized, and then all further processing takes place on subword tokens rather than words. This will require, as we'll see, that for some NLP tasks that require notions of words (like named entity tagging, or parsing) we will occasionally need to map subwords back to words.", "questions_and_answers": [{"answer_start": 27, "answer": "over 100M", "question": "How many parameters does the model have?"}, {"answer_start": 60, "answer": "WordPiece", "question": "What is one of the large family of subword tokenization algorithms that includes the BPE algorithm?"}, {"answer_start": 303, "answer": "tokenized", "question": "What does every input sentence first have to be?"}, {"answer_start": 488, "answer": "named entity tagging, or parsing", "question": "What are some NLP tasks that require notions of words?"}]}, {"context": "Finally, a fundamental issue with transformers is that the size of the input layer dictates the complexity of model. Both the time and memory requirements in a transformer grow quadratically with the length of the input. It's necessary, therefore, to set a fixed input length that is long enough to provide sufficient context for the model to function and yet still be computationally tractable. For BERT, a fixed input size of 512 subword tokens was used.", "questions_and_answers": [{"answer_start": 55, "answer": "the size of the input layer", "question": "What dictates the complexity of a transformer?"}, {"answer_start": 177, "answer": "quadratically", "question": "How much do the time and memory requirements in a transformer grow with the length of the input?"}, {"answer_start": 251, "answer": "set a fixed input length", "question": "What is necessary to provide enough context for the model to function and yet still be computationally tractable?"}, {"answer_start": 428, "answer": "512", "question": "How many subword tokens were used for BERT?"}]}, {"context": "We trained causal transformer language models in Chapter 9 by making them iteratively predict the next word in a text. But eliminating the causal mask makes the guess-the-next-word language modeling task trivial since the answer is now directly available from the context, so we're in need of a new training scheme. Fortunately, the traditional learning objective suggests an approach that can be used to train bidirectional encoders. Instead of trying to predict the next word, the model learns to perform a fill-in-the-blank task, technically called the cloze task (Taylor, 1953) . To cloze task see this, let's return to the motivating example from Chapter 3. Instead of predicting which words are likely to come next in this example:", "questions_and_answers": [{"answer_start": 62, "answer": "making them iteratively predict the next word in a text", "question": "How did we train causal transformer language models in Chapter 9?"}, {"answer_start": 123, "answer": "eliminating the causal mask", "question": "What makes the guess-the-next-word language modeling task trivial?"}, {"answer_start": 411, "answer": "bidirectional encoders", "question": "The traditional learning objective suggests an approach that can be used to train what?"}, {"answer_start": 556, "answer": "cloze task", "question": "What is the fill-in-the-blank task called?"}, {"answer_start": 628, "answer": "motivating", "question": "What is the cloze task an example of?"}, {"answer_start": 674, "answer": "predicting which words are likely to come next", "question": "Instead of trying to predict the next word, what is the cloze task?"}]}, {"context": "we're asked to predict a missing item given the rest of the sentence.", "questions_and_answers": [{"answer_start": 25, "answer": "missing item", "question": "What are we asked to predict given the rest of the sentence?"}]}, {"context": "That is, given an input sequence with one or more elements missing, the learning task is to predict the missing elements. More precisely, during training the model is deprived of one or more elements of an input sequence and must generate a probability distribution over the vocabulary for each of the missing items. We then use the cross-entropy loss from each of the model's predictions to drive the learning process.", "questions_and_answers": [{"answer_start": 92, "answer": "predict the missing elements", "question": "What is the learning task given an input sequence with one or more missing elements?"}, {"answer_start": 241, "answer": "probability distribution", "question": "What must the model generate over the vocabulary for each of the missing items?"}, {"answer_start": 398, "answer": "the learning process", "question": "What do we use the cross-entropy loss from each of the model's predictions to drive?"}]}, {"context": "This approach can be generalized to any of a variety of methods that corrupt the training input and then asks the model to recover the original input. Examples of the kinds of manipulations that have been used include masks, substitutions, reorderings, deletions, and extraneous insertions into the training text.", "questions_and_answers": [{"answer_start": 131, "answer": "the original input", "question": "What does the model then ask the model to recover?"}, {"answer_start": 218, "answer": "masks, substitutions, reorderings, deletions, and extraneous insertions", "question": "What are examples of manipulations that have been used?"}]}, {"context": "The original approach to training bidirectional encoders is called Masked Language Modeling (MLM) (Devlin et al., 2019) . As with the language model training meth-", "questions_and_answers": [{"answer_start": 67, "answer": "Masked Language Modeling", "question": "What is the original approach to training bidirectional encoders called?"}, {"answer_start": 158, "answer": "meth", "question": "What is another name for the language model training?"}]}, {"context": "ods we've already seen, MLM uses unannotated text from a large corpus. Here, the MLM model is presented with a series of sentences from the training corpus where a random sample of tokens from each training sequence is selected for use in the learning task. Once chosen, a token is used in one of three ways:", "questions_and_answers": [{"answer_start": 33, "answer": "unannotated", "question": "What type of text does MLM use?"}, {"answer_start": 162, "answer": "a random sample of tokens", "question": "What is selected from each training sequence for use in the learning task?"}, {"answer_start": 297, "answer": "three", "question": "How many ways is a token used in an MLM model?"}]}, {"context": "[ \u2022 ] It is replaced with another token from the vocabulary, randomly sampled based on token unigram probabilities. [ \u2022 ] It is left unchanged.", "questions_and_answers": [{"answer_start": 87, "answer": "token unigram probabilities", "question": "What is the random sampling based on?"}, {"answer_start": 133, "answer": "unchanged", "question": "What is left after the token is replaced?"}]}, {"context": "In BERT, 15% of the input tokens in a training sequence are sampled for learning. Of these, 80% are replaced with [MASK] , 10% are replaced with randomly selected tokens, and the remaining 10% are left unchanged.", "questions_and_answers": [{"answer_start": 9, "answer": "15%", "question": "What percentage of input tokens in a training sequence are sampled for learning?"}, {"answer_start": 145, "answer": "randomly selected tokens", "question": "What are 10% of input tokens replaced with?"}, {"answer_start": 123, "answer": "10%", "question": "What percentage of input tokens are replaced with randomly selected tokens?"}]}, {"context": "The MLM training objective is to predict the original inputs for each of the masked tokens using a bidirectional encoder of the kind described in the last section. The cross-entropy loss from these predictions drives the training process for all the parameters in the model. Note that all of the input tokens play a role in the selfattention process, but only the sampled tokens are used for learning.", "questions_and_answers": [{"answer_start": 30, "answer": "to predict the original inputs", "question": "What is the MLM training objective?"}, {"answer_start": 168, "answer": "cross-entropy", "question": "What loss drives the training process for all parameters in the model?"}, {"answer_start": 324, "answer": "the selfattention process", "question": "What do all of the input tokens play a role in?"}]}, {"context": "For many NLP applications, the natural unit of interest may be larger than a single word (or token). Question answering, syntactic parsing, coreference and semantic role labeling applications all involve the identification and classification of constituents, or phrases. This suggests that a span-oriented masked learning objective might provide improved performance on such tasks.", "questions_and_answers": [{"answer_start": 63, "answer": "larger", "question": "For many NLP applications, the natural unit of interest may be what?"}, {"answer_start": 245, "answer": "constituents", "question": "What do NLP applications use to identify and classify phrases?"}, {"answer_start": 346, "answer": "improved performance", "question": "What might a span-oriented masked learning objective provide?"}]}, {"context": "A span is a contiguous sequence of one or more words selected from a training text, prior to subword tokenization. In span-based masking, a set of randomly selected spans from a training sequence are chosen. In the SpanBERT work that originated this technique (Joshi et al., 2020) , a span length is first chosen by sampling from a geometric distribution that is biased towards shorter spans an with upper bound of 10. Given this span length, a starting location consistent with the desired span length and the length of the input is sampled uniformly.", "questions_and_answers": [{"answer_start": 10, "answer": "a contiguous sequence of one or more words selected from a training text", "question": "What is a span?"}, {"answer_start": 147, "answer": "randomly selected spans", "question": "In span-based masking, a set of what is selected from a training sequence?"}, {"answer_start": 313, "answer": "by sampling from a geometric distribution that is biased towards shorter spans", "question": "How is a span length chosen?"}, {"answer_start": 443, "answer": "a starting location consistent with the desired span length and the length of the input", "question": "What is sampled uniformly given a span length?"}]}, {"context": "Once a span is chosen for masking, all the words within the span are substituted according to the same regime used in BERT: 80% of the time the span elements are substituted with the [MASK] token, 10% of the time they are replaced by randomly sampled words from the vocabulary, and 10% of the time they are left as is. Note that this substitution process is done at the span level-all the tokens in a given span are substituted using the same method. As with BERT, the total token substitution is limited to 15% of the training sequence input. Having selected and masked the training span, the input is passed through the standard transformer architecture to generate contextualized representations of the input tokens.", "questions_and_answers": [{"answer_start": 234, "answer": "randomly sampled words", "question": "What are the words in a span replaced by 10% of the time?"}, {"answer_start": 363, "answer": "at the span level", "question": "Where is the masking process done?"}, {"answer_start": 508, "answer": "15%", "question": "The total token substitution is limited to what percentage of the training sequence input?"}, {"answer_start": 622, "answer": "standard transformer architecture", "question": "What is used to generate contextualized representations of the input tokens?"}]}, {"context": "Downstream span-based applications rely on span representations derived from the tokens within the span, as well as the start and end points, or the boundaries, of a span. Representations for these boundaries are typically derived from the first and last words of a span, the words immediately preceding and following the span, or some combination of them. The SpanBERT learning objective augments the MLM objective with a boundary oriented component called the Span Boundary Objective (SBO). The SBO relies on a model's ability to predict the words within a masked span from the words immediately preceding and following it. This prediction is made using the output vectors associated with the words that immediately precede and follow the span being masked, along with positional embedding that signals which word in the span is being predicted:", "questions_and_answers": [{"answer_start": 120, "answer": "start and end points", "question": "What are the boundaries of a span?"}, {"answer_start": 240, "answer": "first and last words", "question": "What are the boundaries of a span typically derived from?"}, {"answer_start": 462, "answer": "Span Boundary Objective", "question": "What is the boundary oriented component of the SpanBERT learning objective called?"}, {"answer_start": 511, "answer": "a model's ability to predict the words within a masked span from the words immediately preceding and following it", "question": "What does the SBO depend on?"}, {"answer_start": 771, "answer": "positional embedding", "question": "What signals which word in the span is being predicted?"}]}, {"context": "where s denotes the position of the word before the span and e denotes the word after the end. The prediction for a given position i within the span is produced by concatenating the output embeddings for words s and e span boundary vectors with a positional embedding for position i and passing the result through a 2-layer feedforward network.", "questions_and_answers": [{"answer_start": 2, "answer": "e", "question": "What denotes the position of the word before the span?"}, {"answer_start": 316, "answer": "2-layer", "question": "How many layers is the feedforward network?"}]}, {"context": "The focus of masked-based learning is on predicting words from surrounding contexts with the goal of producing effective word-level representations. However, an important class of applications involves determining the relationship between pairs of sentences. These includes tasks like paraphrase detection (detecting if two sentences have similar meanings), entailment (detecting if the meanings of two sentences entail or contradict each other) or discourse coherence (deciding if two neighboring sentences form a coherent discourse).", "questions_and_answers": [{"answer_start": 101, "answer": "producing effective word-level representations", "question": "What is the goal of masked-based learning?"}, {"answer_start": 202, "answer": "determining the relationship between pairs of sentences", "question": "What is an important class of applications of masked-based learning?"}, {"answer_start": 358, "answer": "entailment", "question": "What is the term for detecting if the meanings of two sentences entail or contradict each other?"}, {"answer_start": 449, "answer": "discourse coherence", "question": "What is the term for deciding if two neighboring sentences form a coherent discourse?"}]}, {"context": "To capture the kind of knowledge required for applications such as these, BERT introduced a second learning objective called Next Sentence Prediction (NSP). In", "questions_and_answers": [{"answer_start": 125, "answer": "Next Sentence Prediction", "question": "What is NSP?"}, {"answer_start": 157, "answer": "In", "question": "Where was the second learning objective introduced?"}]}, {"context": "this task, the model is presented with pairs of sentences and is asked to predict whether each pair consists of an actual pair of adjacent sentences from the training corpus or a pair of unrelated sentences. In BERT, 50% of the training pairs consisted of positive pairs, and in the other 50% the second sentence of a pair was randomly selected from elsewhere in the corpus. The NSP loss is based on how well the model can distinguish true pairs from random pairs. To facilitate NSP training, BERT introduces two new tokens to the input representation (tokens that will prove useful for fine-tuning as well). After tokenizing the input with the subword model, the token [CLS] is prepended to the input sentence pair, and the token [SEP] is placed between the sentences and after the final token of the second sentence. Finally, embeddings representing the first and second segments of the input are added to the word and positional embeddings to allow the model to more easily distinguish the input sentences.", "questions_and_answers": [{"answer_start": 39, "answer": "pairs of sentences", "question": "What is presented to the model in this task?"}, {"answer_start": 256, "answer": "positive pairs", "question": "In BERT, 50% of training pairs consisted of what?"}, {"answer_start": 400, "answer": "how well the model can distinguish true pairs from random pairs", "question": "What is the NSP loss based on?"}, {"answer_start": 509, "answer": "two new tokens", "question": "To facilitate NSP training, BERT introduces what to the input representation?"}, {"answer_start": 660, "answer": "the token [CLS] is prepended to the input sentence pair", "question": "What happens after tokenizing the input with the subword model?"}, {"answer_start": 828, "answer": "embeddings", "question": "What is added to the word and positional embeddings to allow the model to more easily distinguish the input sentences?"}]}, {"context": "During training, the output vector from the final layer associated with the [CLS] token represents the next sentence prediction. As with the MLM objective, a learned set of classification weights W NSP \u2208 R 2\u00d7d h is used to produce a two-class prediction from the raw [CLS] vector.", "questions_and_answers": [{"answer_start": 99, "answer": "the next sentence prediction", "question": "What does the output vector from the final layer associated with the [CLS] token represent?"}, {"answer_start": 233, "answer": "two-class prediction", "question": "A learned set of classification weights W NSP  R 2d h is used to produce what from the raw [CLS] vector"}]}, {"context": "The corpus used in training BERT and other early transformer-based language models consisted of an 800 million word corpus of book texts called BooksCorpus (Zhu et al., 2015 ) and a [ 2.5 ] Billion word corpus derived from the English Wikipedia, for a combined size of [ 3.3 ] Billion words. The BooksCorpus is no longer used (for intellectual property reasons), and in general, as we'll discuss later, state-of-the-art models employ corpora that are orders of magnitude larger than these early efforts. To train the original BERT models, pairs of sentences were selected from the training corpus according to the next sentence prediction 50/50 scheme. Pairs were sampled so that their combined length was less than the 512 token input. Tokens within these sentence pairs were then masked using the MLM approach with the combined loss from the MLM and NSP objectives used for a final loss. Approximately 40 passes (epochs) over the training data was required for the model to converge.", "questions_and_answers": [{"answer_start": 99, "answer": "800 million", "question": "How many words were in the BooksCorpus corpus?"}, {"answer_start": 331, "answer": "intellectual property reasons", "question": "Why is the BooksCorpus no longer used?"}, {"answer_start": 539, "answer": "pairs of sentences", "question": "What was selected from the training corpus according to the next sentence prediction 50/50 scheme?"}, {"answer_start": 720, "answer": "512 token input", "question": "What was the combined length of pairs of sentences selected from the training corpus?"}, {"answer_start": 799, "answer": "MLM approach", "question": "What method was used to mask the tokens within sentence pairs?"}, {"answer_start": 904, "answer": "40", "question": "How many passes over the training data was required for the model to converge?"}]}, {"context": "The result of this pretraining process consists of both learned word embeddings, as well as all the parameters of the bidirectional encoder that are used to produce contextual embeddings for novel inputs.", "questions_and_answers": [{"answer_start": 165, "answer": "contextual embeddings", "question": "What are the parameters of the bidirectional encoder used to produce for novel inputs?"}, {"answer_start": 118, "answer": "bidirectional encoder", "question": "What is used to produce contextual embeddings for novel inputs?"}]}, {"context": "Given a pretrained language model and a novel input sentence, we can think of the output of the model as constituting contextual embeddings for each token in the contextual embeddings input. These contextual embeddings can be used as a contextual representation of the meaning of the input token for any task requiring the meaning of word.", "questions_and_answers": [{"answer_start": 105, "answer": "constituting contextual embeddings", "question": "What can we think of the output of a pretrained language model as for each token in the contextual embeddings input?"}, {"answer_start": 236, "answer": "contextual representation", "question": "What can contextual embeddings be used for?"}]}, {"context": "Contextual embeddings are thus vectors representing some aspect of the meaning of a token in context. For example, given a sequence of input tokens x 1 , ..., x n , we can use the output vector y i from the final layer of the model as a representation of the meaning of token x i in the context of sentence x 1 , ..., x n . Or instead of just using the vector y i from the final layer of the model, it's common to compute a representation for x i by averaging the output tokens y i from each of the last four layers of the model.", "questions_and_answers": [{"answer_start": 0, "answer": "Contextual embeddings", "question": "What are vectors representing some aspect of the meaning of a token in context?"}, {"answer_start": 276, "answer": "x i", "question": "What is the output vector y i from the final layer of the model?"}, {"answer_start": 450, "answer": "averaging", "question": "How is a representation for x i computed?"}]}, {"context": "Just as we used static embeddings like word2vec to represent the meaning of words, we can use contextual embeddings as representations of word meanings in context for any task that might require a model of word meaning. Where static embeddings represent the meaning of word types (vocabulary entries), contextual embeddings represent the meaning of word tokens: instances of a particular word type in a particular context. Contextual embeddings can thus by used for tasks like measuring the semantic similarity of two words in context, and are useful in linguistic tasks that require models of word meaning.", "questions_and_answers": [{"answer_start": 39, "answer": "word2vec", "question": "What is an example of a static embedding?"}, {"answer_start": 334, "answer": "the meaning of word tokens", "question": "What do contextual embeddings represent?"}, {"answer_start": 423, "answer": "Contextual embeddings", "question": "What can be used for tasks like measuring the semantic similarity of two words in context?"}]}, {"context": "In the next section, however, we'll see the most common use of these representations: as embeddings of word or even entire sentences that are the inputs to classifiers in the fine-tuning process for downstream NLP applications.", "questions_and_answers": [{"answer_start": 89, "answer": "embeddings of word or even entire sentences", "question": "What are the inputs to classifiers in the fine-tuning process for downstream NLP applications?"}, {"answer_start": 175, "answer": "fine-tuning", "question": "In what process are embeddings of word or even entire sentences the inputs to classifiers?"}]}, {"context": "The power of pretrained language models lies in their ability to extract generalizations from large amounts of text-generalizations that are useful for myriad downstream applications. To make practical use of these generalizations, we need to create interfaces from these models to downstream applications through a process called fine-tuning. Fine-tuning facilitates the creation of applications on top of prefine-tuning trained models through the addition of a small set of application-specific parameters. The fine-tuning process consists of using labeled data from the application to train these additional application-specific parameters. Typically, this training will either freeze or make only minimal adjustments to the pretrained language model parameters.", "questions_and_answers": [{"answer_start": 48, "answer": "their ability to extract generalizations", "question": "What is the power of pretrained language models?"}, {"answer_start": 331, "answer": "fine-tuning", "question": "What is the process called that creates interfaces from pretrained language models to downstream applications?"}, {"answer_start": 344, "answer": "Fine-tuning", "question": "What facilitates the creation of applications on top of prefine-tuned models through the addition of a small set of application-specific parameters?"}, {"answer_start": 551, "answer": "labeled data", "question": "What does the fine-tuning process use to train additional application-specific parameters?"}, {"answer_start": 681, "answer": "freeze or make only minimal adjustments", "question": "What does fine-tuning typically do to the pretrained language model parameters?"}]}, {"context": "Sequence classification applications often represent an input sequence with a single consolidated representation. With RNNs, we used the hidden layer associated with the final input element to stand for the entire sequence. A similar approach is used with transformers. An additional vector is added to the model to stand for the entire sequence. This vector is sometimes called the sentence embedding since it refers sentence embedding to the entire sequence, although the term 'sentence embedding' is also used in other ways. In BERT, the [CLS] token plays the role of this embedding. This unique token is added to the vocabulary and is prepended to the start of all input sequences, both during pretraining and encoding. The output vector in the final layer of the model for the [CLS] input represents the entire input sequence and serves as the input to a classifier head, a logistic regression or neural network classifier that makes the classifier head relevant decision.", "questions_and_answers": [{"answer_start": 0, "answer": "Sequence classification applications", "question": "What often represent an input sequence with a single consolidated representation?"}, {"answer_start": 203, "answer": "the entire sequence", "question": "What does the hidden layer associated with the final input element stand for?"}, {"answer_start": 256, "answer": "transformers", "question": "A similar approach is used with what?"}, {"answer_start": 270, "answer": "An additional vector", "question": "What is added to the model to stand for the entire sequence?"}, {"answer_start": 383, "answer": "sentence embedding", "question": "What is the additional vector that is added to the model to stand for the entire sequence called?"}, {"answer_start": 541, "answer": "[CLS] token", "question": "What is added to the vocabulary and is prepended to the start of all input sequences?"}, {"answer_start": 592, "answer": "unique token", "question": "What is added to the vocabulary and is prepended to the start of all input sequences?"}, {"answer_start": 724, "answer": "The output vector", "question": "What represents the entire input sequence in the final layer of the model for the [CLS] input?"}]}, {"context": "As an example, let's return to the problem of sentiment classification. A simple approach to fine-tuning a classifier for this application involves learning a set of weights, W C , to map the output vector for the [CLS] token, y CLS to a set of scores over the possible sentiment classes. Assuming a three-way sentiment classification task (positive, negative, neutral) and dimensionality d h for the size of the language model hidden layers gives W C \u2208 R 3\u00d7d h . Classification of unseen documents proceeds by passing the input text through the pretrained language model to generate y CLS , multiplying it by W C , and finally passing the resulting vector through a softmax.", "questions_and_answers": [{"answer_start": 46, "answer": "sentiment classification", "question": "Let's return to the problem of what?"}, {"answer_start": 227, "answer": "y CLS", "question": "What is the output vector for the [CLS] token?"}, {"answer_start": 341, "answer": "positive, negative, neutral", "question": "What is the three-way sentiment classification task?"}, {"answer_start": 227, "answer": "y CLS", "question": "What is the output vector for the [CLS] token?"}]}, {"context": "Finetuning the values in W C requires supervised training data consisting of input sequences labeled with the appropriate class. Training proceeds in the usual way; cross-entropy loss between the softmax output and the correct answer is used to drive the learning that produces W C .", "questions_and_answers": [{"answer_start": 77, "answer": "input sequences labeled with the appropriate class", "question": "What does supervised training data consist of?"}, {"answer_start": 150, "answer": "the usual way", "question": "How does training in W C proceed?"}]}, {"context": "As mentioned in Section [ 11.2 ].3, an important type of problem involves the classification of pairs of input sequences. Practical applications that fall into this class include logical entailment, paraphrase detection and discourse analysis.", "questions_and_answers": [{"answer_start": 74, "answer": "the classification of pairs of input sequences", "question": "What is an important type of problem?"}, {"answer_start": 122, "answer": "Practical applications", "question": "What types of applications fall into the class of logical entailment?"}]}, {"context": "Fine-tuning an application for one of these tasks proceeds just as with pretraining using the NSP objective. During fine-tuning, pairs of labeled sentences from the supervised training data are presented to the model. As with sequence classification, the output vector associated with the prepended [CLS] token represents the model's view of the input pair. And as with NSP training, the two inputs are separated by the a [SEP] token. To perform classification, the [CLS] vector is multiplied by a set of learning classification weights and passed through a softmax to generate label predictions, which are then used to update the weights.", "questions_and_answers": [{"answer_start": 0, "answer": "Fine-tuning", "question": "What is an application for one of these tasks called?"}, {"answer_start": 129, "answer": "pairs of labeled sentences", "question": "What are presented to the model during fine-tuning?"}, {"answer_start": 251, "answer": "the output vector associated with the prepended [CLS] token", "question": "What represents the model's view of the input pair?"}, {"answer_start": 420, "answer": "a [SEP] token", "question": "What separates the inputs from the output vector?"}, {"answer_start": 578, "answer": "label predictions", "question": "What is generated by the softmax?"}]}, {"context": "As an example, let's consider an entailment classification task with the Multi-Genre Natural Language Inference (MultiNLI) dataset (Williams et al., 2018) . In the task of natural language inference or NLI, also called recognizing textual natural language inference entailment, a model is presented with a pair of sentences and must classify the relationship between their meanings. For example in the MultiNLI corpus, pairs of sentences are given one of 3 labels: entails, contradicts and neutral. These labels describe a relationship between the meaning of the first sentence (the premise) and the meaning of the second sentence (the hypothesis). Here are representative examples of each class from the corpus:", "questions_and_answers": [{"answer_start": 113, "answer": "MultiNLI", "question": "What is another name for Multi-Genre Natural Language Inference?"}, {"answer_start": 219, "answer": "recognizing textual natural language inference entailment", "question": "What is another name for the task of natural language inference?"}, {"answer_start": 465, "answer": "entails, contradicts and neutral", "question": "What are the three labels given to pairs of sentences in the MultiNLI corpus?"}, {"answer_start": 579, "answer": "the premise", "question": "What is the meaning of the first sentence in the MultiNLI corpus?"}, {"answer_start": 658, "answer": "representative examples", "question": "What are the labels of each class from the MultiNLI corpus?"}]}, {"context": "[ \u2022 ] Neutral a: Jon walked back to the town to the smithy. b: Jon traveled back to his hometown.", "questions_and_answers": [{"answer_start": 6, "answer": "Neutral", "question": "What color was Jon's mood?"}, {"answer_start": 84, "answer": "his hometown", "question": "Where did Jon travel back to?"}]}, {"context": "[ \u2022 ] Contradicts a: Tourist Information offices can be very helpful. b: Tourist Information offices are never of any help.", "questions_and_answers": [{"answer_start": 21, "answer": "Tourist Information offices", "question": "What can be very helpful?"}, {"answer_start": 105, "answer": "never", "question": "How often are Tourist Information offices of any help?"}]}, {"context": "A relationship of contradicts means that the premise contradicts the hypothesis; entails means that the premise entails the hypothesis; neutral means that neither is necessarily true. The meaning of these labels is looser than strict logical entailment or contradiction indicating that a typical human reading the sentences would most likely interpret the meanings in this way.", "questions_and_answers": [{"answer_start": 155, "answer": "neither is necessarily true", "question": "What is neutral in a relationship of contradicts and entails?"}, {"answer_start": 215, "answer": "looser", "question": "What is the meaning of the labels?"}]}, {"context": "To fine-tune a classifier for the MultiNLI task, we pass the premise/hypothesis pairs through a bidirectional encoder as described above and use the output vector for the [CLS] token as the input to the classification head. As with ordinary sequence classification, this head provides the input to a three-way classifier that can be trained on the MultiNLI training corpus.", "questions_and_answers": [{"answer_start": 145, "answer": "the output vector", "question": "What is the input to the classification head?"}, {"answer_start": 344, "answer": "the MultiNLI training corpus", "question": "What can a three-way classifier be trained on?"}]}, {"context": "Alternatively, the distribution over labels provided by the softmax for each input token can be passed to a conditional random field (CRF) layer which can take global tag-level transitions into account.", "questions_and_answers": [{"answer_start": 134, "answer": "CRF", "question": "What is another name for a conditional random field?"}, {"answer_start": 60, "answer": "softmax", "question": "The distribution over labels provided by what can be passed to a conditional random field layer?"}]}, {"context": "Bidirectional Transformer Encoder NNP MD VB DT NN Figure 11 .9 Sequence labeling for part-of-speech tagging with a bidirectional transformer encoder. The output vector for each input token is passed to a simple k-way classifier.", "questions_and_answers": [{"answer_start": 85, "answer": "part-of-speech", "question": "What type of tagging is labeled with a bidirectional transformer encoder?"}, {"answer_start": 211, "answer": "k-way classifier", "question": "The output vector for each input token is passed to what?"}]}, {"context": "A complication with this approach arises from the use of subword tokenization such as WordPiece or Byte Pair Encoding. Supervised training data for tasks like named entity recognition (NER) is typically in the form of BIO tags associated with text segmented at the word level. For example the following sentence containing two named entities:", "questions_and_answers": [{"answer_start": 86, "answer": "WordPiece or Byte Pair Encoding", "question": "What are two examples of subword tokenization?"}, {"answer_start": 159, "answer": "named entity recognition", "question": "What is NER?"}, {"answer_start": 323, "answer": "two", "question": "How many named entities does the following sentence contain?"}]}, {"context": "Unfortunately, the WordPiece tokenization for this sentence yields the following sequence of tokens which doesn't align directly with BIO tags in the ground truth annotation:", "questions_and_answers": [{"answer_start": 15, "answer": "the WordPiece tokenization", "question": "What produces the following sequence of tokens that don't align directly with BIO tags in the ground truth annotation?"}]}, {"context": "'Mt ', '. ', 'San', '##itas', 'is', 'in', 'Sunshine', 'Canyon' '.' To deal with this misalignment, we need a way to assign BIO tags to subword tokens during training and a corresponding way to recover word-level tags from subwords during decoding. For training, we can just assign the gold-standard tag associated with each word to all of the subword tokens derived from it.", "questions_and_answers": [{"answer_start": 0, "answer": "'Mt", "question": "What is 'San', '##itas', 'is', 'in', 'Suns"}, {"answer_start": 43, "answer": "Sunshine", "question": "What is another name for Canyon?"}, {"answer_start": 123, "answer": "BIO tags", "question": "What do we need to assign to subword tokens during training?"}, {"answer_start": 285, "answer": "gold-standard tag", "question": "For training, we can assign what tag to all of the subword tokens derived from each word?"}]}, {"context": "For decoding, the simplest approach is to use the argmax BIO tag associated with the first subword token of a word. Thus, in our example, the BIO tag assigned to \"Mt\" would be assigned to \"Mt.\" and the tag assigned to \"San\" would be assigned to \"Sanitas\", effectively ignoring the information in the tags assigned to \".\" and \"##itas\". More complex approaches combine the distribution of tag probabilities across the subwords in an attempt to find an optimal word-level tag.", "questions_and_answers": [{"answer_start": 50, "answer": "argmax BIO tag", "question": "What is the simplest way to decode a word?"}, {"answer_start": 163, "answer": "Mt", "question": "What would the BIO tag assigned to be assigned to \"Mt.\"?"}, {"answer_start": 246, "answer": "Sanitas", "question": "What would the tag assigned to \"San\" be assigned to?"}, {"answer_start": 325, "answer": "\"##itas\"", "question": "What is the tag assigned to Sanitas instead of Sanitas?"}, {"answer_start": 371, "answer": "distribution of tag probabilities", "question": "What do more complex approaches combine to find an optimal word-level tag?"}]}, {"context": "Span-oriented applications operate in a middle ground between sequence level and token level tasks. That is, in span-oriented applications the focus is on generating and operating with representations of contiguous sequences of tokens. Typical operations include identifying spans of interest, classifying spans according to some labeling scheme, and determining relations among discovered spans. Applications include named entity recognition, question answering, syntactic parsing, semantic role labeling and coreference resolution.", "questions_and_answers": [{"answer_start": 62, "answer": "sequence level and token level tasks", "question": "Span-oriented applications operate in a middle ground between what two tasks?"}, {"answer_start": 155, "answer": "generating and operating with representations of contiguous sequences of tokens", "question": "What is the focus of span-oriented applications?"}, {"answer_start": 351, "answer": "determining relations among discovered spans", "question": "What is a typical span-oriented operation?"}, {"answer_start": 418, "answer": "named entity recognition", "question": "What is an application that span-oriented applications include?"}]}, {"context": "The first step in fine-tuning a pretrained language model for a span-based application using the contextualized input embeddings from the model to generate representations for all the spans in the input. Most schemes for representing spans make use of two primary components: representations of the span boundaries and summary representations of the contents of each span. To compute a unified span representation, we concatenate the boundary representations with the summary representation.", "questions_and_answers": [{"answer_start": 18, "answer": "fine-tuning", "question": "What is the first step in creating a pretrained language model for a span-based application?"}, {"answer_start": 276, "answer": "representations of the span boundaries and summary representations of the contents of each span", "question": "What are the two primary components of most schemes for representing spans?"}, {"answer_start": 418, "answer": "concatenate", "question": "How do we compute a unified span representation?"}]}, {"context": "In the simplest possible approach, we can use the contextual embeddings of the start and end tokens of a span as the boundaries, and the average of the output embeddings within the span as the summary representation.", "questions_and_answers": [{"answer_start": 189, "answer": "the summary representation", "question": "The average of the output embeddings within a span can be used as what?"}, {"answer_start": 133, "answer": "the average", "question": "What is the summary representation of the output embeddings within a span?"}, {"answer_start": 75, "answer": "the start and end tokens", "question": "What are the boundaries of a span?"}, {"answer_start": 189, "answer": "the summary representation", "question": "The average of the output embeddings within a span can be used as what?"}]}, {"context": "A weakness of this approach is that it doesn't distinguish the use of a word's embedding as the beginning of a span from its use as the end of one. Therefore, more elaborate schemes for representing the span boundaries involve learned representations for start and end points through the use of two distinct feedforward networks:", "questions_and_answers": [{"answer_start": 295, "answer": "two", "question": "How many distinct feedforward networks are used to represent span boundaries?"}]}, {"context": "Similarly, a simple average of the vectors in a span is unlikely to be an optimal representation of a span since it treats all of a span's embeddings as equally important. For many applications, a more useful representation would be centered around the head of the phrase corresponding to the span. One method for getting at such information in the absence of a syntactic parse is to use a standard self-attention layer to generate a span representation.", "questions_and_answers": [{"answer_start": 113, "answer": "it treats all of a span's embeddings as equally important", "question": "Why is a simple average of the vectors in a span unlikely to be an optimal representation of a span?"}, {"answer_start": 233, "answer": "centered around the head of the phrase corresponding to the span", "question": "What is a more useful representation of a span?"}, {"answer_start": 399, "answer": "self-attention layer", "question": "What is used to generate a span representation in the absence of a syntactic parse?"}]}, {"context": "spans in the text. That is, all the unigrams, bigrams, trigrams, etc. up to the length limit.", "questions_and_answers": [{"answer_start": 0, "answer": "spans", "question": "What are all the unigrams, bigrams, trigrams, etc. up to the length limit in text?"}, {"answer_start": 28, "answer": "all the unigrams, bigrams, trigrams", "question": "What are spans in a text?"}, {"answer_start": 80, "answer": "length limit", "question": "What is the length limit for unigrams, bigrams, trigrams, etc.?"}]}, {"context": "With this approach, fine-tuning entails using supervised training data to learn the parameters of the final classifier, as well as the weights used to generate the boundary representations, and the weights in the self-attention layer that generates the span content representation. During training, the model's predictions for all spans are compared to their gold-standard labels and cross-entropy loss is used to drive the training.", "questions_and_answers": [{"answer_start": 213, "answer": "self-attention layer", "question": "What layer generates the span content representation?"}, {"answer_start": 20, "answer": "fine-tuning", "question": "What entails using supervised training data to learn the parameters of the final classifier?"}, {"answer_start": 359, "answer": "gold-standard labels", "question": "What are the model's predictions for all spans compared to?"}, {"answer_start": 384, "answer": "cross-entropy loss", "question": "What is used to drive the training?"}]}, {"context": "There are two significant advantages to a span-based approach to NER over a BIO-based per-word labeling approach. The first advantage is that BIO-based approaches are prone to a labeling mis-match problem. That is, every label in a longer named entity must be correct for an output to be judged correct. Returning to the example in Figure 11 .10, the following labeling would be judged entirely wrong due to the incorrect label on the first item. Span-based approaches only have to make one classification for each span. The second advantage to span-based approaches is that they naturally accommodate embedded named entities. For example, in this example both United Airlines and United Airlines Holding are legitimate named entities. The BIO approach has no way of encoding this embedded structure. But the span-based approach can naturally label both since the spans are labeled separately.", "questions_and_answers": [{"answer_start": 10, "answer": "two", "question": "How many significant advantages are there to a span-based approach to NER over a BIO-based per-word labeling approach?"}, {"answer_start": 178, "answer": "labeling mis-match", "question": "BIO-based approaches are prone to what problem?"}, {"answer_start": 215, "answer": "every label in a longer named entity must be correct for an output to be judged correct", "question": "What is a labeling mis-match problem?"}, {"answer_start": 412, "answer": "incorrect label on the first item", "question": "Why would the labeling in the example in Figure 11.10 be judged entirely wrong?"}, {"answer_start": 169, "answer": "one", "question": "How many classifications does a span-based approach have to make for each span?"}, {"answer_start": 575, "answer": "they naturally accommodate embedded named entities", "question": "What is the second advantage to span-based approaches?"}, {"answer_start": 661, "answer": "United Airlines and United Airlines Holding", "question": "Which two entities are legitimate named entities?"}, {"answer_start": 736, "answer": "The BIO approach has no way of encoding this embedded structure", "question": "What is the advantage of a span-based approach to NER over a BIO-based approach?"}, {"answer_start": 42, "answer": "span-based approach", "question": "What can naturally label both United Airlines and United Airlines Holding since the spans are labeled separately?"}]}, {"context": "Large pretrained neural language models exhibit many of the potential harms discussed in Chapter 4 and Chapter 6. Many of these harms become realized when pretrained language models are fine-tuned to downstream tasks, particularly those involving text generation, such as in assistive technologies like web search query completion, or predictive typing for email (Olteanu et al., 2020) .", "questions_and_answers": [{"answer_start": 0, "answer": "Large", "question": "What type of neural language models exhibit many of the potential harms discussed in Chapter 4 and Chapter 6?"}, {"answer_start": 150, "answer": "when pretrained language models are fine-tuned to downstream tasks", "question": "When do many of these harms become realized?"}]}, {"context": "For example, language models can generate toxic language. Gehman et al. (2020) show that many kinds of completely non-toxic prompts can nonetheless lead large language models to output hate speech and abuse. Brown et al. (2020) and Sheng et al. (2019) showed that large language models generate sentences displaying negative attitudes toward minority identities such as being Black or gay.", "questions_and_answers": [{"answer_start": 42, "answer": "toxic language", "question": "Language models can generate what type of language?"}, {"answer_start": 58, "answer": "Gehman", "question": "Who et al. showed that non-toxic prompts can still lead large language models to output hate speech and abuse?"}, {"answer_start": 185, "answer": "hate speech and abuse", "question": "What do non-toxic prompts cause large language models to output?"}, {"answer_start": 208, "answer": "Brown", "question": "Which ethnicity did Gehman and Sheng show that large language models produce negative attitudes toward minority identities?"}, {"answer_start": 232, "answer": "Sheng", "question": "Who et al. (2019) showed that large language models generate sentences displaying negative attitudes toward minority identities?"}, {"answer_start": 295, "answer": "sentences displaying negative attitudes toward minority identities", "question": "Brown et al. and Sheng et al. (2019) showed that large language models produce what?"}]}, {"context": "Indeed, language models are biased in a number of ways by the distributions of their training data. Gehman et al. (2020) shows that large language model training datasets include toxic text scraped from banned sites. In addition to problems of toxicity, internet data is disproportionately generated by authors from developed countries, and many large language models train on data from Reddit, whose authors skew male and young. Such biased population samples likely skew the resulting generation away from the perspectives or topics of underrepresented populations. Furthermore, language models can amplify demographic and other biases in training data, just as we saw for embedding models in Chapter 6.", "questions_and_answers": [{"answer_start": 62, "answer": "distributions of their training data", "question": "How are language models biased in a number of ways?"}, {"answer_start": 100, "answer": "Gehman", "question": "Who showed that large language model training datasets include toxic text scraped from banned sites?"}, {"answer_start": 203, "answer": "banned sites", "question": "Where is toxic text scraped from language model training datasets?"}, {"answer_start": 387, "answer": "Reddit", "question": "Many large language models train on data from what site?"}, {"answer_start": 538, "answer": "underrepresented populations", "question": "What do biased population samples likely skew the generation away from?"}, {"answer_start": 675, "answer": "embedding models", "question": "What did we see in Chapter 6 about language models amplify demographic and other biases in training data?"}]}, {"context": "Language models can also be a tool for generating text for misinformation, phishing, radicalization, and other socially harmful activities (Brown et al., 2020) . McGuffie and Newhouse (2020) show how large language models generate text that emulates online extremists, with the risk of amplifying extremist movements and their attempt to radicalize and recruit.", "questions_and_answers": [{"answer_start": 0, "answer": "Language models", "question": "What can be a tool for generating text for misinformation, phishing, radicalization, and socially harmful activities?"}, {"answer_start": 162, "answer": "McGuffie and Newhouse", "question": "Who showed how large language models generate text that emulates online extremists?"}]}, {"context": "This chapter has introduced the topic of transfer learning from pretrained language models. Here's a summary of the main points that we covered:", "questions_and_answers": [{"answer_start": 41, "answer": "transfer learning", "question": "What is the topic of pretrained language models?"}, {"answer_start": 101, "answer": "summary", "question": "What is a summary of the main points that we covered in this chapter?"}]}, {"context": "[ \u2022 ] Bidirectional encoders can be used to generate contextualized representations of input embeddings using the entire input context. [ \u2022 ] Pretrained language models based on bidirectional encoders can be learned using a masked language model objective where a model is trained to guess the missing information from an input. [ \u2022 ] Pretrained language models can be fine-tuned for specific applications by adding lightweight classifier layers on top of the outputs of the pretrained model.", "questions_and_answers": [{"answer_start": 6, "answer": "Bidirectional encoders", "question": "What can be used to generate contextualized representations of input embeddings using the entire input context?"}, {"answer_start": 284, "answer": "guess the missing information", "question": "What is a pretrained language model trained to do from an input?"}, {"answer_start": 416, "answer": "lightweight classifier layers", "question": "Pretrained language models can be fine-tuned for specific applications by adding what on top of the outputs of the pretrained model?"}]}]